<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>徐阿衡</title>
  <subtitle>Shuang</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.shuang0420.com/"/>
  <updated>2017-10-11T13:10:56.000Z</updated>
  <id>http://www.shuang0420.com/</id>
  
  <author>
    <name>徐阿衡</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>NLP 笔记 - Discourse Analysis</title>
    <link href="http://www.shuang0420.com/2017/09/20/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/"/>
    <id>http://www.shuang0420.com/2017/09/20/NLP 笔记 - Discourse Analysis/</id>
    <published>2017-09-20T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>CMU 11611 笔记。讲语篇分析的一些概念，包括 coreference, cohesion, speech acts 等。<br><a id="more"></a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><blockquote>
<p><strong>Discourse</strong> is the coherent structure of language above the level of sentences or clauses. A discourse is a coherent structured group of sentences.</p>
</blockquote>
<p><strong>Discourse Analysis</strong> 中文对应过来通常是<strong>语篇/篇章分析</strong>。前面讲到了语素级别的(morphemes)、词汇级别的(lexical)、短语级别的(segmentation)、句子级别的(syntactic parsing)种种概念及分析，现在到了 <strong>beyond sentences</strong> 这一级别，只有两句或两个句子/从句以上的句子，才被称为 discourse。广义来讲，discourse 其实有很多含义，大多都能归到下面三类。</p>
<ul>
<li><strong>Language beyond sentences</strong><br>语言学家(Linguistists)关注的概念，分析句子之间是怎么<strong>联系/衔接</strong>的，也是本篇的重点</li>
<li><strong>Language in use</strong><br>可以理解为实际发生的对话(conversation)，这是应用语言学家(Applied Linguistists)会关注的，比如说他们会来研究医患人员的对话来看医生是怎么在对话过程中建立权威的(结合 speech acts)</li>
<li><strong>A broader range of social practice that includes nonliguistic and nonspecific instances of language</strong><br>不止是语言学的内容，而是 linguistic + social practice + ideological assumption 结合的产物，社会学家对这个更感兴趣，会关注特定时间特定场景下的行为，比如来研究种族歧视等社会现象(结合 contexts)</li>
</ul>
<p>具体见<a href="A broader range of social practice that includes nonliguistic and nonspecific instances of langue">The Handbook of Discourse Analysis</a></p>
<p>语篇分析的应用很广泛，比如说<strong>自动文摘、自动作文评分、会议理解、对话系统</strong>等。</p>
<h1 id="Coreference"><a href="#Coreference" class="headerlink" title="Coreference"></a>Coreference</h1><p>一个重要的概念是 <strong>coreference</strong>，表示共指关系。自然语言的所指现象非常丰富，有<strong>不定名词短语(indefinite noun phrase)、有定名词短语(definite noun phrase)、代词(pronoun)、指示词(demonstrative)、单个复指(one-anaphora)</strong>等，所指对象类型有<strong>推理对象(inferrable)、不连续集(discontinuous set)和类属(generic)</strong>。下面主要以<strong>代词指代</strong>来讲共指的概念。</p>
<p>先来看下两个概念，<strong>anaphora</strong> 和 <strong>cataphora</strong>，两者都是指代，不同的是 referent 和 referring expression 出现的先后顺序</p>
<ul>
<li><strong>anaphora:</strong> the use of a word referring to or replacing a word used earlier in a sentence</li>
<li><strong>cataphora:</strong> the use of a word or phrase that refers to or stands for a later word or phrase</li>
</ul>
<p><strong>E.g., Anphora </strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">I went to see my grandfather at the hopital.</div><div class="line">The old man has been there for weeks.</div><div class="line">He had surgery a few days ago.</div></pre></td></tr></table></figure></p>
<p>the old man 和 he 是 referring expression，在这个场景下也是 anaphora，都指代前面的 my grandfather，my grandfather 又称为先行词(antecedents)。</p>
<p><strong>Referring expressions:</strong> the old man, he<br><strong>Antecedents:</strong> my grandfather</p>
<p><strong>E.g., Cataphora </strong><br>先出现 She，再出现 She 指代的 Mary。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">– R: She didn’t like it!</div><div class="line">– D: What do you mean?</div><div class="line">– R: She didn’t like it!</div><div class="line">– D: Who didn’t like what?</div><div class="line">– R: Mary.</div><div class="line">– D: What didn’t Mary like?</div><div class="line">– R: She didn’t like the article I read in the *New Yorker*.</div></pre></td></tr></table></figure></p>
<p>指代问题在单个句子或者多个句子中都会出现，这一章讲 discourse，只讨论多个句子中的指代消解问题(<strong>Reference Resolution</strong>)。</p>
<h2 id="Pronoun-reference-resolution"><a href="#Pronoun-reference-resolution" class="headerlink" title="Pronoun reference resolution"></a>Pronoun reference resolution</h2><p>看一个简单的代词指代消解的例子。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">John saw Mary in the park. As every morning, she was walking her dog.</div></pre></td></tr></table></figure></p>
<p>我们需要来判断 she 指代谁。<br>第一步，找到所有的 candidate referents，也就是名词短语。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">- John</div><div class="line">- Mary</div><div class="line">- The park</div><div class="line">- Every morning</div><div class="line">- Her dog</div></pre></td></tr></table></figure></p>
<p>直觉上看，She 必须是 Person，所以 morning, park 删除，John 是男性，gender 不符，删除，her dog 难以确定 gender，最有可能的是 Mary。这个例子非常简单，仅仅通过一致性约束就判断出了正确的 referent，很多场景比这复杂的多。下面先来看一下代词指代消解相关的一些规则/模型。</p>
<h3 id="Filters-句法和语义约束"><a href="#Filters-句法和语义约束" class="headerlink" title="Filters: 句法和语义约束"></a>Filters: 句法和语义约束</h3><p>根据下面的一些规则约束可以 <strong>排除</strong> 一些 candidate referents。</p>
<ul>
<li><strong>Agreement constraints (一致性)</strong><br>gender, number, person, animacy</li>
<li><strong>Binding theory:</strong> <strong>reflexive</strong> required/prohibited (反身代词)<br>反身代词可以用于同指包含它的最近邻从句的主语，而非反身代词不能同指该主语<br>– John bought himself a new Ford. [himself=John]<br>– John bought him a new Ford. [him≠John]<br>– John said that Bill bought him a new Ford. [him≠Bill]<br>– J said that B bought himself a new F. [himself=Bill]<br>– He said that he bought J a new Ford. [both he≠J]</li>
<li><strong>Selectional restrictions</strong><br>选择限制，动词对论元(argument)施加的选择限制<br>John parked his car in the garage after driving it around for hours.<br>动词 drive 要求直接宾语是能够驾驶的事物，比如说 car</li>
</ul>
<h3 id="Preferences-优先级"><a href="#Preferences-优先级" class="headerlink" title="Preferences: 优先级"></a>Preferences: 优先级</h3><p>下面的一些偏好规则说明哪些 referents 有更大的可能性是正确的。</p>
<ul>
<li><strong>Parallelism</strong></li>
<li><strong>Sentence ordering: Recency </strong><br>邻近话段引入的实体比较远话段引入的显著性更高</li>
<li><strong>Grammatical Role</strong>: subj&gt;obj&gt;others</li>
<li><strong>Repeated mention</strong><br>Billy had been drinking for days.<br>He went to the bar again today. Jim went with him. He ordered rum.</li>
<li><strong>Verb semantics</strong><br>有些动词的出现会对其中一个论元的位置产生语义上的强调，这会造成对其后代词的理解偏差<br>John <strong>phoned/criticized</strong> Bill. He lost the laptop.<br>如果是 phone，明显应该是 John 丢了电脑，如果是 criticize，应该是 Bill 丢了。这被认为是动词的“隐含因果关系”，criticize 事件的隐含因果被认为是动词宾语，而 phone 被认为是动词主语</li>
</ul>
<h3 id="Discourse-model"><a href="#Discourse-model" class="headerlink" title="Discourse model"></a>Discourse model</h3><p>很多指代消解算法的第一步是建立 discourse model，discourse model 包含了 discourse 所指实体的表示以及它们所承担的关系，模型有两个基本操作，如下图所示，当第一次提到所指对象时，我们称它的表示为被唤起(evoke)而进入模型，之后当再次提及时，我们称从模型中访问(access)它的表示。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/discourse%20model.png" class="ful-image" alt="discourse%20model.png"></p>
<h2 id="Computational-approaches-to-pronouns-reference-resolution"><a href="#Computational-approaches-to-pronouns-reference-resolution" class="headerlink" title="Computational approaches to pronouns reference resolution"></a>Computational approaches to pronouns reference resolution</h2><p>有了前面的知识储备，现在可以来看一下代词指代消解的传统算法。</p>
<h3 id="Hobbs-Algorithm"><a href="#Hobbs-Algorithm" class="headerlink" title="Hobbs Algorithm"></a>Hobbs Algorithm</h3><p>非常早期的，1978 年 Hobbs 提出一种不依赖任何语义知识或语篇信息，只利用语法规则和完全解析树信息的指代消解算法，又叫<strong>树查询算法(Tree Search Algorithm)</strong>。算法会遍历当前句子和先行句(preceding sentences)的解析树，根据 binding theory, recency, 和 grammatical role preferences 选择合适的 NP 作为 referent，这种方法需要 parser，需要 gender 和 number 信息，也需要用于确定 NP gender 的 head rule 和 wordnet。现在实际系统中很少直接使用，一般只会拿来做 baseline。</p>
<p><strong>算法过程:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/HOBBS.png" class="ful-image" alt="HOBBS.png"></p>
<h3 id="Resolution-of-Anaphora-Procedure-RAP"><a href="#Resolution-of-Anaphora-Procedure-RAP" class="headerlink" title="Resolution of Anaphora Procedure(RAP)"></a>Resolution of Anaphora Procedure(RAP)</h3><p>1994 年 Lappin 和 Lease 提出的，综合考虑了 recency 和基于句法的优先关系的影响。使用 McCord 提出的 Slot Grammar 获得文档的句法结构，根据过滤规则过滤掉不合适的 referent，然后通过手工加权的各种语言特征计算剩下的 referent 重要性，确定 referent。1996 年 Kennedy 等人对 RAP 做了修改和扩展，避免了构建完整的解析树，只用 NLP 工具预处理得到词性标注和句法功能标注等浅层信息，2005 年 Luo 等人继续做了改进，尝试用最大熵模型来自动确定各种语言特征的权值。下面来看一下基础版本的 RAP 算法。</p>
<p>两个步骤，<strong>discourse model 的更新和代词的判定</strong>。遇到一个唤起的新的实体的名词短语时，必须为它添加一个表示以及用于计算的<strong>显著度(salience)</strong>，显著度由一组<strong>显著因子(salience factor)</strong>所指派的权值综合来计算。每处理一个新句子，discourse model 中的每个因子为实体所指派的权重就减一半。</p>
<p><strong>显著因子及其权重：</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/salience%20weights.png" class="ful-image" alt="salience%20weights.png"></p>
<p><strong>RAP 过程:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/RAP.png" class="ful-image" alt="RAP.png"></p>
<p><strong>Example:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/egs1.png" class="ful-image" alt="egs1.png"></p>
<p>=&gt; he 指代 John</p>
<p><strong>Halve</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/egs2halv.png" class="ful-image" alt="egs2halv.png"></p>
<p>加入 he 的分数<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/egs3he.png" class="ful-image" alt="egs3he.png"></p>
<p>根据规则 =&gt; it 指代 Integra，加入 it 的分数</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/egs4.png" class="ful-image" alt="egs4.png">
<p>加入 Bill<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/egs5.png" class="ful-image" alt="egs5.png"></p>
<p><strong>Halve</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/egs6.png" class="ful-image" alt="egs6.png"></p>
<p>……</p>
<h3 id="Centering-theory"><a href="#Centering-theory" class="headerlink" title="Centering theory"></a>Centering theory</h3><p><strong>Centering algorithm</strong> 和 Lappin &amp; Leass 算法一样都采用了 discourse model 的表示，但同时引入了 center 的概念，center 表示语段中心成分，在语篇中联系不同语段的实体(entity)，在话语中的任何定点都有一个单独的实体被作为 center。center 细分为<strong>语段潜在中心</strong> (forward-looking center $C_f$) 和<strong>语段现实中心</strong>(backward-looking center $C_b$)。</p>
<p>对于由 $U_1, …, U_t$ 构成的语篇，语段 $U_n$ 的 $C_f$ 和 $C_b$ 由下面的制约条件：</p>
<ul>
<li>$C_f(U_n)$ 是当前语段中的所有实体组成的集合，在下一语段中至少会部分实现(realize)</li>
<li>$C_b(U_n)$ 是 $C_f(U_{n-1})$ 中的一个，而且是 rank 最高的那个 $C_b = \ most \ highly \ ranked \ C_f \ used \ from  \ prev. \ S$<br><strong>Rank:</strong> Subj &gt; ExistPredNom &gt; Obj &gt; IndObj-Obl &gt; DemAdvPP<br>语法角色层级和 Lappin &amp; Leass 算法相似，但并没有给实体附加权重值，只是简单的相互排序</li>
<li>每一个 $U_n$ 都可以有一组 $C_f$，但最多只能有一个 $C_b$，一般来说，篇章的第一个语段没有 $C_b$</li>
<li>在 $C_f$ 集合里，rank 最高的称为 Preferred Center $C_p$</li>
</ul>
<p><strong>转换规则：</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/centering1.png" class="ful-image" alt="centering1.png"></p>
<p>有了上面的概念和规则，再来看一下基于 Center 的指代消解算法<br><strong>Step1：</strong> 为每个语段中的实体生成可能的 Cb-Cf组；<br><strong>Step2：</strong> 通过各种约束条件来过滤（比如：句法位置约束、语义选择限制，等等）；<br><strong>Step3：</strong> 通过转换顺序来给出排序：如果一个代词 R 的指代成分为 A 所得到的篇章连贯性高于指代成分为 B 时得到的篇章连贯性，则将 R 的指代成分确定为 A。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/centeringeg.png" class="ful-image" alt="centeringeg.png"></p>
<p>Centering 和 Hobbs 都假设输入时正确的句法结构。和 Lappin &amp; Leass 算法相似，中心算法的主要显著因子包括 Grammatical Role, Recency, Repeated Mention，但不同的是语法层级对显著性影响的方式是间接的，如果低级语法角色的所指对象导致的转换时较高级别的，它会比高级角色的所指对象优先，所以 centering algorithm 可能会将其他算法认为是相对较低显著性的所指对象判定一个代词的所指对象。比如说</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">– Bob opened a new dealership last week</div><div class="line">– John took a look at the Fords in his lot [Cb=Bob]</div><div class="line">– He ended up buying one</div><div class="line"></div><div class="line">Results: He=Bob =&gt; CONTINUE, He=John =&gt; SMOOTH</div></pre></td></tr></table></figure>
<h3 id="Log-linear-model"><a href="#Log-linear-model" class="headerlink" title="Log-linear model"></a>Log-linear model</h3><p>监督学习，需要手工标注同指关系，基于规则过滤，还是以上面的语段为例，特征如下：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/feature.png" class="ful-image" alt="feature.png"></p>
<h3 id="General-Coreference-Resolution"><a href="#General-Coreference-Resolution" class="headerlink" title="General Coreference Resolution"></a>General Coreference Resolution</h3><p>就是转化为一个分类问题，先识别文本中的 NP，然后对每一个 NP pair 进行一个二分类，看他们是否是共指关系，然后合并结果形成<strong>共指链(coreferential chain)</strong>，Coreference chains 其实是 cohesion 的一个部分，下面会具体讲到 cohesion。所以我们需要的是</p>
<ul>
<li>a choice of classifier</li>
<li>lots of labeled data</li>
<li>features</li>
</ul>
<p>可以选的特征有<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">• Edit distance between the two NPs</div><div class="line">• Are the two NPs the same NER type?</div><div class="line">• Appositive syntax</div><div class="line">  – “Alan Shepherd, the first American astronaut…”</div><div class="line">• Proper/definite/indefinite/pronoun</div><div class="line">• Gender</div><div class="line">• Number</div><div class="line">• Distance in sentences</div><div class="line">• Number of NPs between</div><div class="line">• Grammatical role</div><div class="line">• etc.</div></pre></td></tr></table></figure></p>
<p>更多见<br>• Combine best: ENCORE (Bo Lin et al 2010)<br>• ML for Cross-Doc Coref (Rushin Shah et al 2011)</p>
<h1 id="Coherence-Cohesion"><a href="#Coherence-Cohesion" class="headerlink" title="Coherence, Cohesion"></a>Coherence, Cohesion</h1><h2 id="Coherence-Relations"><a href="#Coherence-Relations" class="headerlink" title="Coherence Relations"></a>Coherence Relations</h2><p>Cohesion 是衔接，强调句子构成成分之间的关联性，Coherence 是连贯，强调句子之间的语义连接关系。看下面三组句子，只有第一组是 make sense 的，而第二第三组的两个句子间没有任何关联。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">I saw Mary in the street. She was looking for a bookstore.</div><div class="line">? I saw Mary in the street. She has a cat.</div><div class="line">?? I saw Mary in the street. The pistons won.</div></pre></td></tr></table></figure></p>
<p>句子之间的衔接关系有很多种，比如说<strong>结果(result)、解释(explanation)、平行(parallel)、详述(elaboration)</strong>等。 <a href="https://en.wikipedia.org/wiki/William_C._Mann" target="_blank" rel="external">William Mann</a> 和 <a href="https://en.wikipedia.org/wiki/Sandra_Thompson_(linguist" target="_blank" rel="external">Sandra Thompson</a>) 提出了 <strong>RST (Rhetorical Structure Theory，修辞结构理论)</strong>，可以用来解释这种关系。RST 是基于局部文本之间的关系的文本组织理论，它认为语篇(discourse)的构成具有层次关系，通过修饰结构可以表示语篇结构。RST 在<strong>文本生成(text generation)</strong>、<strong>文本摘要(text summarization)</strong> 等场景下都有应用。</p>
<p>两个概念是 <strong>核心(nucleus)</strong> 和 <strong>外围(satellite)</strong>。RST 一般将文本的中心片段称为 <strong>核心(nucleus)</strong>，文本的周边片段称为 <strong>外围(satellite)</strong>，比如说下面的段落<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">The carpenter was tired. He had been working all day.</div></pre></td></tr></table></figure></p>
<p>第二个句子详细描述了<strong>(elaborate)</strong>第一个句子，解释了 carpenter 为什么会 tired。更明显的是第二个句子以代词 He 开头，对第一个句子的依赖性很强，相对来说句子重要性更低，所以第一个句子是 Nucleus，第二个句子是 Satellite。</p>
<p><strong>Nucleus 和 Satellite 的关系</strong></p>
<ul>
<li>The satellite increases the belief in the relation described in the nucleus</li>
<li>Some relations have only a nucleus, others have two nuclei, yet others have on nucleus and one satellite</li>
</ul>
<p>再看一组 RST 关系的定义<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/RSTdef.png" class="ful-image" alt="RSTdef.png"></p>
<p>RST 是通过层级进行组合的，也就是说，我们可以采用一对相关文本作为其他高层关系的外围或者核心。和句法结构类似，这可以形成 discourse 的结构，可以看下几个例子，在下面的树里，代表一组局部连贯话段的节点被称为 discourse segment，相当于句法中的 consitute。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">S1: John went to the bank to deposit his paycheck</div><div class="line">S2: He then took a bus to Bill’s car dealership</div><div class="line">S3: He needed to buy a car</div><div class="line">S4: The company he works for now isn’t near a bus line</div><div class="line">S5: He also wanted to talk with Bill about their soccer league</div></pre></td></tr></table></figure>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/RSTeg1.png" class="ful-image" alt="RSTeg1.png">
<p>更多例子<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/RSTeg2.png" class="ful-image" alt="RSTeg2.png"></p>
<h2 id="Automatic-Coherence-Assignment"><a href="#Automatic-Coherence-Assignment" class="headerlink" title="Automatic Coherence Assignment"></a>Automatic Coherence Assignment</h2><p>给定句子/从句的序列，我们希望能自动的</p>
<ul>
<li>决定句子之间的衔接关系(<strong>coherence relation assignment</strong>)</li>
<li>抽取能够表示整个 discourse 的树/图结构(<strong>discourse parsing</strong>)</li>
</ul>
<h3 id="Use-cue-phrases-discourse-markers"><a href="#Use-cue-phrases-discourse-markers" class="headerlink" title="Use cue phrases/discourse markers"></a>Use cue phrases/discourse markers</h3><p>Automatic Coherence Assignment 是一个很难的任务，现有的一种方法是利用线索型的<strong>短语(cue phrases)</strong>，具体过程如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">John hid Bill’s car keys because he was drunk.</div><div class="line">The scarecrow came to ask for a brain. Similarly, the tin man wants a heart.</div></pre></td></tr></table></figure>
<ol>
<li><strong>Identify</strong><br>识别文本中的 cue phrases，如第一句中的 because，第二句中的 similarly</li>
<li><strong>Segment</strong><br>将文本分成 discourse segments</li>
<li><strong>Classify</strong><br>对每组相邻的 discourse segment 进行关系分类</li>
</ol>
<p><strong><a href="https://pdfs.semanticscholar.org/ba81/b31598b85259b20399e485a1ab156db5511f.pdf" target="_blank" rel="external">Marcu and Echihabi 2002</a></strong> 最早提出了关于文本结构的完全确定性的形式化模型，用无监督方法来自动识别 4 种 RST 关系(contrast, cause-explanation-evidence, condition, elaboration + non-relation)，利用 Word co-occurrence，训练了 Naive Bayes 关系分类器，取得了不错的结果，论文值得一看，是当时 discourse analysis 的一个重大突破，不过这种模型过度依赖 cue phrases，匹配模式也很简单，只能对文本进行颗粒度较粗的分析。</p>
<p>除了 <strong>cue phrases/discourse markers</strong>，还可以利用的是推理关系。</p>
<h3 id="Use-abduction-defeasible-inference"><a href="#Use-abduction-defeasible-inference" class="headerlink" title="Use abduction/defeasible inference"></a>Use abduction/defeasible inference</h3><p>基于推理的判定算法主要是通过推理来约束连贯关系。之前在<a href="http://www.shuang0420.com/2017/04/07/NLP%20笔记%20-%20Meaning%20Representation%20Languages/">NLP 笔记 - Meaning Representation Languages</a>中讲过<strong>取式推理(modus ponens)</strong>，是<strong>演绎(deduction)</strong>的规则，也是 sound inference 的一种形式，如果前提为真，结论必为真。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/modus.png" class="ful-image" alt="modus.png">
<p>然而很多 NLU 依赖的推理是不可靠的，比如说 <strong>abduction(溯因推理)</strong>，中心规则如下：</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/abduction.png" class="ful-image" alt="abduction.png">
<p>这其实相当于 Peter Lipton 说的 <strong>Inference to the Best Explanation(IBE)</strong>，从结果中找最可能的原因。比如说我们知道 All Acuras are fast.，还知道 John’s car is fast，想来解释为什么 John’s car is fast，发现最合理的理由是  John’s car is an Acura。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">All Acuras are fast.</div><div class="line">John&apos;s car is fast.</div><div class="line">Maybe John&apos;s car is an Acura.</div></pre></td></tr></table></figure>
<p>然而这可能是一个不正确的推理，John 的汽车可能是由其他制造商生产同时速度很快。一个给定的结果 $\beta$ 可能会有很多潜在的原因 $\alpha$，要找到 BE，可以采用<strong>概率模型(Charniak and Goldman, 1988; Charniak and Shimony, 1990)</strong>，或者<strong>启发式方法(Charniak and McDermott)</strong>。</p>
<p>下面看一个具体的例子，下面两个句子应该是 <strong>Explanation</strong> 的关系。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">John hid Bill&apos;s car keys. He was drunk.</div></pre></td></tr></table></figure></p>
<p><strong>推理图:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/inference.png" class="ful-image" alt="inference.png"></p>
<p>下面看一下具体的过程。首先需要<strong>关于 cohesion 本身的公理</strong>，表示要确定两个事件有连贯关系，一种可能性是假定两者是解释(explanation)关系<br>$∀ e_i, e_j \ Explanation(e_i, e_j) =&gt; CoherenceRel(e_i, e_j)$</p>
<p>然后是需要<strong>关于解释(explanation)的公理</strong>，要求第二个话段是第一个话段的原因<br>$∀ e_i, e_j \ cause(e_j, e_i) =&gt; Explanation(e_i, e_j)$</p>
<p>再然后是<strong>代表世界常识的公理</strong>，第一条，如果某人喝醉了，我们就不让他开车<br>$∀ x, y, e_i \ drunk(e_i, x) =&gt; ∃ e_j, e_k diswant(e_j, y, e_k) ∧ drive(e_k, x) ∧  cause(e_i, e_j)$</p>
<p>第二条，如果某人不想让其他人开车，那么他们就不愿意让这个人拿到他的车钥匙<br>$∀ x, y, e_j, e_k diswant(e_j, y, e_k) ∧ drive(e_k, x) =&gt; ∃ z, e_l, e_m diswant(e_l, y, e_m) ∧ have(e_m, x, z)  ∧ carkeys(z, x)  ∧  cause(e_j, e_l)$</p>
<p>第三条，如果某人不想让其他人拥有某件东西，那么他可以将东西藏起来<br>$∀ x, y, z, e_i, e_j diswant(e_l, y, e_m) ∧ have(e_m, x, z)  =&gt; ∃e_n hide(e_n, y, x, z) ∧ cause(e_l, e_n) $</p>
<p>最后一个公理，原因是可传递的<br>$∀e_i, e_j e_k cause(e_i, e_j)  ∧ cause(e_j, e_k) =&gt; cause(e_i, e_k)$</p>
<p>开始假设连贯关系是 explanation，根据公理最后能得到<br>$diswant(e_3, John, e_5) ∧ have（e_5, Bill, carkey)$<br>$diswant(e_4, John, e_6) ∧ drive（e_6, Bi)$<br>=&gt; 推测出<br>$drunk(e_2, Bill)$</p>
<p>通过 coreference 可以把 he 和 Bill 绑定，这就确立了句子的连贯。然而要注意的是，Abduction 是<strong>非可靠</strong>的推理，是<strong>可废止的(defeasible)</strong>。比如说如果紧跟上面句子的下面的句子，那么我们不得不撤销连接之前两个句子的推理连，然后用事实(藏钥匙是恶作剧的一部分)来替代。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Bill&apos;s car isn&apos;t here anyway; John was just playing a practical joke on him.</div></pre></td></tr></table></figure>
<h2 id="Discourse-Segmentation"><a href="#Discourse-Segmentation" class="headerlink" title="Discourse Segmentation"></a>Discourse Segmentation</h2><p>还有一个任务是 <strong>discourse segmentation</strong>，目标是将文本切分为一个子话题(subtopics)的线性序列，比如说</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/segmentation.png" class="ful-image" alt="segmentation.png">
<p>常用的方法是 <strong>TextTiling</strong>，通过词汇层面的共现和分布模式(lexical co-occurrence and distribution)来寻找 subtopic 的边界。它的假设是认为描述 subtopic 的词会局部共现，从一个 subtopic 到另一个 subtopic 的 switch 以一个共现词集合的结束和另一个共现词集合的开始为标志。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/TextTiling.png" class="ful-image" alt="TextTiling.png"></p>
<p><strong>步骤:</strong></p>
<ol>
<li><strong>Tokenization</strong><br>进行 tokenization 得到 ABCDE 等 term 以及以句子为单位的词汇单元(sentence-sized units)，如上图 1-8，每一列都是一个 unit</li>
<li><strong>Lexical score determination</strong><br>方法有 blocks, vocabulary introductions 和 chains<br>上图表示 blocks 方法，把 k 个句子 group 成 block (一般 K=2)，计算 block lexical score，一般就是向量內积，比如第一个 block 的 score 就是 8=2x1(for A)+1x1(for B)+2x1(for C)+1x1(for D)+1x2(for E)<br>Block 其实就相当于一个 moving window</li>
<li><strong>Boundary identification</strong><br>如果一个较低的  lexical score 前面和后面都跟着一个高的 lexical score，那么较低的 lexical score 所在的位置可能就代表了一个 shift，或者说 subtopic change</li>
</ol>
<p>更多戳论文<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1.5278&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">TextTiling: A Quantitative Approach to Discourse Segmentation</a></p>
<p>另外还有监督学习的方法，可以训练一个 binary classifier，在句子之间放个 marker，标注这是不是 discourse boundary，使用到的 feature 有<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">• Discourse markers or cue words</div><div class="line">• Word overlap before/after boundary</div><div class="line">• Number of coreference chains that cross boundary</div><div class="line">...</div></pre></td></tr></table></figure></p>
<h1 id="Context-Speech-Acts"><a href="#Context-Speech-Acts" class="headerlink" title="Context, Speech Acts"></a>Context, Speech Acts</h1><p>最后来看一下 context 和 speech acts。</p>
<h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>同一个句子在不同的情境(context)下的含义可能是不同的。需要考虑的情境：</p>
<ul>
<li>Social context<br>Social identities, relationships, and setting</li>
<li>Physical context<br>Where? What objects are present? What actions?</li>
<li>Linguistic context<br>Conversation history</li>
<li>Other forms of context<br>Shared knowledge, etc.</li>
</ul>
<h2 id="Speech-Acts"><a href="#Speech-Acts" class="headerlink" title="Speech Acts"></a>Speech Acts</h2><blockquote>
<p>A <strong>speech act</strong> in <a href="https://en.wikipedia.org/wiki/Linguistics" target="_blank" rel="external">linguistics</a> and the <a href="https://en.wikipedia.org/wiki/Philosophy_of_language" target="_blank" rel="external">philosophy of language</a> is an utterance that has <a href="https://en.wikipedia.org/wiki/Performativity" target="_blank" rel="external">performative function</a> in language and communication.</p>
</blockquote>
<p><strong>语言行为理论(Speech Acts)</strong>最初由语言哲学家 Austin 提出，后来由其学生 Searle 进一步发展。核心理论是 <strong>Sentences perform actions</strong>，说话人只要说出了有意义的，可以被听众理解的话，就可以说他实施了某个行为，这个行为就是 Speech Act。</p>
<h3 id="Austin"><a href="#Austin" class="headerlink" title="Austin"></a>Austin</h3><p><a href="http://en.wikipedia.org/wiki/J._L._Austin" target="_blank" rel="external">Austin</a> 最初把言语分为两类，<strong>言有所述(constatives)</strong>和<strong>言有所为(performatives)</strong>。判断一个句子是不是 performative 的方法是加上 <strong>hereby</strong> 来验证，如果句子依然通顺，这个句子就含有 performative verb。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">– I hereby name this ship the Queen Elizabeth.</div><div class="line">– I hereby take this man to be my husband.</div><div class="line">– I hereby bequeath this watch to my brother.</div><div class="line">– I hereby declare war.</div></pre></td></tr></table></figure></p>
<p>加上 hereby 之后，上面的句子依旧 make sense，然而下面这两个句子就不能<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">– Birds hereby sing.</div><div class="line">– There is hereby fighting in Syria.</div></pre></td></tr></table></figure></p>
<p>然而后来 Austin 发现用 hereby 来判读一个句子是不是有 performative 有点牵强，于是提出了一个新的模式，一个人说话的时候，同时实施了三种行为，<strong>言内行为(locutionary act), 言外行为(illocutionary act), 和言后行为( perlocutionary act)</strong></p>
<ul>
<li><strong>Locuion</strong>: say some words<br>通过说话表达字面意义，包括说话时所用的发出的语音、音节、单词、短语、句子</li>
<li><strong>Illocution</strong>: an action performed <em>in</em> saying words<br>​     通过字面意义表达说话人的意图，比如说发出命令<br>​  Ask, promise, command</li>
<li><strong>Perlocution</strong>: an action performed <em>by</em> saying words, probably the effect that an illocution has on the listener.<br>说话人的话语作用在听众身上所带来的效果<br>Persuade, convince, scare, elicit an answer, etc.</li>
</ul>
<h3 id="Searle"><a href="#Searle" class="headerlink" title="Searle"></a>Searle</h3><p><a href="http://en.wikipedia.org/wiki/Speech_act" target="_blank" rel="external">Searle</a>进一步说明了<strong>人类交际的基本单位不是句子或其他任何表达手段，而是完成一定的行为</strong>，并提出了言外行为的几个分类</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/searle%27s%20speech%20acts.png" class="ful-image" alt="searle%27s%20speech%20acts.png">
<p>同时提出了<strong>间接言语行为理论(indirect speech acts)</strong>，通过某一个言语行为来做另一个言外行为，比如陈述句不是陈述，祈使句不是祈使，疑问句不是疑问的情况等。<br><strong>Indirect speech acts:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">– Can you pass the salt?</div><div class="line">​	• Has the form of a *question*, but the effect of a *directive*.</div></pre></td></tr></table></figure></p>
<p><a href="http://ccl.pku.edu.cn/doubtfire/NLP/Artificial_Intelligence/Searle/%D1%D4%D3%EF%D0%D0%CE%AA%C0%ED%C2%DB%C6%C0%CA%F6.htm" target="_blank" rel="external">言语行为理论评述</a></p>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>Speech acts 的主要应用应该是对话系统，如下面是任务导向型对话系统的 speech acts 示例<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/speech_acts_eg1.png" class="ful-image" alt="speech_acts_eg1.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/speech_acts_eg2.png" class="ful-image" alt="speech_acts_eg2.png"></p>
<p>谈判的 speech acts<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Discourse%20Analysis/speech_acts_eg3.png" class="ful-image" alt="speech_acts_eg3.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CMU 11611 笔记。讲语篇分析的一些概念，包括 coreference, cohesion, speech acts 等。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Course" scheme="http://www.shuang0420.com/categories/NLP/Course/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="discourse analysis" scheme="http://www.shuang0420.com/tags/discourse-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Neo4j Cypher Cheetsheet</title>
    <link href="http://www.shuang0420.com/2017/09/11/Neo4j%20Cypher%20Cheetsheet/"/>
    <id>http://www.shuang0420.com/2017/09/11/Neo4j Cypher Cheetsheet/</id>
    <published>2017-09-11T12:40:10.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>内容主要来自 Coursera 课程 <strong>Big Data Graph Analytics</strong>，在这对 Cypher 语句做个整理，方便查阅。包括基本语句、以及路径分析、链接分析样例。<br><a id="more"></a></p>
<p>Neo4j 使用 Cypher 查询图形数据，Cypher 是描述性的图形查询语言，语法简单功能强大，由于 Neo4j 在图形数据库家族中处于绝对领先的地位，拥有众多的用户基数，Cypher 成为图形查询语言的事实上的标准。<br>和 SQL 很相似，Cypher 语言的关键字不区分大小写，但是属性值，标签，关系类型和变量是区分大小写的。</p>
<p>看一下基本的概念</p>
<ul>
<li><p><strong>变量(Variable)</strong><br>变量用于对搜索模式的部分进行命名，并在同一个查询中引用，在小括号()中命名变量，<strong>变量名是区分大小写的</strong>，示例代码创建了两个变量：n 和 b，通过 return 子句返回变量 b；</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">MATCH (n)--&gt;(b)</div><div class="line">RETURN b</div></pre></td></tr></table></figure>
</li>
<li><p><strong>访问属性(Property)</strong><br>在 Cypher 查询中，通过点来访问属性，格式是：Variable.PropertyKey，通过 id 函数来访问实体的 ID，格式是 id(Variable)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n)--&gt;(b)</div><div class="line">where id(n)=5 and b.age=18</div><div class="line">return b;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>节点(Node)</strong><br>节点模式的构成：<code>(Variable:Lable1 {Key1:Value1,Key2,Value2})</code><br>每个节点都有一个整数 ID，在创建新的节点时，Neo4j 自动为节点设置 ID 值，在整个数据库中，节点的 ID 值是递增和唯一的。<br>下面的 Cypher 查询创建一个节点，标签是 Person，具有两个属性 name 和 born，通过 RETURN 子句，返回新建的节点：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create (n:Person &#123; name: &apos;Tom Hanks&apos;, born: 1956 &#125;) return n;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>匹配(Match)</strong><br>通过match子句查询数据库，match子句用于指定搜索的模式（Pattern），where子句为match模式增加谓词（Predicate），用于对Pattern进行约束；</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match(n) return n;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>关系(Relation)</strong><br>关系的构成：<code>StartNode - [Variable:RelationshipType {Key1:Value1, Key2:Value2}] -&gt; EndNode</code><br>创建关系时，必须指定关系类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">MATCH (a:Person),(b:Movie)</div><div class="line">WHERE a.name = &apos;Robert Zemeckis&apos; AND b.title = &apos;Forrest Gump&apos;</div><div class="line">CREATE (a)-[r:DIRECTED]-&gt;(b)</div><div class="line">RETURN r;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>本篇数据集：<br><strong>链接:</strong> <a href="http://pan.baidu.com/s/1dEHWQch" target="_blank" rel="external">http://pan.baidu.com/s/1dEHWQch</a><br><strong>密码:</strong> 00v4</p>
<h1 id="Create-and-Delete"><a href="#Create-and-Delete" class="headerlink" title="Create and Delete"></a>Create and Delete</h1><p>建图要求<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">==============</div><div class="line">Five Nodes</div><div class="line">N1 = Tom</div><div class="line">N2 = Harry</div><div class="line">N3 = Julian</div><div class="line">N4 = Michele</div><div class="line">N5 = Josephine</div><div class="line"></div><div class="line">Five Edges</div><div class="line">e1 = Harry ‘is known by’ Tom</div><div class="line">e2 = Julian ‘is co-worker of’ Harry</div><div class="line">e3 = Michele ‘is wife of’ Harry</div><div class="line">e4 = Josephine ‘is wife of’ Tom</div><div class="line">e5 = Josephine ‘is friend of’ Michele</div><div class="line"></div><div class="line">==============</div><div class="line">A simple text description of a graph</div><div class="line">N1 - e1 -&gt; N2</div><div class="line">N2 - e2 -&gt; N3</div><div class="line">N2 - e3 -&gt; N4</div><div class="line">N1 - e4 -&gt; N5</div><div class="line">N4 - e5 -&gt; N5</div><div class="line">==============</div></pre></td></tr></table></figure></p>
<p>创建完整的 graph<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">create (N1:ToyNode &#123;name: &apos;Tom&apos;&#125;) - [:ToyRelation &#123;relationship: &apos;knows&apos;&#125;] -&gt; (N2:ToyNode &#123;name: &apos;Harry&apos;&#125;),</div><div class="line">(N2) - [:ToyRelation &#123;relationship: &apos;co-worker&apos;&#125;] -&gt; (N3:ToyNode &#123;name: &apos;Julian&apos;, job: &apos;plumber&apos;&#125;),</div><div class="line">(N2) - [:ToyRelation &#123;relationship: &apos;wife&apos;&#125;] -&gt; (N4:ToyNode &#123;name: &apos;Michele&apos;, job: &apos;accountant&apos;&#125;),</div><div class="line">(N1) - [:ToyRelation &#123;relationship: &apos;wife&apos;&#125;] -&gt; (N5:ToyNode &#123;name: &apos;Josephine&apos;, job: &apos;manager&apos;&#125;),</div><div class="line">(N4) - [:ToyRelation &#123;relationship: &apos;friend&apos;&#125;] -&gt; (N5)</div><div class="line">;</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/create_1.png" class="ful-image" alt="create_1.png">
<p>ToyNode is a node type and ToyRelation is an edge type. ToyNode can have properties, so can ToyRelation.</p>
<p><strong>//View the resulting graph</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n:ToyNode)-[r]-(m) return n, r, m</div></pre></td></tr></table></figure></p>
<p><strong>//Delete all nodes and edges</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n)-[r]-() delete n, r</div></pre></td></tr></table></figure></p>
<p><strong>//Delete all nodes which have no edges</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n) delete n</div></pre></td></tr></table></figure></p>
<p><strong>//Delete only ToyNode nodes which have no edges</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n:ToyNode) delete n</div></pre></td></tr></table></figure></p>
<p><strong>//Delete all edges</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n)-[r]-() delete r</div></pre></td></tr></table></figure></p>
<p><strong>//Delete only ToyRelation edges</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n)-[r:ToyRelation]-() delete r</div></pre></td></tr></table></figure></p>
<p><strong>//Selecting an existing single ToyNode node</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n:ToyNode &#123;name:&apos;Julian&apos;&#125;) return n</div></pre></td></tr></table></figure></p>
<h1 id="Adding-or-Modify"><a href="#Adding-or-Modify" class="headerlink" title="Adding or Modify"></a>Adding or Modify</h1><p>Merge 子句的作用：当模式（Pattern）存在时，匹配该模式；当模式不存在时，创建新的模式，功能是 match 子句和 create 的组合。在 merge 子句之后，可以显式指定 on create 和 on match 子句，用于修改绑定的节点或关系的属性。</p>
<p>通过 merge 子句，可以指定图形中必须存在一个节点，该节点必须具有特定的标签，属性等，如果不存在，那么 merge 子句将创建相应的节点。</p>
<p><strong>//Adding a Node Correctly</strong><br>First find a node you wanna add to, then add the node.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n:ToyNode &#123;name:&apos;Julian&apos;&#125;)</div><div class="line">merge (n)-[:ToyRelation &#123;relationship: &apos;fiancee&apos;&#125;]-&gt;(m:ToyNode &#123;name:&apos;Joyce&apos;, job:&apos;store clerk&apos;&#125;)</div></pre></td></tr></table></figure></p>
<p><strong>//Adding a Node Incorrectly</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">create (n:ToyNode &#123;name:&apos;Julian&apos;&#125;)-[:ToyRelation &#123;relationship: &apos;fiancee&apos;&#125;]-&gt;(m:ToyNode &#123;name:&apos;Joyce&apos;, job:&apos;store clerk&apos;&#125;)</div></pre></td></tr></table></figure></p>
<p><strong>//Correct your mistake by deleting the bad nodes and edge</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match (n:ToyNode &#123;name:&apos;Joyce&apos;&#125;)-[r]-(m) delete n, r, m</div></pre></td></tr></table></figure></p>
<p><strong>//Modify a Node’s Information</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n:ToyNode) where n.name = &apos;Harry&apos; set n.job = &apos;drummer&apos;</div><div class="line">match (n:ToyNode) where n.name = &apos;Harry&apos; set n.job = n.job + [&apos;lead guitarist&apos;]</div></pre></td></tr></table></figure></p>
<h1 id="Import"><a href="#Import" class="headerlink" title="Import"></a>Import</h1><p><strong>//One way to “clean the slate” in Neo4j before importing (run both lines):</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (a)-[r]-&gt;() delete a,r</div><div class="line">match (a) delete a</div></pre></td></tr></table></figure></p>
<p><strong>//Script to Import Data Set: test.csv (simple road network)</strong><br><strong>//[NOTE: replace any spaces in your path with %20, “percent twenty” ]</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">LOAD CSV WITH HEADERS FROM &quot;file:///test.csv&quot; AS line</div><div class="line">MERGE (n:MyNode &#123;Name:line.Source&#125;)</div><div class="line">MERGE (m:MyNode &#123;Name:line.Target&#125;)</div><div class="line">MERGE (n) -[:TO &#123;dist:line.distance&#125;]-&gt; (m)</div></pre></td></tr></table></figure></p>
<p><strong>//Script to import global terrorist data</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">LOAD CSV WITH HEADERS FROM &quot;file:///terrorist_data_subset.csv&quot; AS row</div><div class="line">MERGE (c:Country &#123;Name:row.Country&#125;)</div><div class="line">MERGE (a:Actor &#123;Name: row.ActorName, Aliases: row.Aliases, Type: row.ActorType&#125;)</div><div class="line">MERGE (o:Organization &#123;Name: row.AffiliationTo&#125;)</div><div class="line">MERGE (a)-[:AFFILIATED_TO &#123;Start: row.AffiliationStartDate, End: row.AffiliationEndDate&#125;]-&gt;(o)</div><div class="line">MERGE(c)&lt;-[:IS_FROM]-(a);</div></pre></td></tr></table></figure></p>
<p>When you are loading CSVs you get an error like “Couldn’t load the external resource at: file: […]”, put your csv file in the right path like <code>/Users/shuang/Documents/Neo4j/default.graphdb/import/</code>, the problem will be solved.</p>
<h1 id="Basic-Graph-Operations"><a href="#Basic-Graph-Operations" class="headerlink" title="Basic Graph Operations"></a>Basic Graph Operations</h1><p><strong>//Counting the number of nodes</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)</div><div class="line">return count(n)</div></pre></td></tr></table></figure></p>
<p><strong>//Counting the number of edges</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r]-&gt;()</div><div class="line">return count(r)</div></pre></td></tr></table></figure></p>
<p><strong>//Finding leaf nodes:</strong><br><strong>Leaf node: </strong> the node which have no outgoing edges<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r:TO]-&gt;(m)</div><div class="line">where not ((m)--&gt;())</div><div class="line">return m</div></pre></td></tr></table></figure></p>
<p><strong>//Finding root nodes:</strong><br><strong>Root node: </strong> the node which have no incoming edges<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (m)-[r:TO]-&gt;(n:MyNode)</div><div class="line">where not (()--&gt;(m))</div><div class="line">return m</div></pre></td></tr></table></figure></p>
<p><strong>//Finding triangles:</strong><br><strong>Triangle: </strong> a three cycle, consisting of three nodes and three edges where the beginning and end node are the same<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (a)-[:TO]-&gt;(b)-[:TO]-&gt;(c)-[:TO]-&gt;(a)</div><div class="line">return distinct a, b, c</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/triangle.png" class="ful-image" alt="triangle.png">
<p><strong>//Finding 2nd neighbors of D:</strong><br><strong>2nd neighbor: </strong> two nodes away from D<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (a)-[:TO*..2]-(b)</div><div class="line">where a.Name=&apos;D&apos;</div><div class="line">return distinct a, b</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/2nd_nei.png" class="ful-image" alt="2nd_nei.png">
<p>Some nodes appear to be only one node away from the node D but we can get to those nodes indirectly through another node, which means that they’re not only a first neighbor but they’re also a second neighbor.</p>
<p><strong>//Finding the types of a node:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n)</div><div class="line">where n.Name = &apos;Afghanistan&apos;</div><div class="line">return labels(n)</div></pre></td></tr></table></figure></p>
<p><strong>//Finding the label of an edge:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n &#123;Name: &apos;Afghanistan&apos;&#125;)&lt;-[r]-()</div><div class="line">return distinct type(r)</div></pre></td></tr></table></figure></p>
<p><strong>//Finding all properties of a node:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n:Actor)</div><div class="line">return * limit 20</div></pre></td></tr></table></figure></p>
<p><strong>//Finding loops:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n)-[r]-&gt;(n)</div><div class="line">return n, r limit 10</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/loops.png" class="ful-image" alt="loops.png">
<p><strong>//Finding multigraphs:</strong><br><strong>Multigraph: </strong> any two nodes which have two or more edges between them<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n)-[r1]-&gt;(m), (n)-[r2]-(m)</div><div class="line">where r1 &lt;&gt; r2</div><div class="line">return n, r1, r2, m limit 10</div></pre></td></tr></table></figure></p>
<p>remember to apply a constraint in which the edges must be different for the same pairs of nodes<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/multi_graph.png" class="ful-image" alt="multi_graph.png"></p>
<p><strong>//Finding the induced subgraph given a set of nodes:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n)-[r:TO]-(m)</div><div class="line">where n.Name in [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;] and m.Name in [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;]</div><div class="line">return n, r, m</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/induced.png" class="ful-image" alt="induced.png">
<h1 id="Path-Analytics"><a href="#Path-Analytics" class="headerlink" title="Path Analytics"></a>Path Analytics</h1><p><strong>//Viewing the graph</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r]-&gt;(m)</div><div class="line">return n, r, m</div></pre></td></tr></table></figure></p>
<p><strong>//Finding paths between specific nodes:</strong><br>Use the match command to match p which is a variable we’re using to represent our path, = node a, going through an edge to node c. There’s something slightly different about this edge, and that is that we’re using a star to represent an arbitrary number of edges in sequence between a and c, and we’ll be returning all of those edges that are necessary to complete the path. And in this case we only want to return a single path.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match p=(a)-[:TO*]-(c)</div><div class="line">where a.Name=&apos;H&apos; and c.Name=&apos;P&apos;</div><div class="line">return p limit 1</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/HP.png" class="ful-image" alt="HP.png">
<p>*Your results might not be the same as the video hands-on demo. If not, try the following query and it should return the shortest path between nodes H and P:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">match p=(a)-[:TO*]-(c) where a.Name=&apos;H&apos; and c.Name=&apos;P&apos; return p order by length(p) asc limit 1</div></pre></td></tr></table></figure></p>
<p><strong>//Finding the length between specific nodes:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match p=(a)-[:TO*]-(c)</div><div class="line">where a.Name=&apos;H&apos; and c.Name=&apos;P&apos;</div><div class="line">return length(p) limit 1</div></pre></td></tr></table></figure></p>
<p><strong>//Finding a shortest path between specific nodes:</strong><br>Use a built-in command shortestPath<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match p=shortestPath((a)-[:TO*]-(c))</div><div class="line">where a.Name=&apos;A&apos; and c.Name=&apos;P&apos;</div><div class="line">return p, length(p) limit 1</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/shortest.png" class="ful-image" alt="shortest.png">
<p><strong>//All Shortest Paths:</strong><br>Use a built-in command allShortestPaths<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">MATCH p = allShortestPaths((source)-[r:TO*]-(destination))</div><div class="line">WHERE source.Name=&apos;A&apos; AND destination.Name = &apos;P&apos;</div><div class="line">RETURN EXTRACT(n IN NODES(p)| n.Name) AS Paths</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/shortest_all.png" class="ful-image" alt="shortest_all.png">
<p><strong>//All Shortest Paths with Path Conditions:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">MATCH p = allShortestPaths((source)-[r:TO*]-&gt;(destination))</div><div class="line">WHERE source.Name=&apos;A&apos; AND destination.Name = &apos;P&apos; AND LENGTH(NODES(p)) &gt; 5</div><div class="line">RETURN EXTRACT(n IN NODES(p)| n.Name) AS Paths,length(p)</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/shortest_cond.png" class="ful-image" alt="shortest_cond.png">
<p><strong>//Diameter of the graph:</strong><br><strong>Diameter: </strong> the longest shortest path between two nodes in the graph<br>Returned in the form of an array. We’re using a new term, extract, which is based on the following. Assuming we have matched our path p, we want to identify all of the nodes in p and extract their names. And we’ll return these names as a listing, which we’ll call the variable paths. If there’s more than one shortest path, we’ll get multiple listings of node names.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode), (m:MyNode)</div><div class="line">where n &lt;&gt; m</div><div class="line">with n, m</div><div class="line">match p=shortestPath((n)-[*]-&gt;(m))</div><div class="line">return n.Name, m.Name, length(p)</div><div class="line">order by length(p) desc limit 1</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/diameter.png" class="ful-image" alt="diameter.png">
<p><strong>//Extracting and computing with node and properties:</strong><br>Returned as the variable pathLength.<br><strong>Reduce line</strong> begins by setting a variable s equal to 0. And then define a variable e, which represents the set of relationships in a path that’s returned,<br>or in other words, the edges. And we pass that into this variable s, and add to it, the value of the distance that we’ve assigned to that edge.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">match p=(a)-[:TO*]-(c)</div><div class="line">where a.Name=&apos;H&apos; and c.Name=&apos;P&apos;</div><div class="line">return extract(n in nodes(p)|n.Name) as Nodes, length(p) as pathLength,</div><div class="line">reduce(s=0, e in relationships(p)| s + toInt(e.dist)) as pathDist limit 1</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/extract.png" class="ful-image" alt="extract.png">
<p>The path itself, as we know, begins in H and ends in P. And it has a pathLength of 8, but it has a pathDist of 40.<br>So we could interpret this to mean that even though there are 7 towns between the source town and the destination town, or a pathLength of 8,<br>the actual distance in miles would be a value of 40.</p>
<p><strong>//Dijkstra’s algorithm for a specific target node:</strong><br>This is not the path in our network with the least weights. It is the weight of the shortest path based on numbers of hops.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">MATCH (from: MyNode &#123;Name:&apos;A&apos;&#125;), (to: MyNode &#123;Name:&apos;P&apos;&#125;),</div><div class="line">path = shortestPath((from)-[:TO*]-&gt;(to))</div><div class="line">WITH REDUCE(dist = 0, rel in rels(path) | dist + toInt(rel.dist)) AS distance, path</div><div class="line">RETURN path, distance</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/Dijkstra.png" class="ful-image" alt="Dijkstra.png">
<p><strong>//Dijkstra’s algorithm SSSP:</strong><br>What we’ve calculated is the shortest hop path with the weights added, the sum of the weights of the edges in that path. This is not the least weight path of the entire network.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">MATCH (from: MyNode &#123;Name:&apos;A&apos;&#125;), (to: MyNode),</div><div class="line">path = shortestPath((from)-[:TO*]-&gt;(to))</div><div class="line">WITH REDUCE(dist = 0, rel in rels(path) | dist + toInt(rel.dist)) AS distance, path, from, to</div><div class="line">RETURN from, to, path, distance order by distance desc</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/error.png" class="ful-image" alt="error.png">
<p>Problem not solved. Refer to <a href="https://github.com/neo4j/neo4j/issues/9992" target="_blank" rel="external">allshortestPaths error start/end nodes the same with cypher.forbid_shortestpath_common_node=false</a></p>
<p><strong>//Graph not containing a selected node:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n)-[r:TO]-&gt;(m)</div><div class="line">where n.Name &lt;&gt; &apos;D&apos; and m.Name &lt;&gt; &apos;D&apos;</div><div class="line">return n, r, m</div></pre></td></tr></table></figure></p>
<p><strong>//Shortest path over a Graph not containing a selected node:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match p=shortestPath((a &#123;Name: &apos;A&apos;&#125;)-[:TO*]-(b &#123;Name: &apos;P&apos;&#125;))</div><div class="line">where not(&apos;D&apos; in (extract(n in nodes(p)|n.Name)))</div><div class="line">return p, length(p)</div></pre></td></tr></table></figure></p>
<p><strong>//Graph not containing the immediate neighborhood of a specified node:</strong><br>Remember to take leaf and root node into account.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">match (d &#123;Name:&apos;D&apos;&#125;)-[:TO]-(b)</div><div class="line">with collect(distinct b.Name) as neighbors</div><div class="line">match (n)-[r:TO]-&gt;(m)</div><div class="line">where</div><div class="line">not (n.Name in (neighbors+&apos;D&apos;))</div><div class="line">and</div><div class="line">not (m.Name in (neighbors+&apos;D&apos;))</div><div class="line">return n, r, m</div><div class="line">;</div><div class="line">match (d &#123;Name:&apos;D&apos;&#125;)-[:TO]-(b)-[:TO]-&gt;(leaf)</div><div class="line">where not((leaf)--&gt;())</div><div class="line">return (leaf)</div><div class="line">;</div><div class="line">match (d &#123;Name:&apos;D&apos;&#125;)-[:TO]-(b)&lt;-[:TO]-(root)</div><div class="line">where not((root)&lt;--())</div><div class="line">return (root)</div></pre></td></tr></table></figure></p>
<p>The result for first statement.<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/no_immediate%20neighborhood.png" class="ful-image" alt="no_immediate%20neighborhood.png"></p>
<p><strong>//Graph not containing a selected neighborhood:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">match (a &#123;Name: &apos;F&apos;&#125;)-[:TO*..2]-(b)</div><div class="line">with collect(distinct b.Name) as MyList</div><div class="line">match (n)-[r:TO]-&gt;(m)</div><div class="line">where not(n.Name in MyList) and not (m.Name in MyList)</div><div class="line">return distinct n, r, m</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/no_contain.png" class="ful-image" alt="no_contain.png">
<h1 id="Connectivity-Analytics"><a href="#Connectivity-Analytics" class="headerlink" title="Connectivity Analytics"></a>Connectivity Analytics</h1><blockquote>
<p><strong>Connectivity analytics</strong> in terms of network robustness. In other words, a measure of how resistant a graph network is to being disconnected<br>Two ways of connectivity analytics: One computed the eigenvalues, and the second computed the degree distribution. For these examples, we’re going to use the second one, degree distributions.</p>
</blockquote>
<p><strong>//Viewing the graph</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r]-&gt;(m)</div><div class="line">return n, r, m</div></pre></td></tr></table></figure></p>
<p><strong>// Find the outdegree of all nodes</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r]-&gt;()</div><div class="line">return n.Name as Node, count(r) as Outdegree</div><div class="line">order by Outdegree</div><div class="line">union</div><div class="line">match (a:MyNode)-[r]-&gt;(leaf)</div><div class="line">where not((leaf)--&gt;())</div><div class="line">return leaf.Name as Node, 0 as Outdegree</div></pre></td></tr></table></figure></p>
<p><strong>// Find the indegree of all nodes</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)&lt;-[r]-()</div><div class="line">return n.Name as Node, count(r) as Indegree</div><div class="line">order by Indegree</div><div class="line">union</div><div class="line">match (a:MyNode)&lt;-[r]-(root)</div><div class="line">where not((root)&lt;--())</div><div class="line">return root.Name as Node, 0 as Indegree</div></pre></td></tr></table></figure></p>
<p><strong>// Find the degree of all nodes</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r]-()</div><div class="line">return n.Name, count(distinct r) as degree</div><div class="line">order by degree</div></pre></td></tr></table></figure></p>
<p><strong>// Find degree histogram of the graph</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r]-()</div><div class="line">with n as nodes, count(distinct r) as degree</div><div class="line">return degree, count(nodes) order by degree asc</div></pre></td></tr></table></figure></p>
<p><strong>//Save the degree of the node as a new node property</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode)-[r]-()</div><div class="line">with n, count(distinct r) as degree</div><div class="line">set n.deg = degree</div><div class="line">return n.Name, n.deg</div></pre></td></tr></table></figure></p>
<p><strong>// Construct the Adjacency Matrix of the graph</strong><br><strong>Philosophical issue：</strong><br>Every database will allow you some analytical computation and the remainder of the analytical computations must be done outside of the database. However, it is always a judicious idea to get the database to achieve an intermediate result formatted in a way that you would need for the next computation. And then, you use that intermediate result as the input to the next computation. We’ve seen that a number of computations in graph analytics start with the adjacency matrix. So we should be able to force Cypher to produce an adjacency matrix<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode), (m:MyNode)</div><div class="line">return n.Name, m.Name,</div><div class="line">case</div><div class="line">when (n)--&gt;(m) then 1</div><div class="line">else 0</div><div class="line">end as value</div></pre></td></tr></table></figure></p>
<p><strong>// Construct the Normalized Laplacian Matrix of the graph</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">match (n:MyNode), (m:MyNode)</div><div class="line">return n.Name, m.Name,</div><div class="line">case</div><div class="line">when n.Name = m.Name then 1</div><div class="line">when (n)--&gt;(m) then -1/(sqrt(toInt(n.deg))*sqrt(toInt(m.deg)))</div><div class="line">else 0</div><div class="line">end as value</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/matrix.png" class="ful-image" alt="matrix.png">
<h1 id="Scale-View"><a href="#Scale-View" class="headerlink" title="Scale View"></a>Scale View</h1><p>可以调整显示区的大小，浏览器调到 inspect 模式，在 d3 代码区域添加 scale 函数，如下。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/scale0.png" class="ful-image" alt="scale0.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Neo4j%20Cypher%20Cheetsheet/scale1.png" class="ful-image" alt="scale1.png">
<p><strong>References:</strong></p>
<blockquote>
<p><a href="https://neo4j.com/docs/cypher-refcard/current/" target="_blank" rel="external">Neo3j Cypher Refcard 3.2</a><br><a href="http://www.ttlsa.com/nosql/how-to-neo4j-cypher-query-language/" target="_blank" rel="external">Neo4j Cypher查询语言详解</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;内容主要来自 Coursera 课程 &lt;strong&gt;Big Data Graph Analytics&lt;/strong&gt;，在这对 Cypher 语句做个整理，方便查阅。包括基本语句、以及路径分析、链接分析样例。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Knowledge Graph" scheme="http://www.shuang0420.com/categories/NLP/Knowledge-Graph/"/>
    
    
      <category term="Knowledge Graph" scheme="http://www.shuang0420.com/tags/Knowledge-Graph/"/>
    
      <category term="知识库" scheme="http://www.shuang0420.com/tags/%E7%9F%A5%E8%AF%86%E5%BA%93/"/>
    
      <category term="Neo4j" scheme="http://www.shuang0420.com/tags/Neo4j/"/>
    
  </entry>
  
  <entry>
    <title>项目实战--知识图谱初探</title>
    <link href="http://www.shuang0420.com/2017/09/05/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/"/>
    <id>http://www.shuang0420.com/2017/09/05/项目实战-知识图谱初探/</id>
    <published>2017-09-05T12:40:10.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>实践了下怎么建一个简单的知识图谱，两个版本，一个从 0 开始(start from scratch)，一个在 CN-DBpedia 基础上补充，把 MySQL，PostgreSQL，Neo4j 数据库都尝试了下。自己跌跌撞撞摸索可能踩坑了都不知道，欢迎讨论。<br><a id="more"></a></p>
<h1 id="CN-DBpedia-构建流程"><a href="#CN-DBpedia-构建流程" class="headerlink" title="CN-DBpedia 构建流程"></a>CN-DBpedia 构建流程</h1><p>知识库可以分为两种类型，一种是以 Freebase，Yago2 为代表的 Curated KBs，主要从维基百科和 WordNet 等知识库中抽取大量的实体及实体关系，像是一种结构化的维基百科。另一种是以 Stanford OpenIE，和我们学校 Never-Ending Language Learning (NELL) 为代表的 Extracted KBs，直接从上亿个非结构化网页中抽取实体关系三元组。与 Freebase 相比，这样得到的知识更加<strong>多样性</strong>，但同时精确度要低于 Curated KBs，因为实体关系和实体更多的是<strong>自然语言</strong>的形式，如“奥巴马出生在火奴鲁鲁。” 可以被表示为（“Obama”, “was also born in”, “ Honolulu”），</p>
<p>下面以 CN-DBpedia 为例看下知识图谱大致是怎么构建的。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/CN_DBpedia%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B.png" class="ful-image" alt="CN_DBpedia%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/CN_DBpedia.png" class="ful-image" alt="CN_DBpedia.png"></p>
<p>上图分别是 CN-DBpedia 的构建流程和系统架构。知识图谱的构建是一个浩大的工程，从大方面来讲，分为<strong>知识获取、知识融合、知识验证、知识计算和应用</strong>几个部分，也就是上面架构图从下往上走的一个流程，简单来走一下这个流程。</p>
<h2 id="数据支持层"><a href="#数据支持层" class="headerlink" title="数据支持层"></a>数据支持层</h2><p>最底下是知识获取及存储，或者说是<strong>数据支持层</strong>，首先从不同来源、不同结构的数据中<strong>获取</strong>知识，CN-DBpedia 的知识来源主要是通过爬取各种百科知识这类半结构化数据。</p>
<p>至于<strong>数据存储</strong>，要考虑的是选什么样的数据库以及怎么设计 schema。选<strong>关系数据库</strong>还是<strong>NoSQL 数据库</strong>？要不要用<strong>内存数据库</strong>？要不要用<strong>图数据库</strong>？这些都需要根据数据场景慎重选择。CN-DBpedia 实际上是基于 mongo 数据库，参与开发的谢晨昊提到，一般只有在基于特定领域才可能会用到图数据库，就知识图谱而言，基于 json(bson) 的 mongo 就足够了。用到图查询的领域如征信，一般是需要要找两个公司之间的关联交易，会用到最短路径/社区计算等。</p>
<p>schema 的重要性不用多说，高质量、标准化的 schema 能有效降低领域数据之间对接的成本。我们希望达到的效果是，对于任何数据，进入知识图谱后后续流程都是相同的。换言之，对于不同格式、不同来源、不同内容的数据，在接入知识图谱时都会按照预定义的 schema 对数据进行转换和清洗，无缝使用已有元数据和资源。</p>
<h2 id="知识融合层"><a href="#知识融合层" class="headerlink" title="知识融合层"></a>知识融合层</h2><p>我们知道，目前分布在互联网上的知识常常以<strong>分散、异构、自治</strong>的形式存在，另外还具有<strong>冗余、噪音、不确定、非完备</strong>的特点，清洗并不能解决这些问题，因此从这些知识出发，通常需要<strong>融合</strong>和<strong>验证</strong>的步骤，来将不同源不同结构的数据融合成统一的知识图谱，以保证知识的一致性。所以数据支持层往上一层实际上是融合层，主要工作是对获取的数据进行标注、抽取，得到大量的三元组，并对这些三元组进行融合，去冗余、去冲突、规范化，</p>
<p>第一部分 SPO <strong>三元组抽取</strong>，对不同种类的数据用不同的技术提取</p>
<ul>
<li>从结构化数据库中获取知识：D2R<br>难点：复杂表数据的处理</li>
<li>从链接数据中获取知识：图映射<br>难点：数据对齐</li>
<li>从半结构化（网站）数据中获取知识：使用包装器<br>难点：方便的包装器定义方法，包装器自动生成、更新与维护</li>
<li>从文本中获取知识：信息抽取<br>难点：结果的准确率与覆盖率</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/%E7%9F%A5%E8%AF%86%E8%8E%B7%E5%8F%96.png" class="ful-image" alt="%E7%9F%A5%E8%AF%86%E8%8E%B7%E5%8F%96.png">
<p>尤其是纯文本数据会涉及到的 <strong>实体识别、实体链接、实体关系识别、概念抽取</strong> 等，需要用到许多自然语言处理的技术，包括但不仅限于分词、词性标注、分布式语义表达、篇章潜在主题分析、同义词构建、语义解析、依存句法、语义角色标注、语义相似度计算等等。</p>
<p>第二部分才到融合，目的是将不同数据源获取的知识进行融合构建数据之间的关联。包括 <strong>实体对齐、属性对齐、冲突消解、规范化</strong> 等，这一部分很多都是 dirty work，更多的是做一个数据的映射、实体的匹配，可能还会涉及的是本体的构建和融合。最后融合而成的知识库存入上一部分提到的数据库中。如有必要，也需要如 Spark 等大数据平台提供高性能计算能力，支持快速运算。</p>
<p>知识融合的四个难点：</p>
<ul>
<li>实现不同来源、不同形态数据的融合</li>
<li>海量数据的高效融合</li>
<li>新增知识的实时融合</li>
<li>多语言的融合</li>
</ul>
<h2 id="知识验证"><a href="#知识验证" class="headerlink" title="知识验证"></a>知识验证</h2><p>再往上一层主要是<strong>验证</strong>，分为<strong>补全、纠错、外链、更新</strong>各部分，确保知识图谱的<strong>一致性和准确性</strong>。一个典型问题是，知识图谱的构建不是一个静态的过程，当引入新知识时，需要判断新知识是否正确，与已有知识是否一致，如果新知识与旧知识间有冲突，那么要判断是原有的知识错了，还是新的知识不靠谱？这里可以用到的证据可以是<strong>权威度、冗余度、多样性、一致性</strong>等。如果新知识是正确的，那么要进行相关实体和关系的更新。</p>
<h2 id="知识计算和应用"><a href="#知识计算和应用" class="headerlink" title="知识计算和应用"></a>知识计算和应用</h2><p>这一部分主要是基于知识图谱计算功能以及知识图谱的应用。<strong>知识计算</strong>主要是根据图谱提供的信息得到更多隐含的知识，像是通过<strong>本体或者规则推理</strong>技术可以获取数据中存在的隐含知识；通过<strong>链接预测</strong>预测实体间隐含的关系；通过<strong>社区计算</strong>在知识网络上计算获取知识图谱上存在的社区，提供知识间关联的路径……通过知识计算知识图谱可以产生大量的智能应用如专家系统、推荐系统、语义搜索、问答等。</p>
<p>知识图谱涉及到的技术非常多，每一项技术都需要专门去研究，而且已经有很多的研究成果。Anyway 这章不是来论述知识图谱的具体技术，而是讲怎么做一个 hello world 式的行业知识图谱。这里讲两个小 demo，一个是 <strong>爬虫+mysql+d3</strong> 的小型知识图谱，另一个是 <strong>基于 CN-DBpedia+爬虫+PostgreSQL+d3</strong> 的”增量型”知识图谱，要实现的是某行业上市公司与其高管之间的关系图谱。</p>
<h1 id="Start-from-scratch"><a href="#Start-from-scratch" class="headerlink" title="Start from scratch"></a>Start from scratch</h1><h2 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h2><p>第一个重要问题是，我们需要什么样的知识？需要爬什么样的数据？一般在数据获取之前会先做个<strong>知识建模</strong>，建立知识图谱的数据模式，可以采用两种方法：一种是<strong>自顶向下</strong>的方法，专家手工编辑形成数据模式；另一种是<strong>自底向上</strong>的方法，基于行业现有的标准进行转换或者从现有的高质量行业数据源中进行映射。数据建模都过程很重要，因为标准化的 schema 能有效降低领域数据之间对接的成本。</p>
<p>作为一个简单的 demo，我们只做上市公司和高管之间的关系图谱，企业信息就用公司注册的基本信息，高管信息就用基本的姓名、出生年、性别、学历这些。然后开始写爬虫，爬虫看着简单，实际有很多的技巧，怎么做优先级调度，怎么并行，怎么屏蔽规避，怎么在遵守互联网协议的基础上最大化爬取的效率，有很多小的 trick，之前博客里也说了很多，就不展开了，要注意的一点是，<strong>高质量的数据来源是成功的一半！</strong></p>
<p>来扯一扯爬取建议：</p>
<ul>
<li>从数据质量来看，优先考虑权威的、稳定的、数据格式规整且前后一致、数据完整的网页</li>
<li>从爬取成本来看，优先考虑免登录、免验证码、无访问限制的页面</li>
<li>爬下来的数据务必<strong>保存好爬取时间、爬取来源(source)或网页地址(url)</strong><br>source 可以是新浪财经这类的简单标识，url 则是网页地址，这些在后续数据清洗以及之后的纠错(权威度计算)、外链和更新中非常重要</li>
</ul>
<p>企业信息可以在天眼查、启信宝、企查查各种网站查到，信息还蛮全的，不过有访问限制，需要注册登录，还有验证码的环节，当然可以过五关斩六将爬到我们要的数据，然而没这个必要，换别个网站就好。</p>
<p>推荐两个数据来源：</p>
<ul>
<li><a href="http://data.cfi.cn/cfidata.aspx" target="_blank" rel="external">中财网数据引擎</a></li>
<li><a href="http://www.cninfo.com.cn/cninfo-new/index" target="_blank" rel="external">巨潮资讯</a></li>
</ul>
<p>其中巨潮资讯还可以同时爬取高管以及公告信息。看一下数据<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/cfi.png" class="ful-image" alt="cfi.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/cninfo.png" class="ful-image" alt="cninfo.png"></p>
<p>换句话说，我们直接能得到规范的<strong>实体(公司、人)</strong>，以及规范的<strong>关系(高管)</strong>，当然也可以把高管展开，用下一层关系，董事长、监事之类，这就需要做进一步的清洗，也可能需要做关系的对齐。</p>
<p>这里爬虫框架我用的是 scrapy+redis 分布式，每天可以定时爬取，爬下来的数据写好自动化清洗脚本，定时入库。</p>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>数据存储是非常重要的一环，第一个问题是选什么数据库，这里作为 starter，用的是关系型数据库 MySQL。设计了四张表，两张实体表分别存<strong>公司(company)</strong>和<strong>人物(person)</strong>的信息，一张关系表存公司和高管的<strong>对应关系(management)</strong>，最后一张 SPO 表存<strong>三元组</strong>。</p>
<p><strong>为什么爬下来两张表，存储却要用 4 张表？</strong><br>一个考虑是知识图谱里典型的<strong>一词多义</strong>问题，相同实体名但有可能指向不同的意义，比如说 Paris 既可以表示巴黎，也可以表示人名，怎么办？让作为地名的 “Paris” 和作为人的 “Paris” 有各自独一无二的ID。“Paris1”（巴黎）通过一种内在关系与埃菲尔铁塔相联，而 “Paris2”（人）通过取消关系与各种真人秀相联。这里也是一样的场景，同名同姓不同人，需要用 id 做唯一性标识，也就是说我们需要对原来的数据格式做一个转换，不同的张三要标识成张三1，张三2… 那么，用什么来区别人呢？拍脑袋想用姓名、生日、性别来定义一个人，也就是说我们需要一张人物表，需要 (name, birth, sex) 来作<strong>composite unique key</strong> 表示每个人。公司也是相同的道理，不过这里只有上市公司，股票代码就可以作为唯一性标识。</p>
<p>Person 表和 company 表是多对多的关系，这里需要做 normalization，用 management 这张表来把多对多转化为两个一对多的关系，(person_id, company_id) 就表示了这种映射。management 和 spo 表都表示了这种映射，为什么用两张表呢？是出于实体对齐的考虑。management 保存了原始的关系，”董事”、监事”等，而 spo 把这些关系都映射成”高管”，也就是说 management 可能需要通过映射才能得到 SPO 表，SPO 才是最终成型的表。</p>
<p>可能有更简单的方法来处理上述问题，思考中，待更新—-</p>
<p>我们知道知识库里的关系其实有两种，一种是<strong>属性(property)</strong>，一种是<strong>关系(relation)</strong>。那么还有一个问题是 <strong>SPO 需不需要存储属性？</strong><br>最初的想法是实体归实体，属性归属性，SPO 只存实体间的关系，属性由实体表检索得到，然而这样的话需要多表 JOIN，属性增加时扩展性也很差。因此把属性也存到 SPO 表中。在 SPO 表中多加一列 type，来区分这关系是实体间关系还是实体与属性的关系，便于之后的可视化。<img src="spo.png" alt=""></p>
<p>最后要注意的一点是，每条记录要保存创建时间以及最后更新时间，做一个简单的版本控制。</p>
<h2 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h2><p>Flask 做 server，d3 做可视化，可以检索公司名/人名获取相应的图谱，如下图。之后会试着更新有向图版本。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/eg.png" class="ful-image" alt="eg.png"></p>
<h1 id="Start-from-CN-DBpedia"><a href="#Start-from-CN-DBpedia" class="headerlink" title="Start from CN-DBpedia"></a>Start from CN-DBpedia</h1><p>把 CN-DBpedia 的三元组数据，大概 6500 万条，导入数据库，这里尝试了 PostgreSQL。然后检索了 112 家上市公司的注册公司名称，只有 69 家公司返回了结果，属性、关系都不是很完善，说明了通用知识图谱有其不完整性(也有可能需要先做一次 mention2entity，可能它的标准实体并不是注册信息的公司名称，不过 API 小范围试了下很多是 Unknown Mention)。</p>
<p>做法也很简单，把前面 <strong>Start from scratch</strong> 中得到的 SPO 表插入到这里的 SPO 表就好了。这么简单？因为这个场景下不用做实体对齐和关系对齐。</p>
<h1 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h1><p>这只是个 hello world 项目，在此基础上可以进行很多有趣的拓展，最相近的比如说加入企业和股东的关系，可以进行<strong>企业最终控制人查询</strong>(e.g.,基于股权投资关系寻找持股比例最大的股东，最终追溯至自然人或国有资产管理部门)。再往后可以做企业社交图谱查询、企业与企业的路径发现、企业风险评估、反欺诈等等等等。具体来说：</p>
<ol>
<li>重新设计数据模型 引入”概念”，形成可动态变化的“概念—实体—属性—关系”数据模型，实现各类数据的统一建模</li>
<li>扩展多源、异构数据，结合实体抽取、关系抽取等技术，填充数据模型</li>
<li>展开知识融合(实体链接、关系链接、冲突消解等)、验证工作(纠错、更新等)</li>
</ol>
<p>最后补充一下用 Neo4j 方式产生的可视化图，有两种方法。一是把上面说到的 MySQL/PostgreSQL 里的 company 表和 person 表存成 node，node 之间的关系由 spo 表中 type == relation 的 record 中产生；二是更直接的，从 spo 表中，遇到 type == property 就给 node(subject) 增加属性({predicate:object})，遇到 type == relation 就给 node 增加关系((Nsubject) - [r:predicate]-&gt; node(Nobject))，得到下面的图，移动鼠标到相应位置就可以在下方查看到关系和节点的属性。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%88%9D%E6%8E%A2/show2.png" class="ful-image" alt="show2.png">
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;实践了下怎么建一个简单的知识图谱，两个版本，一个从 0 开始(start from scratch)，一个在 CN-DBpedia 基础上补充，把 MySQL，PostgreSQL，Neo4j 数据库都尝试了下。自己跌跌撞撞摸索可能踩坑了都不知道，欢迎讨论。&lt;br&gt;
    
    </summary>
    
      <category term="Projects" scheme="http://www.shuang0420.com/categories/Projects/"/>
    
    
      <category term="Knowledge Graph" scheme="http://www.shuang0420.com/tags/Knowledge-Graph/"/>
    
      <category term="知识库" scheme="http://www.shuang0420.com/tags/%E7%9F%A5%E8%AF%86%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>神经网络-过拟合(Andrew Ng. DL 笔记)</title>
    <link href="http://www.shuang0420.com/2017/08/29/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88(Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0)/"/>
    <id>http://www.shuang0420.com/2017/08/29/神经网络-过拟合(Andrew Ng. DL 笔记)/</id>
    <published>2017-08-29T04:20:02.000Z</published>
    <updated>2017-10-11T13:35:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>Andrew Ng. Deep Learning Course 2 Improving Deep Neural Networks 过拟合部分的笔记。<br><a id="more"></a></p>
<p><strong>高方差(high variance)</strong> 对应的问题就是 <strong>过拟合(overfitting)</strong>，模型在训练集上表现的非常完美，然而开发集和测试集却有很高的错误率。这时需要引入正则或者多加些数据来调优。这一篇就来讲过拟合的处理方法。方差/偏差的解释戳<a href="http://www.shuang0420.com/2017/03/17/会议笔记%20-%20Nuts%20and%20Bolts%20of%20Applying%20Deep%20Learning/">会议笔记 - Nuts and Bolts of Applying Deep Learning</a></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/overfit.jpg" class="ful-image" alt="overfit.jpg">
<h1 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h1><p><strong>正则化(Regularization)</strong> 是最常见的方法之一。在深度学习中的正则化中，我们保留所有的 unit，但是会压缩其权重。</p>
<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><p>对损失函数加上一个正则化参数，一般形式<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/regu1.png" class="ful-image" alt="regu1.png"></p>
<p>其中 $\Omega(\theta)$ 是参数范数惩罚，$\alpha \in [0,+\infty)$ 是参数范数惩罚程度的超参数，$\alpha=0$ 代表没有正则化，$\alpha$ 越大正则化惩罚越大。</p>
<p> $\Omega(\theta)$ 有 L1 和 L2 范式，如果用 L1，W 最终会是稀疏的，也就是说 W 中会有很多 0；L2 参数正则化通常被称为<strong>权重衰减(weight decay)</strong>，实际过程中一般用的是 L2。</p>
<p>$L1: \ \ \ \ \Omega(\theta)=||w||_1$<br>$L2: \ \ \ \ \Omega(\theta)={1 \over 2}||w||^2_2$</p>
<p>在原来的损失函数基础上加上正则因子：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/l2_fw.jpg" class="ful-image" alt="l2_fw.jpg"></p>
<p>权重更新：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/l2_bp.jpg" class="ful-image" alt="l2_bp.jpg"></p>
<p>$min_{w^{[1]},b{[1]},…w^{[L]},b{[L]},  }J(w,b)={1 \over m}\sum^m_{i=1}L(\hat y_{(i)}, y^{(i)}) + {\lambda \over 2m}\sum^L_{l=1}||w||^2_2$</p>
<p>发现加入 L2 后，每次梯度更新前权重会先乘以 $1-\alpha {\lambda \over m} $，相当于收缩了权重，因此 L2 正则也叫权重衰减(weight decay)。</p>
<p>这里的正则化参数$\lambda$通常使用 dev_set 来配置。</p>
<h2 id="Why-regularization"><a href="#Why-regularization" class="headerlink" title="Why regularization"></a>Why regularization</h2><p>一个直观上的理解是如果 $\lambda$ 足够大，由上一部分的计算可以得出 W 接近于 0，也就是说很多 hidden units 的权重被降成了 0，这就消除了很多 hidden units 的影响，实际上就是从下面右图的结构转换到了左图。当然事实上并不能说消除了这些 hidden units 的影响，只能说是减少，网络变得更简单罢了。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/why%20reg1.png" class="ful-image" alt="why%20reg1.png">
<p>从另一个角度考虑，$\lambda$ 变大 =&gt; $W^{[l]}$ 变小 =&gt; z 变小，看一下激活函数，以 tanh 为例，在 z 小的部分，曲线趋于线性，计算接近线性函数的值。如果每一层都是线性的话，那么无论网络有多少层，输出都是输入的线性组合而已，当然就不会过拟合啦。所以说在需要做复杂的决策的时候，$\lambda$ 不能设太大。另外使用 L2 正则需要搜索合适的 $\lambda$，花费很大。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/why%20reg2.png" class="ful-image" alt="why%20reg2.png">
<h1 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h1><p>另一种方法是 Dropout，随机删除一些 unit。Dropout 会遍历网络每一层，设置消除网络中节点的概率，对待删除的节点，删除从该节点进出的连线，得到一个节点更少、规模更小的网络，然后用 BP 对这个新的小的网络训练，持续这个过程。因为丢弃的神经元在训练阶段对 BP 算法的前向和后向阶段都没有贡献，所以每一次训练都像是在训练一个新的网络。</p>
<p>这里要讲的是 <strong>Inverted dropout</strong>，看下代码，keep_prob 表示保留任意一个 hidden unit 的概率，清除任意一个 hidden unit 的概率是 1-keep_prob，在网络第三层，过程如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_prob</div><div class="line">a3 = np.multiply(a3, d3)</div><div class="line">a3 /= keep_prob</div></pre></td></tr></table></figure>
<p>没有第三行就只是普通的 <strong>dropout</strong>，在这种情况下，测试阶段我们必须关闭 dropout 模式，去模拟训练阶段的集成网络模型，因为我们不希望最后结果是随机的，不希望预测结果受到干扰。而加了第三行就变成了 <strong>inverted dropout</strong>，我们只要在训练阶段缩放激活函数的输出值，而不用在测试阶段改变什么(只用修改一个参数)。举个例子，第三层有 50 个 units，keep_prob=0.8，有 10% 的 units 被消除了，那么在下一层，$z^{[4]}=w^{[4]}*a^{[3]}+b^{[4]}$，$a^{[3]}$ 的大小减少了 20%，为了让 $a^{[3]}$ 的期望值不变，需要补上这 20%，所以 $w^{[4]}*a^{[3]}/0.8$。</p>
<h2 id="Why-dropout"><a href="#Why-dropout" class="headerlink" title="Why dropout"></a>Why dropout</h2><p>很直接的思路，每次迭代网络都变小了，自然就减少了过拟合的可能。另一种解释是，dropout 使得神经网络不能依靠任何一个特征，因为每个特征都有可能被随机清除，这样的将结果是网络不会给一个 unit 特别大的权重，而是会 spread out weight，给每个 unit 都增加一点权重。而分散所有权重其实就产生了和 L2 类似的压缩权重的效果。</p>
<p>相对于 L2 正则，dropout 可以处理多样化的输入，然而 dropout 方法不会阻止参数过大，参数之间也不会互相牵制，所以有时需要配合使用 L2 或者其他正则化来改变这个情况。</p>
<p>另外提到的一个技巧是，可以对不同层设置不同的 keep_prob。如下图，第一层 W 矩阵是 3x7，过拟合的可能性小一些，可以留下 70% 的 unit，第二层是 7x7，更可能过拟合，所以少保留一些，设 keep_prob=0.5，由此类推，给每一层设定不同的 keep_prob，对不需要担心过拟合的层，直接设为 1。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/why_dropout1.png" class="ful-image" alt="why_dropout1.png">
<p>还有要注意的是，dropout 开启的情况下损失函数不再是定义良好的，也就没法根据损失函数的效果图来 debug，所以一般在看代码有没有 bug 的时候先会关闭 dropout。</p>
<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><ul>
<li><strong>Data Augmentation</strong><br>解决过拟合的另一个思路是使用更多的数据，所以当数据量不够的时候，会进行数据增强。<ul>
<li>数据集的各种变换，如对图像的平移、旋转、缩放、裁剪、扭曲变形。</li>
<li>在输入层注入噪声，如去噪自编码器，通过将随机噪声添加到输入再进行训练能够大大改善神经网络的健壮性。</li>
</ul>
</li>
<li><strong>Early Stopping</strong><br>同时画出 train error 和 dev error，会发现 dev error 先下降然后到某个点会上升，所以在迭代到某次觉得结果不错的时候，提前停止训练。<br>w 在最开始的时候值很小，到后面的时候会很大，在中间的时候可能得到一个中等大小的 Frobenius norm，和 L2 正则相似，我们要选择 W 范数较小的神经网络。找 small, large, middle 几个点，不用像 L2 正则那样尝试很多的 $\lambda$ 参数，这时 early stopping 的优势，然而过早的停止可能对损失函数 J 的优化不到位，loss 不够小。<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E8%BF%87%E6%8B%9F%E5%90%88%28Andrew%20Ng.%20DL%20%E7%AC%94%E8%AE%B0%29/early_stop.jpg" class="ful-image" alt="early_stop.jpg">
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Andrew Ng. Deep Learning Course 2 Improving Deep Neural Networks 过拟合部分的笔记。&lt;br&gt;
    
    </summary>
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/categories/Deep-learning/"/>
    
      <category term="General" scheme="http://www.shuang0420.com/categories/Deep-learning/General/"/>
    
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/tags/Deep-learning/"/>
    
      <category term="过拟合" scheme="http://www.shuang0420.com/tags/%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    
      <category term="overfitting" scheme="http://www.shuang0420.com/tags/overfitting/"/>
    
  </entry>
  
  <entry>
    <title>EMNLP 2017 北京论文报告会笔记</title>
    <link href="http://www.shuang0420.com/2017/08/21/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.shuang0420.com/2017/08/21/EMNLP 2017 北京论文报告会笔记/</id>
    <published>2017-08-21T13:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>16 号在北京举办的，邀请了国内部分被录用论文的作者来报告研究成果，整场报告会分为<strong>文本摘要及情感分析、机器翻译、信息抽取及自动问答、文本分析及表示学习</strong>四个部分。感觉上次的 <a href="http://www.shuang0420.com/2017/07/15/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/">CCF-GAIR 参会笔记</a> 写的像流水账，这次换一种方式做笔记。<br><a id="more"></a></p>
<p>分为四个部分，并没有包含分享的所有论文。第一部分写我最喜欢的论文，第二部分总结一些以模型融合为主要方法的论文，第三部分总结一些对模型组件进行微调的论文，第四部分是类似旧瓶装新酒的 idea。</p>
<h1 id="I-like"><a href="#I-like" class="headerlink" title="I like"></a>I like</h1><h2 id="Multimodal-Summarization-for-Asynchronous-Collection-of-Text-Image-Audio-and-Video"><a href="#Multimodal-Summarization-for-Asynchronous-Collection-of-Text-Image-Audio-and-Video" class="headerlink" title="Multimodal Summarization for Asynchronous Collection of Text, Image, Audio and Video"></a>Multimodal Summarization for Asynchronous Collection of Text, Image, Audio and Video</h2><p>异步的文本、图像、音视频多模态摘要，一般的文本摘要关注的是 <strong>salience, non-redundancy</strong>，这里关注的是 <strong>readability, visual information</strong>，visual information 这里说的就是图片信息，暗示事件的 highlights。考虑一个视频新闻，本身有视觉模态和音频模态，通过 ASR，还可以产生文本模态，问题是<strong>如何将这些模态连接起来，产生一个附带精彩图片的文本摘要呢？</strong> 这篇论文就在讨论这个问题，整个模型<strong>输入</strong>是一个主题的文本以及视频，<strong>输出</strong>是一段附图片的文本摘要。</p>
<p><strong>1. 预处理：</strong><br><strong>视频产生图片：</strong>CV 基本思路，把 Video 切成一个个的 shots(镜头/段落)，每个镜头可以 group(组合) 成一个 story(scene)，每一个镜头还可以细分成 sub-shots，每个 sub-shot 可以用 key-frame 来表示，<strong>选择关键帧作为视觉信息</strong>，同时认为<strong>长镜头的图片相对于短镜头更重要</strong>，基于此对图片重要性进行打分。<br><strong>音频产生文字</strong>：ASR。一方面语音识别结果并不十分准确，另一方面音频模态会有一些音频信号可以暗示我们哪些内容是重要的，基于这两点会产生两个指导策略，稍后提到。</p>
<p><strong>2. 文本重要性打分：</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/multimodal_salient.png" class="ful-image" alt="multimodal_salient.png"><br>用 <strong>LexRank</strong>，句子是点，连线是重要性，进行随机游走，针对音频产生文字的两个特性使用两个<strong>指导策略:</strong></p>
<ul>
<li>如果语音识别结果和文本句子语义相同，那么让语音识别结果来推荐文本，反之不然；</li>
<li>如果语音信号比较明显，语音推荐文本，反之不然；</li>
</ul>
<p>这两条指导策略会提升<strong>文本可读性</strong>。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/multimodal_guidance.png" class="ful-image" alt="multimodal_guidance.png"></p>
<p><strong>3. 图文匹配问题：</strong><br>希望摘要能覆盖视觉信息，能解释图片，所以需要做一个文本图片分类器。图像 vcr 解码接两层前向网络，文本做一个高斯分布再求 fisher rank，也是接两层前向网络，最终将两个文本映射到同一个语义空间，计算匹配度。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/visual_match.png" class="ful-image" alt="visual_match.png"></p>
<p>一个问题是<strong>如何在复杂的句子里提出子句</strong>，作者提出了基于传统<strong>语义角色标注</strong>的方法，利用中心谓词提取匹配的 frame 信息(predicate, argument1, argument2)，好处是可以抽取语义相对独立的部分，还可以通过 frame 的设定(只取施、受、谓词)过滤如时间等图片很难反映的信息。</p>
<p><strong>4. 目标函数：</strong><br>提到了三个目标函数：</p>
<ol>
<li><strong>针对文本：</strong>对文本重要性奖励、冗余性惩罚</li>
<li><strong>针对视觉：</strong>图片重要性(镜头时长)，是否被文本摘要覆盖(是否有匹配)</li>
<li><strong>平衡</strong>视觉信息和文本信息</li>
</ol>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/multimodal_loss_f.png" class="ful-image" alt="multimodal_loss_f.png">
<p>下面一篇 <strong>Affinity-Preserving Random Walk for Multi-Document Summarization</strong> 多文档摘要也用到了图排序模型，这里略过。</p>
<h2 id="Reasoning-with-Heterogeneous-Knowledge-for-Commonsense-Machine-Comprehension"><a href="#Reasoning-with-Heterogeneous-Knowledge-for-Commonsense-Machine-Comprehension" class="headerlink" title="Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension"></a>Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension</h2><p>聚焦两个问题：<strong>如何去获取并且表示常识知识？并且如何应用获取到的常识知识进行推理？</strong> 论文尝试从多个不同来源的异构知识库当中获取了相关的信息，并将这些知识统一表示成了带有推理代价的推理规则的形式，采用一个基于注意力机制的多知识推理模型，综合考虑上述所有的知识完成推理任务。</p>
<p><strong>任务类型：</strong> 在 RocStories 数据集上，在给定一个故事的前 4 句话的情况下，要求系统从两个候选句子当中选出一个作为故事的结尾。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_story.png" class="ful-image" alt="kb_story.png"></p>
<p><strong>推理规则：</strong>统一将知识表示成如下的推理规则的形式，在<strong>关系 f</strong> 下，<strong>元素 Y</strong> 可以由<strong>元素 X</strong> 推出，其<strong>推理代价</strong>是 <strong>s</strong>。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_rule.png" class="ful-image" alt="kb_rule.png"></p>
<h3 id="知识获取"><a href="#知识获取" class="headerlink" title="知识获取"></a>知识获取</h3><p>主要从不同来源获取三类知识，包括：</p>
<ul>
<li><strong>事件序列知识(Event Narrative Knowledge)</strong><br>捕捉事件之间的时间、因果关系(去了餐馆 -&gt; 要点餐)<br>采用两个模型来捕捉这个信息，一种是<strong>基于有序的 PMI 模型</strong>，另外一个<strong>基于Skip-Gram的向量化表示模型</strong>，本质都是基于事件对在文本当中的<strong>有序共现的频繁程度</strong>来计算推理规则的代价的。</li>
<li><strong>实体的语义知识(Entity semantic knowledge)</strong><br>捕捉实体之间的语义关系<br>以星巴克为例，捕捉的第一种关系是<strong>实体间的共指关系(coreference)</strong>，比如说用“咖啡屋”来指代星巴克。从 <u>Wordnet</u> 来获取实体间上下位关系的知识。cost 是 1 当且仅当 X 和 Y 是同义词或者有上下位关系<br>​ 第二种关系是<strong>相关关系(associative)</strong>，比如说出现星巴克时可能会出现“拿铁咖啡”这一类与之相关的实体。通过 <u>Wikipedia</u> 中实体页面的链接关系来得到实体间的相关关系知识，Cost 是<strong>两个实体间的距离</strong>(Milne and Witten(2008).)</li>
<li><strong>情感的一致性知识(Sentiment coherent knowledge)</strong><br>捕捉元素间的情感关系<br>故事的结尾和故事的整体的情感应该基本上保持一致，否则结尾就会显得太突兀，那么这样的结尾就不是一个好的结尾。从 <u>SentiWordnet</u> 上来获得这种不同元素之间的情感一致性的知识。cost 为 1 if both subjective and have opposite sentimental polarity; 为 -1 if both subjective and have same sentimental polarity; 否则为 0</li>
</ul>
<p>上述推理规则代价的计算方式不同，论文使用了一种类似于 Metric Learning的方式，通过在每个类别的推理规则上增加了一个<strong>非线性层</strong>来自动学习对不同类别的推理规则代价的校准。</p>
<p>另外，由于否定的存在会反转事件关系以及情感关系的推理结果，论文对否定进行了特殊处理。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_negation.png" class="ful-image" alt="kb_negation.png"></p>
<h3 id="知识推理"><a href="#知识推理" class="headerlink" title="知识推理"></a>知识推理</h3><p><strong>如何将规则用到阅读理解之中？</strong>换句话说，就是在给定一个文档和候选答案的基础上，如何衡量候选答案是否正确？首先将文档以及候选答案都划分为<strong>元素</strong>，整个推理的过程就被转化成了一个推理规则选择以及对这个推理的合理性进行评估的过程。</p>
<p><strong>重要假设：</strong>一组有效的推理应当要能够覆盖住结尾当中的所有元素。换言之，结尾当中出现的每一个元素，都应当能够在原文当中找到它出现的依据。</p>
<p>对于同样的一个文档和候选答案，我们可以有多种多样不同的推理。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_valid.png" class="ful-image" alt="kb_valid.png"><br>上面一个推理就是一组有效的推理，这组推理是很符合人的认知的。因为我们通常会通过 Mary 和 She 之间的实体共指关系、Restaurant 和 order 之间的序列关系以及 restaurant 和 food 之间的相关关系来判断这个结果是不是成立的。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_invalid.png" class="ful-image" alt="kb_invalid.png">
<p>这个就不怎么合理，因为我们不太会去考虑一个人和一个事件之间是不是有时序关系，以及考虑 walk to 这样一个动作和 food 之间的联系。</p>
<p>采用每一种推理的可能性是不同的，用 $P(R|D, H)$ 来对这种推理的选择建模，基于<strong>元素独立性假设</strong>，得到下面的式子</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_form.png" class="ful-image" alt="kb_form.png">
<p>是否选择一条推理规则参与推理一个假设元素 $h_i$，取决于对于原文当中推理得到 $h_i$ 的元素 $d_j$ 的选择，以及对于 $d_j$ 到 $h_i$ 之间推理关系的选择。然后将这个概率分布重新定义了一个重要性函数，与三个因子相关:</p>
<ul>
<li>s(h,d)<br>文档中的元素与候选答案中元素的语义匹配程度</li>
<li>a(h,f) 以及 a(d,f)<br>一个元素与这条推理规则的关系的一个关联程度，使用一个注意力函数来建模这种关联程度</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_form2.png" class="ful-image" alt="kb_form2.png">
<p>将原文到候选的推理代价定义成其所有有效的推理的期望代价<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_form3.png" class="ful-image" alt="kb_form3.png"></p>
<p>使用一个 softmax 函数来归一化所有候选的代价值，并且使用最大后验概率估计来估计模型当中的参数。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>三个 Baseline 进行了比较：</p>
<ul>
<li>Narrative Event Chain (Chambers and Jurafsky, 2008)<br>仅仅考虑是事件与事件之间的关联信息</li>
<li>DSSM (Huang et al., 2013)<br>将文档和候选答案各自表示成了一个语义向量，并且计算它们之间的语义距离</li>
<li>LSTM 模型 (Pichotta and Mooney, 2015)<br>通过对先前的事件进行序列建模来预测后面发生事件的概率。</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_res_overall.png" class="ful-image" alt="kb_res_overall.png">
<p><strong>不同知识的影响</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_res_k.png" class="ful-image" alt="kb_res_k.png"><br>每一种知识都能够起到作用，移除任何一种知识都会导致系统的performance显著地降低。</p>
<p><strong>推理规则选择方式加入 attention 机制的影响</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/kb_res_att.png" class="ful-image" alt="kb_res_att.png"></p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>一是推理规则怎样产生更多更复杂的推理？二是训练数据，一方面，常识阅读理解数据还是很缺乏，可能需要半监督或远程监督的方法来拓展训练数据；另一方面，可能需要扩展更多的数据源。</p>
<h2 id="Neural-Response-Generation-via-GAN-with-an-Approximate-Embedding-Layer"><a href="#Neural-Response-Generation-via-GAN-with-an-Approximate-Embedding-Layer" class="headerlink" title="Neural Response Generation via GAN with an Approximate Embedding Layer"></a>Neural Response Generation via GAN with an Approximate Embedding Layer</h2><p>生成式聊天系统可以看作是一个特殊的翻译过程，一个 question-answer pair 等价于 SMT 需要处理的一条平行语料，而 SMT 的训练过程实际上也就等价于构建问题和答案当中词语的语义关联过程。NMT 作为 SMT 高级版可以用来实现聊天回复的自动生成。这种新的自动聊天模型架构命名为 <strong>Neural Response Generation(NRG)</strong>。</p>
<p>而现在 NRG 存在问题是生成的答案严重趋同，不具有实际价值，如对于任何的用户 query，生成的结果都有可能是“我也觉得”或“我也是这么认为的”，这种生成结果被称为 <strong>safe response</strong>。safe response 产生原因如下：</p>
<ul>
<li><strong>The data distribution of chat corpus</strong></li>
<li><strong>The fundamental nature of statistical models</strong></li>
</ul>
<p>聊天数据中词语在句子不同位置的概率分布具有非常明显的长尾特性，尤其在句子开头，相当大比例的聊天回复是以“我”“也”作为开头的句子，词语概率分布上的模式会优先被 decoder 的语言模型学到，并在生成过程中严重抑制 query 与 response 之间词语关联模式的作用，也就是说，即便有了 query 的语义向量作为条件，decoder 仍然会挑选概率最大的“我”作为 response 的第一个词语，又由于语言模型的特性，接下来的词语将极有可能是“也”……以此类推，一个 safe response 由此产生。</p>
<p>常见的解决方案包括：<strong>通过引入 attention mechanism 强化 query 中重点的语义信息；削弱 decoder 中语言模型的影响；引入 user modeling 或者外部知识等信息也能够增强生成回复的多样性</strong>。这些其实是对于模型或者数据的局部感知，如果从更加全局的角度考虑 safe response 的问题，就会发现产生 safe response 的 S2S 模型实际上是陷入了一个<strong>局部的最优解</strong>，而我们需要的是给模型<strong>施加一个干扰</strong>，使其跳出局部解，进入更加优化的状态，那么最简单的正向干扰是，告知模型它生成的 safe response 是很差的结果，尽管生成这样的结果的 loss 是较小的。这样就开启了<strong>生成式对抗网络（Generative Adversarial Networks, GAN）</strong>在生成式聊天问题中的曲折探索。</p>
<p>将 GAN 引入聊天回复生成的思路：使用 encoder-decoder 架构搭建一个回复生成器G，负责生成指定 query 的一个 response，同时搭建一个判别器 D 负责判断生成的结果与真正的 response 尚存多大的差距，并根据判别器的输出调整生成器 G，使其跳出产生 safe response 的局部最优局面。</p>
<p>一个重要的问题是<strong>如何实现判别器 D 训练误差向生成器 G 的反向传播(Backpropagation)</strong>。对于文本的生成来说，一个文本样本的生成必然伴随 G 在输出层对词语的采样过程，无论这种采样所遵循的原则是选取最大概率的 greedy思想还是 beam searching，它实际上都引入了离散的操作，这种不可导的过程就像道路上突然出现的断崖，阻挡了反向传播的脚步，使对于 G 的对抗训练无法进行下去。这篇论文就针对<strong>文本生成过程中的采样操作带来的误差无法传导的实际问题</strong>提出了解决方案。</p>
<p>论文为生成器 G 构建了一个 <strong>Approximate Embedding Layer(AEL 如图中红色矩形框中所示，其细节在图右侧部分给出)</strong>，这一层的作用是近似的表达每次采样过程，在每一个 generation step 中不再试图得到具体的词，而是基于词语的概率分布算出一个采样向量。这个操作的具体过程是，在每一个 generation step 里，GRU 输出的隐状态 $h_i$ 在加入一个随机扰动 $z_i$ 之后，经过全连接层和 softmax 之后得到整个词表中每个词语的概率分布，我们将这个概率分布作为权重对词表中所有词语的 embedding 进行加权求和，从而得到一个当前采样的词语的近似向量表示（如图中右侧绿框所示），并令其作为下一个 generation step 的输入。同时，此近似向量同样可以用来拼接组成 fake response 的表示用于 D 的训练。不难看出，这种对于采样结果的近似表示操作是连续可导的，并且引入这种近似表示并不改变模型 G 的训练目标。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/NRG1.png" class="ful-image" alt="NRG1.png">
<p>取得了不错的效果。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/nrg_res.png" class="ful-image" alt="nrg_res.png"></p>
<p>详细戳<a href="https://www.leiphone.com/news/201707/uv3wNCq0MB1HSR56.html" target="_blank" rel="external">首发！三角兽被 EMNLP 录取论文精华导读：基于对抗学习的生成式对话模型浅说</a></p>
<h1 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h1><p>把传统模型和神经网络相结合。</p>
<h2 id="Translating-Phrases-in-Neural-Machine-Translation"><a href="#Translating-Phrases-in-Neural-Machine-Translation" class="headerlink" title="Translating Phrases in Neural Machine Translation"></a>Translating Phrases in Neural Machine Translation</h2><p>目前的 NMT 里 decoder 一次生成一个单词，不能进行 one-many 以及 many-many 的翻译，也就是没法做目标语言 phrase 的翻译，而 SMT 能做，所以想法是把两者结合。结合方法一般来说有两种，一是 shallow，NMT 作为 feature 放到传统框架进行预调；二是 deep，SMT 给 NMT 做推荐，NMT 用神经网络的方式接收 SMT 的东西。这篇论文用的是第二种方式。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/SMT_NMT.png" class="ful-image" alt="SMT_NMT.png"></p>
<p>SMT 先翻译一遍，把 relevant target phrases 扔到 NMT 的 Phrase Memory 里，NMT 从 Phrase Memory 里读取 target phrases 并进行打分，然后系统同时看 target phrase 和 word predictor 的结果，用一个 <strong>balancer</strong> 将 SMT 和 NMT 的优势结合起来，来判断下一个是单词还是短语的概率，来决定选哪个。所以其实产生的翻译 $y={y_1, y_2, …, y_{T_u}}$其实有两个碎片(fragments)组成，NMT 的 word predictor $w={w_1, w_2,…,w_K}$ 以及 phrase memory 里存的相关短语 $p={p_1,p_2,…p_L}$ (这里的<strong>relevant target phrases</strong> 要满足两个条件：<strong>与原文相关(adequacy)；不重复翻译(coverage)</strong>)</p>
<p>另外一点是作者还提出了基于 <strong>chunk</strong> 的翻译，SMT 对 source 提取 Chunk 信息，把布什总统、美国政府这些作为 chunk 让 SMT 预翻，然后把它们写到 phrase memory 里，后续步骤不变。chunk 的实现主要是由 sequence tagging 完成，相同 tag 表示同一个 chunk，开始符号另外标记，比如 “information security” 被标注成 “NP _B NP”，然后新的输入就变成原来的 word embedding 以及 chunking tag embedding。chunk 的好处在于限定了 source-side phrase 的信息，一方面减少了短语间的 overlap，另一方面提高了 decoding 的准确性。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/SMT_NMT_balancer.png" class="ful-image" alt="SMT_NMT_balancer.png">
<p>机器翻译相关戳<br><a href="http://www.shuang0420.com/2017/05/01/NLP 笔记 - Machine Translation/">NLP 笔记 - Machine Translation</a><br><a href="http://www.shuang0420.com/2017/07/10/NLP 笔记 - Machine Translation-Neuron models/">NLP 笔记 - Neural Machine Translation</a></p>
<p>问题是 SMT 没那么强(很难保证准确率)，NMT 也没那么弱(一个单词一个单词的翻译也能把正确的短语翻译出来)</p>
<h2 id="Incorporating-Relation-Paths-in-Neural-Relation-Extraction"><a href="#Incorporating-Relation-Paths-in-Neural-Relation-Extraction" class="headerlink" title="Incorporating Relation Paths in Neural Relation Extraction"></a>Incorporating Relation Paths in Neural Relation Extraction</h2><p>提出了对文本中的<strong>关系路径</strong>进行建模，结合 CNN 模型 (Zeng, et al. (2014). Relation classification via convolutional deep neural network. CGLING) 完成关系抽取任务。<br>传统基于 CNN 的方法，通过 CNN 自动将原始文本映射到特征空间中，以此为依据判断句子所表达的关系<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/re_cnn.png" class="ful-image" alt="re_cnn.png"></p>
<p>这种 CNN 模型存在的问题是难以理解多句话文本上的语义信息。比如说 A is the father of B. B is the father of C. 就没法得出 A 和 C 的关系，基于此，论文提出了在<strong>多样例学习机制</strong>的基础上<strong>引入关系路径编码器</strong>的方法，其实就是原来的 word embedding 输入加上一层 position embedding，position embedding 将当前词与 head entity/tail entity 的相对路径分别用两个 vector 表示。然后用 $\alpha$ 来平衡 text encoder(E) 和 path encoder(G)。<br>$$L(h,r,t)=E(h,r,t|S)+\alpha G(h,r,t|P)$$</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/re_model.png" class="ful-image" alt="re_model.png">
<p>Encoder 用的是<strong>多样例学习机制(Multi-instances Learning)</strong>，也就是用一个句子集合联合预测关系，这样可以捕获更广泛的上下文。句子集合的选择方法有<strong>随机方法(rand)，最大化方法(max, 选最具代表性的)，选择-注意力机制(att)</strong>，注意力机制的效果最好。</p>
<p>实验结果：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/re_res.png" class="ful-image" alt="re_res.png"></p>
<p>之后可以继续的两个改进方向，一是对<strong>多步关系路径</strong>进行建模，使得模型可以处理更复杂的语义情况，而是<strong>将文本中的关系路径和知识图谱中的关系路径有机地结合</strong>，更好地完成关系抽取和知识图谱补全的任务。</p>
<h1 id="零件调整"><a href="#零件调整" class="headerlink" title="零件调整"></a>零件调整</h1><p>对已有模型零部件的一些调整改造。</p>
<h2 id="Towards-a-Universal-Sentiment-Classifier-in-Multiple-languages"><a href="#Towards-a-Universal-Sentiment-Classifier-in-Multiple-languages" class="headerlink" title="Towards a Universal Sentiment Classifier in Multiple languages"></a>Towards a Universal Sentiment Classifier in Multiple languages</h2><p>这里我觉得有意思的一点是作者模仿了 skip-gram 模型提出了一种同时训练多语言的 embedding 的方法。一句话解释就是通过中心词来预测自身/其他语言周围的前后词。比如说双语预料中，需要使中文能预测中文自身的周围词，英文能学习英文自身的周围词，还要通过对齐来学习中文来预测英文、英文来预测中文。skip-gram 相关戳 <a href="http://www.shuang0420.com/2016/06/21/%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93%E7%AC%94%E8%AE%B0%EF%BC%88%E7%AE%80%E6%B4%81%E7%89%88%EF%BC%89/">词向量总结笔记（简洁版）</a>。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/biskip1.png" class="ful-image" alt="biskip1.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/biskip2.png" class="ful-image" alt="biskip2.png">
<p>C 作为 source language S 和 target language T 之间的平行语料，语料库可以分为 $C_S$ 和 $C_T$ 两部分，目标函数如下<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/biskip3.png" class="ful-image" alt="biskip3.png"></p>
<p>然后就用一个 LR 模型进行情感分类。</p>
<h2 id="Neural-Machine-Translation-with-Word-Predictions"><a href="#Neural-Machine-Translation-with-Word-Predictions" class="headerlink" title="Neural Machine Translation with Word Predictions"></a>Neural Machine Translation with Word Predictions</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/nmt_word_pred.png" class="ful-image" alt="nmt_word_pred.png">
<p>我们知道在 NMT 中，训练成本主要来自于输出层在整个 target vocabulary 上的 softmax 计算，为了减小这种 cost，各位学者做出了各种努力，比如说 Devlin et al. (2014) 从计算角度提出了 <strong>self-normalization</strong> 技术，通过改造目标函数把计算整个 matrix 的步骤优化为只计算输出层每一行的值(<a href="http://www.shuang0420.com/2017/07/10/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/">NLP 笔记 - Neural Machine Translation</a>)，而在 <strong>Neural Machine Translation with Word Predictions</strong> 这篇论文中，作者提出了一种减小 target vocabulary 的方法，主要用到了<strong>词预测机制(word predictor)</strong>。</p>
<p>之前 MT 的目标是生成一个<strong>词序列(ordered sequence)</strong>，而现在 word predictor 的目标是生成 y1..yn 的词，但是不考虑词序<strong>(no order)</strong>。</p>
<p>和上图一样的 idea，word prediction 中，initial state($WP_E$)要包含 target sentence 里的所有信息，hidden state(WP_D)要包含没有被翻译的词的所有信息。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/nmt_word_pred_frame.png" class="ful-image" alt="nmt_word_pred_frame.png"></p>
<p>$$P_{WP_E}(y|x)=\prod^{|y|}_{j=1}P_{WP_E}(y_j|x)$$<br>$$P_{WP_D}(y_j,y_{j+1},…,y_{|y|}|y_{&lt;j},x)=\prod^{|y|}_{k=j}P_{WP_D}(y_k|y_{&lt;j},x)$$</p>
<p>这样无论是效果和效率上都有了显著提升<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/nmt_word_pred_res.png" class="ful-image" alt="nmt_word_pred_res.png"></p>
<p>这个方法很好的一点是目标中的词对词预测来说是天然的标注，构造简单。然而要注意的两个点是 <strong>预测要准&amp;预测要快</strong>，否则就失去了意义。还有个问题是，按理来说较大词表质量更好然而翻译效率低，较小的词表，像这篇论文提出的，翻译某句话提前先预测生成一个新的小的词表交给 decoder，效率毫无疑问会提升，但是质量，为啥会更好？不是很理解，坐等论文。</p>
<h2 id="Towards-Bidirectional-Hierarchical-Representations-for-Attention-based-Neural-Machine-Translation"><a href="#Towards-Bidirectional-Hierarchical-Representations-for-Attention-based-Neural-Machine-Translation" class="headerlink" title="Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation"></a>Towards Bidirectional Hierarchical Representations for Attention-based Neural Machine Translation</h2><p>对传统 tree-based encoder 的一个改进。传统的 tree-based encoder 是 bottom-up 的结构，能抓局部信息却捕捉不了全局信息<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/tree_base_encoder.png" class="ful-image" alt="tree_base_encoder.png"></p>
<p>这篇论文对 tree-based encoder 做了改造，让它既能捕捉局部的语义信息，又能捕捉全局的语义信息。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/tree_base_encoder_goal.png" class="ful-image" alt="tree_base_encoder_goal.png"></p>
<p>bottom-up encoding 取得局部信息，top-down encoding 取得全局信息。对于 OOV(out-of-vocabulary) 问题，基于 sub-word 思想，这里单独建立一个二叉词法树并将其融入原来的句法树里。这样如下图所示，模型囊括了句子、短语、词、sub-word 各种全局/局部信息，表达力 max。然而同样带来的问题是会产生重复信息，进而可能会造成重复翻译。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/tree_encoder.png" class="ful-image" alt="tree_encoder.png"></p>
<p>为解决重复翻译的问题，或者说词/短语向量的 balance，这里还引入了 attention 机制<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/tree_decoder_attention.png" class="ful-image" alt="tree_decoder_attention.png"></p>
<p>效果有了一定提升。举个例子说明 tree-based encoder 的优势。用普通的 sequence encoder 翻译 PP 时会产生错误，普通的 tree-based 能翻译好 PP，不过 <em>境外</em> 和 <em>以外的地区</em> 还是有一点差距的，新版 tree-decoder 翻译就无压力。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/tree_encoder_ress.png" class="ful-image" alt="tree_encoder_ress.png"></p>
<h1 id="迁移-idea"><a href="#迁移-idea" class="headerlink" title="迁移 idea"></a>迁移 idea</h1><p>其实就是用已有的但可能用在别的方面的模型/思路解决现在的问题。</p>
<h2 id="A-Question-Answering-Approach-for-Emotion-Cause-Extraction"><a href="#A-Question-Answering-Approach-for-Emotion-Cause-Extraction" class="headerlink" title="A Question Answering Approach for Emotion Cause Extraction"></a>A Question Answering Approach for Emotion Cause Extraction</h2><p>这一部分之前木有研究过，先来看一下什么是 <strong>emotion cause extraction</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Document: 我的手机昨天丢了，我现在很难过。 (I lost my phone yesterday, and  I feel sad now. )</div><div class="line">Emotion：Sad  </div><div class="line">Emotional Expression: 很难过</div><div class="line">Emotion Cause: 我的手机昨天丢了</div></pre></td></tr></table></figure>
<p>任务目标是根据文本信息及其中包含的情感表达抽取出<strong>情感原因</strong>。论文作者之前发过论文，用的是基于 dependency parsing 的方法，把情感原因转化为树的分类任务，但结果依赖 dependency parsing 的准确性，而且只能处理对子句／句子级别的原因，不能处理细粒度的短语级别的原因。所以这一篇转换了思路，把 <strong>emotion cause extraction</strong> 问题转化为 <strong>question-answering</strong> 问题，提出了一种<strong>基于卷积的多层 memory network 方法</strong>，结果比之前基于树的方法提升了 2 个点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Emotional Text =&gt; Reading Text</div><div class="line">Emotional Words =&gt; Question/Query</div><div class="line">Emotion Cause Binary Classification Results =&gt; Answer</div></pre></td></tr></table></figure>
<p>用传统的 memory network 作为基础模型，reading text 用词向量 embedding 表达，存到记忆单元，待判断的情感词的词向量作为注意力单元，将 query 和 text 每个词进行内积操作，softmax 归一化作为词权重，用注意力的加权和作为整个句子的表达。为了引入词语的上下文，用了<strong>类似卷积的注意力加权方法</strong>，每个词的注意力由当前词、前文词、后文词共同决定，加权过程中根据上下文注意力对不同位置的词语进行加权，获得以短语窗口为单位的加权结果，然后进行输出。同时对记忆网络做了多层的堆叠，以学习更深的特征。最后效果得到了提升，并且在短语级别的情感原因抽取上也取得了不错的效果。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/conv_memory_network.png" class="ful-image" alt="conv_memory_network.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/conv_memory_results.png" class="ful-image" alt="conv_memory_results.png">
<p>问题来了，query 是怎么产生的呢？=&gt; <strong>数据集标注好了情感表达词！</strong></p>
<h2 id="Earth-Mover’s-Distance-Minimization-for-Unsupervised-Bilingual-Lexicon-Induction"><a href="#Earth-Mover’s-Distance-Minimization-for-Unsupervised-Bilingual-Lexicon-Induction" class="headerlink" title="Earth Mover’s Distance Minimization for Unsupervised Bilingual Lexicon Induction"></a>Earth Mover’s Distance Minimization for Unsupervised Bilingual Lexicon Induction</h2><p>主要研究无监督的双语对齐方法，也就是能无监督地联系两个词向量空间，本质上是需要词向量空间之间，或者说词向量分布之间距离的度量。用的 <strong>EMD 思想</strong>，目标就是寻找一个映射G，使得映射后的源语言词向量分布和目标语言词向量分布的 EMD 或者说 Wasserstein 距离最小化。具体等论文发表再研究了。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/EMD1.png" class="ful-image" alt="EMD1.png"></p>
<h2 id="Chinese-Zero-Pronoun-Resolution-with-Deep-Memory-Network"><a href="#Chinese-Zero-Pronoun-Resolution-with-Deep-Memory-Network" class="headerlink" title="Chinese Zero Pronoun Resolution with Deep Memory Network"></a>Chinese Zero Pronoun Resolution with Deep Memory Network</h2><p>解决中文的零指代消解问题。主要思路，用上下文来表示 ZP，使用两个 LSTM，一个对前文建模(left-to-right)，一个对后文建模(right-to-left)，然后连接两边最后一个隐层的向量作为 AZP 的表达(也可以尝试平均／求和)<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/ZP1.png" class="ful-image" alt="ZP1.png"></p>
<p>接着，给定一个 AZP，会有一个 NP 集合被抽出来作为 candidate antecedents，根据每个 candidate antecedent 的重要性产生一个额外的 memory，通过对两个 LSTM(一个前向一个反向) 产生的 hidden vectors 各自进行减法操作然后连接产生最后的 vector 作为最终 candidate antecedents 的表达，并存入外部的 memory 中。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/ZP_memory.png" class="ful-image" alt="ZP_memory.png"></p>
<p>这样我们的 memory 里就有了一堆的候选 candidate antecedents，接着要对 candidate antecedents 的重要性做一个排序，选择合适的 NP 来 fill in the gap (ZP)。这里用了 attention 机制，并加入了一些人工特征(Chen and Ng (2016))，表示为 $v_t^{(feature)}$<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/ZP_score.png" class="ful-image" alt="ZP_score.png"></p>
<p>模型用到了人工特征，能不能改进？ZP 位置必须事先指定，能不能自动检测？还有是对 OOV 怎么处理。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>整场报告会听下来，收获还是有很多的，只是不如想象中那么惊艳，替换零部件，加个 attention，融入传统特征，有很多的套路，最大一个收获可能是再次意识到了 <strong>attention</strong> 机制的强大，大部分论文用了 attention 结果都有大幅的改善。anyway，能提高准确率/训练效率的模型就是好模型！大家都是棒棒哒！学习！</p>
<p>周三开完会，周四飞深圳，周五上班，周六日去了澳门浪，好不容易开始笔记，发现好多内容都快忘了，有点难过 TAT，虽然我也有长短期记忆，也禁不起这么折腾…</p>
<p>最后叨叨一句，大部分论文都没发表出来，如果有错误，各位多包容，也热切欢迎大家批评指正～</p>
<p>文末彩蛋(其实还有张 Wu &amp; Tang 喝着喜茶打农药的高清大图，我先犹豫下要不要发～)<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/hello1.png" class="ful-image" alt="hello1.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/EMNLP%202017%20%E5%8C%97%E4%BA%AC%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A%E4%BC%9A%E7%AC%94%E8%AE%B0/hello2.png" class="ful-image" alt="hello2.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;16 号在北京举办的，邀请了国内部分被录用论文的作者来报告研究成果，整场报告会分为&lt;strong&gt;文本摘要及情感分析、机器翻译、信息抽取及自动问答、文本分析及表示学习&lt;/strong&gt;四个部分。感觉上次的 &lt;a href=&quot;http://www.shuang0420.com/2017/07/15/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/&quot;&gt;CCF-GAIR 参会笔记&lt;/a&gt; 写的像流水账，这次换一种方式做笔记。&lt;br&gt;
    
    </summary>
    
      <category term="Others" scheme="http://www.shuang0420.com/categories/Others/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="AI" scheme="http://www.shuang0420.com/tags/AI/"/>
    
      <category term="Machine Translation" scheme="http://www.shuang0420.com/tags/Machine-Translation/"/>
    
      <category term="Relation Extraction" scheme="http://www.shuang0420.com/tags/Relation-Extraction/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - A Neural Attention Model for Abstractive Sentence Summarization</title>
    <link href="http://www.shuang0420.com/2017/08/08/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/"/>
    <id>http://www.shuang0420.com/2017/08/08/论文笔记 - A Neural Attention Model for Abstractive Sentence Summarization/</id>
    <published>2017-08-08T05:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>接之前的<a href="http://www.shuang0420.com/2017/05/10/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/">NLP 笔记 - Text Summarization</a>，介绍一种 abstractive summarization 方法 textsum。<br><a id="more"></a></p>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><h2 id="Summarization-Phenomena"><a href="#Summarization-Phenomena" class="headerlink" title="Summarization Phenomena"></a>Summarization Phenomena</h2><p>先来观察下文本摘要的一些现象，一般是通过对源文本进行<strong>泛化(generalization)、删除(deletion)、改写(paraphrase)</strong>等操作来产生目标文本，也就是文本摘要。看一下例子</p>
<ul>
<li><strong>Generalization</strong><br><strong>Source:</strong> <strong>Russian Defense Minister Ivanov</strong> called Sunday for the creation of a joint front for combating global terrorism.<br><strong>Target:</strong> <strong>Russia</strong> calls for joint front against terrorism.</li>
<li><strong>Deletion</strong><br><strong>Source:</strong> Russian Defense Minister Ivanov called <strong>Sunday</strong> for the creation of a joint front for combating global terrorism.<br><strong>Target:</strong> Russia calls for joint front against terrorism.        </li>
<li><strong>Paraphrase</strong><br><strong>Source:</strong> Russian Defense Minister Ivanov called Sunday for the creation of a joint front <strong>for combating</strong> global terrorism.<br><strong>Target:</strong> Russia calls for joint front <strong>against</strong> terrorism.            </li>
</ul>
<h2 id="Types-of-Sentence-Summary"><a href="#Types-of-Sentence-Summary" class="headerlink" title="Types of Sentence Summary"></a>Types of Sentence Summary</h2><p>对于上面等一些操作，产生了文本摘要的几类技术模型。</p>
<ul>
<li><strong>Compressive: deletion-only:</strong><br>压缩，通过对源文本的删除操作产生目标文本。</li>
<li><strong>Extractive: deletion and reordering:</strong><br>抽取式，摘要句子完全从源文档中抽取形成，详细见 <a href="http://www.shuang0420.com/2017/05/10/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/">NLP 笔记 - Text Summarization</a></li>
<li><strong>Abstractive: arbitary transformation</strong><br>合成式，从源文档中抽取句子并进行改写形成摘要。</li>
</ul>
<p>看下几种方法的比较<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/elements.png" class="ful-image" alt="elements.png"></p>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><p>目前已经有的一些相关工作</p>
<ul>
<li><strong>Syntax-Based</strong><br>Dorr, Zajic, and Schwartz 2003; Cohn and Lapata 2008; Woodsend, Fend, and Lapata 2010</li>
<li><strong>Topic-Based</strong><br>Zajic, Dorr, and Schwartz 2004</li>
<li><strong>Machine Translation-based</strong><br>Banko, Mittal, and Witbrock 2000</li>
<li><strong>Semantics-Based</strong><br>Liu et al 2015</li>
</ul>
<h1 id="Textsum"><a href="#Textsum" class="headerlink" title="Textsum"></a>Textsum</h1><p>Textsum，论文戳 <a href="https://arxiv.org/pdf/1509.00685.pdf" target="_blank" rel="external">A Neural Attention Model for Abstractive Sentence Summarization</a>，tensorflow 代码戳 <a href="https://github.com/tensorflow/models/tree/master/textsum" target="_blank" rel="external">tensorflow/models/textsum</a>。Textsum是一种 abstractive model，主要有下面四个组件构成：</p>
<ul>
<li>Neural language model</li>
<li>Attention-based encoder model</li>
<li>Generation model</li>
<li>Beam-search decoder &amp; additional features model extractive elements</li>
</ul>
<p>下面逐个进行讨论。</p>
<h2 id="Neural-language-model"><a href="#Neural-language-model" class="headerlink" title="Neural language model"></a>Neural language model</h2><p>借鉴了机器翻译的思想，在 <a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="external">A Neural Probabilistic Language Model</a> (Bengio et al. 2013)的基础上，加了一个 attention-based encoder(Bahdanau et al. 2014) 来学习输入文本的 latent soft alignment。</p>
<p>先看一下整体逻辑，看图说话，下面左图圈出来的部分是一个<strong>feed-forward neural network language model(NNLM)</strong>，详情戳<a href="http://www.shuang0420.com/2017/07/10/NLP%20笔记%20-%20Machine%20Translation-Neuron%20models/">NLP 笔记 - Machine Translation(Neuron models)</a>，它的输入是当前 output 已经产生的上下文 $y_c$(注意这个 context 窗口的长度是固定的)，与词向量矩阵 E 做个映射，经过线性变化以及激活函数得到得分矩阵 U，再经过一个 softmax 层得到概率分布形式的输出，也就是下一个单词 $y_{i+1}$，现在我们要加上左边的 attention-based encoder，对输入 source text 和当前我们拥有的 context $y_c$ 做一个 encode，放大的话就是右图。对 context embedding 和 source 的每个单词做一个加权的点乘(weighted dot product)得到 attention distribution 也就是 P，对 source text 做一个局部的平滑(local smoothing)，然后对 source 的 smoothing 版本和 attention distribution 做一个点乘，就得到了我们要的 enc，最后把两边的东西一起扔到 softmax 里得到输出。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/abs_graph.png" class="ful-image" alt="abs_graph.png">
<p>看个例子，如下图，行是 source text，列是 output text，假定我们已经产生了 “russia calls”，现在目标是产生下一个单词 for，我们的模型将利用 attention distribution of source 以及 embedding of context，来得到 for 这个 next word。因为我们用了 bag of words 的 smoothing 版本，也就是说我们对 called 周围的单词进行了加权，attention 很大程度上会指向 called，具体逻辑见下一部分 encoders。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/abs_ex1.png" class="ful-image" alt="abs_ex1.png"></p>
<p>上面说到了，这里选择的 encoder 是 attention-based encoder，下面来看一下为什么选这个 encoder。</p>
<h2 id="Encoders"><a href="#Encoders" class="headerlink" title="Encoders"></a>Encoders</h2><h2 id="Bag-of-words-Encoder"><a href="#Bag-of-words-Encoder" class="headerlink" title="Bag-of-words Encoder"></a>Bag-of-words Encoder</h2><p>BoW encoder 把 encoder 参数估计看作是一个 uniform distribution，赋予了每个词相同的权重，同时忽略了单词词序。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/bow_encoder.png" class="ful-image" alt="bow_encoder.png">
<h3 id="Convolutional-Encoder"><a href="#Convolutional-Encoder" class="headerlink" title="Convolutional Encoder"></a>Convolutional Encoder</h3><p>Convolutional Encoder 通过局部卷积来考虑邻近单词的互动，单词/词组权重由网络训练产生。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/conv%20model2.png" class="ful-image" alt="conv%20model2.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/conv%20model.png" class="ful-image" alt="conv%20model.png"></p>
<h3 id="Attention-Based-Encoder"><a href="#Attention-Based-Encoder" class="headerlink" title="Attention-Based Encoder"></a>Attention-Based Encoder</h3><p>灵感来自 <strong>Bahdanau et al. (2014) attention-based contextual encoder</strong>。和 BoW 相似的一个简单的模型，只不过把 BoW 的 uniform distribution 替换成一个 input 和 summary 之间的 soft alignment P (如下图)，是一个机器翻译的思路。之后用学习到的这个 soft alignment 来给输入的平滑版本进行加权。比如说，如果当前的上下文和位置 i 能很好的对齐，那么单词 $x_{i-Q},…,x_{i+Q}$ 就会被 encoder 赋予更高的权重。与 NNLM 结合的话这个模型可以看作是 attention-based neural machine translation model 的精简版。</p>
<p>$G \in R_{D*V}$: embdding of the context<br>$P \in R_{H*(CD)}$: new weight matrix parameter mapping between the context embedding and input embedding<br>$Q$: smoothing window</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/abs_ex1.png" class="ful-image" alt="abs_ex1.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/attention_decoder.png" class="ful-image" alt="attention_decoder.png">
<h2 id="Generating-Summaries"><a href="#Generating-Summaries" class="headerlink" title="Generating Summaries"></a>Generating Summaries</h2><p>用 beam-search decoder 来寻找最好的 summary，这是机器翻译模型的标准化方法(Bahdanau et al., 2014; Sutskever et al., 2014; Luong et al., 2015) ，这里做了一点改进。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/beam%20search.png" class="ful-image" alt="beam%20search.png">
<p>算法如上，我们需要维护一个词库 V 以及前 k 个最好的 context，复杂度是 O(KNV)。</p>
<h2 id="Tuning"><a href="#Tuning" class="headerlink" title="Tuning"></a>Tuning</h2><p>最后论文提到了一个 tuning，这其实是在 word embedding 维度太低，语义表示不完全时，去人工添加一些特征，这可以 handle 一些 rare/unseen words 的问题，让系统的 extractive/abstractive 趋势更为平衡。<br>通过修改评分函数来直接估计 summary 概率，使用对数线性模型。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20A%20Neural%20Attention%20Model%20for%20Abstractive%20Sentence%20Summarization/tuning.png" class="ful-image" alt="tuning.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接之前的&lt;a href=&quot;http://www.shuang0420.com/2017/05/10/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/&quot;&gt;NLP 笔记 - Text Summarization&lt;/a&gt;，介绍一种 abstractive summarization 方法 textsum。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Text Summarization" scheme="http://www.shuang0420.com/categories/NLP/Text-Summarization/"/>
    
    
      <category term="textsum" scheme="http://www.shuang0420.com/tags/textsum/"/>
    
  </entry>
  
  <entry>
    <title>递归神经网络 RNN 笔记</title>
    <link href="http://www.shuang0420.com/2017/07/21/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.shuang0420.com/2017/07/21/递归神经网络 RNN 笔记/</id>
    <published>2017-07-21T10:45:12.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>介绍 RNN 及其变种。Stanford cs231n Lecture 10: Recurrent Neural Networks 的部分笔记。<br><a id="more"></a></p>
<h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><p>传统的神经网络中间层每一个神经元和输入的每一个数据进行运算得到一个激励然后产生一个中间层的输出，并没有记忆能力，在输入为序列的情况下的效果有限。而很多东西是受到时域信息影响的，某一时刻产生的激励对下一时刻是有用的，递归神经网络就具备这样的记忆能力，它可以把这一刻的特征与上一刻保存的激励信息相结合(并不只是上一刻 s2 是由 s1、s2 产生的，$s_n$ 不仅有 $s_{n-1}$ 的信息，还包括 $s_{n-2}$、$s_{n-3}$…$s_1$ 的信息。</p>
<p> <strong>CNN vs RNN:</strong></p>
<ol>
<li>CNN 需要固定长度的输入、输出，RNN 的输入可以是不定长的</li>
<li><p>CNN 只有 one-to-one 一种结构，而 RNN 有多种结构，如下图</p>
<p>​</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/one_to_many.png" class="ful-image" alt="one_to_many.png">
<p><strong>One-to-one:</strong> Vanilla Neural Networks<br> 最简单的结构，然而效果不怎么好<br><strong>One-to-many:</strong> Image Captioning, image -&gt; sequence of works<br>​输入一个图片，输出一句描述图片的话<br><strong>Many-to-one:</strong> Sentiment Classification, sequence of words -&gt; sentiment<br>​输入一句话，判断是正面还是负面情绪<br><strong>Many-to-many:</strong> Machine Translation, seq of words -&gt; seq of words<br>​有个延时的，譬如<a href="http://lib.csdn.net/base/machinetranslation" target="_blank" rel="external">机器翻译</a>。<br><strong>Many-to-many:</strong> Video classification on frame level<br>​输入一个视频，判断每帧分类。</p>
</li>
</ol>
<p><strong>Applications:</strong></p>
<ul>
<li>language models</li>
<li>translation</li>
<li>caption generation</li>
<li>program execution</li>
</ul>
<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p>以 (Vanilla) Recurrent Neural Network 为例<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/one_to_one.png" class="ful-image" alt="one_to_one.png"></p>
<p><strong>Forward(前向传播)</strong></p>
<p>$$h_t=f_W(h_{t-1},x_t)$$</p>
<p><strong>Notice: the same function and the same set of parameters are used at every time step.</strong></p>
<p>$$h_t=tanh(W_{hh}h_{t-1}+W_{xh}x_t)$$<br>$$y_t=W_{hy}h_t$$</p>
<p>就是多加上 $h_{t-1}$，activation function 用的是 tanh</p>
<p><strong>Backwards: </strong>Backpropagation Through Time(BPTT)<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/bptt.png" class="ful-image" alt="bptt.png"><br>(请原谅我的字～) U 最大特征值(Largest singular value)大于 1 的时候，梯度爆炸，小于 1 的时候，则可能发生梯度消失。&gt; 1 的时候还比较容易察觉，&lt; 1 的时候往往难以发现了。<br>梯度爆炸可以采用<strong>Gradient clipping</strong>的方式(设个天花板)避免，如梯度大于 5 的时候就强制梯度等于5。梯度消散可以通过改变 RNN 结构如采用LSTM的方式抑制。</p>
<p><strong>Loss function(损失函数)</strong><br><strong>Cross-entropy</strong><br>$$E_t(y_t,\hat y_t)=-y_tlog \hat y_t$$<br>$$E(y_t,\hat y_t)=-\sum_t y_tlog \hat y_t$$</p>
<h2 id="其他结构"><a href="#其他结构" class="headerlink" title="其他结构"></a>其他结构</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/many_to_many.png" class="ful-image" alt="many_to_many.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/many_to_one.png" class="ful-image" alt="many_to_one.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/one_to_many_.png" class="ful-image" alt="one_to_many_.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/sequence_to_sequence.png" class="ful-image" alt="sequence_to_sequence.png">
<p>双向网络：输入信息正向，反向，原因是信息等依赖关系顺序不定。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/birnn.png" class="ful-image" alt="birnn.png">
<h2 id="Example-Character-level-Language-Model-Sampling"><a href="#Example-Character-level-Language-Model-Sampling" class="headerlink" title="Example: Character-level Language Model Sampling"></a>Example: Character-level Language Model Sampling</h2><p><strong>Vocabulary:</strong> [h, e, l, o]<br><strong>Exaple training sequence:</strong> “hello”</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/ch_lm_s.png" class="ful-image" alt="ch_lm_s.png">
<p>At test-time sample characters one at a time, feed back to model<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/ch_lm_s2.png" class="ful-image" alt="ch_lm_s2.png"></p>
<p><strong>Backpropagation through time:</strong><br>Foward through entire sequence to compute loss, then backward through entire sequence to compute gradient.<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/btt1.png" class="ful-image" alt="btt1.png"></p>
<p><strong>Truncated Backpropagation through time:</strong><br>Run forward and backward through chunks of the sequence instead of whole sequence.<br>Carry hidden states forward in time forever, but only backpropagate for some smaller number of steps.<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/tbtt2.png" class="ful-image" alt="tbtt2.png"></p>
<h2 id="Image-Captioning"><a href="#Image-Captioning" class="headerlink" title="Image Captioning"></a>Image Captioning</h2><blockquote>
<p>可参考的 paper:<br>xplain Images with Multimodal Recurrent Neural Networks, Mao et al.<br>Deep Visual-Semantic Alignments for Generating Image Descriptions, Karpathy and Fei-Fei<br>Show and Tell: A Neural Image Caption Generator, Vinyals et al.<br>Long-term Recurrent Convolutional Networks for Visual Recognition and Description, Donahue et al.<br>Learning a Recurrent Visual Representation for Image Caption Generation, Chen and Zitnick</p>
</blockquote>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/CNN%26RNN.png" class="ful-image" alt="CNN%26RNN.png">
<p>下一篇重点解释。</p>
<h2 id="RNN-局限"><a href="#RNN-局限" class="headerlink" title="RNN 局限"></a>RNN 局限</h2><p>RNN 前后依赖的特性导致两个输入距离比较远的时候作用会非常弱，比如说下面的例子， China 对 Chinese 起决定作用，然而距离太远难以产生关联。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/%E5%B1%80%E9%99%901.png" class="ful-image" alt="%E5%B1%80%E9%99%901.png"></p>
<p>一个解决方案就是设计 Gate，保存重要记忆，也就是下面要讲的 LSTM，LSTM 网络模型解决了 RNN 梯度消散问题，同时保留了长时序列的相关性。</p>
<h1 id="RNN-变种-LSTM"><a href="#RNN-变种-LSTM" class="headerlink" title="RNN 变种: LSTM"></a>RNN 变种: LSTM</h1><p>LSTM 要理解的核心是 GATE，它就是靠这些 gate 的结构让信息有选择性的影响 RNN 中每个时刻的状态。所谓 gate 的结构就是一个使用 sigmoid 神经网络和一个按位做乘法的操作，这两个操作合在一起就是一个门的结构，sigmoid 作为激活函数的全连接神经网络层会输出一个 0-1 之间的数值，描述当前输入有多少信息量可以通过这个结构，类似于门，门打开时(sigmoid 输出为1时)，全部信息都可以通过；当门关上时(sigmoid 输出为0)，任何信息都无法通过。</p>
<p><strong>Vanilla RNN</strong><br>$$<br>\begin{aligned}<br>  h_t &amp; = tanh(W_{hh}h_{t-1}+W_{xh}x_t) \\<br>  &amp; =  tanh((W_{hh} W_{hx})\binom{h_{t-1}}{x_t}) \\<br>   &amp; = tanh(W \binom{h_{t-1}}{x_t}) \\<br>  \end{aligned}<br>$$</p>
<p>看一下 Vanilla RNN 到 LSTM 前向传播的变化<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/1.png" class="ful-image" alt="1.png"></p>
<p><strong>LSTM 网络结构图</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/LSTMgate2.png" class="ful-image" alt="LSTMgate2.png"></p>
<p><strong>分步：</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/LSTMgate.png" class="ful-image" alt="LSTMgate.png"><br><strong>f</strong>: Forget gate, Whether to erase cell<br><strong>i</strong>: Input gate, whether to write to cell<br><strong>g</strong>: Gate gate (?), How much to write to cell<br><strong>o</strong>: Output gate, How much to reveal cell</p>
<p><strong>Step 1:</strong><br>新输入 $x_t$ 前状态 $h_{t-1}$ 决定 C 哪些信息可以舍弃。$f_t$ 与 $C_{t-1}$ 运算，对部分信息进行去除</p>
<p><strong>Step 2:</strong><br>新输入 $x_t$ 前状态 $h_{t-1}$ 告诉 C 哪些新信息想要保存。<br>$i_t:$ 新信息添加时的系数(对比 $f_t$)，$g_t$ 单独新数据形成的控制参数，用于对 $C_t$ 进行更新。</p>
<p><strong>Step 3:</strong><br>根据旧的控制参数 $C_{t-1}$，新生成的更新控制参数 $g_t$ 组合生成最终生成该时刻最终控制参数</p>
<p><strong>Step 4:</strong><br>根据控制参数 $C_t$ 产生此刻的新的 LSTM 输出</p>
<p>核心内容 $C_t$，信息流控制的关键，参数决定了 $h_t$ 传递过程中，哪些被保存或舍弃，参数被 Gate 影响。<strong>怎样实现 Gate 对 C 影响？</strong> Sigmoid 函数系数据定 $C_t$ 参数的变化，而 Sigmoid 函数决定于输入。<br>整个过程：$C_t$ 信息舍弃 =&gt; $C_t$ 局部生成 =&gt; $C_t$ 更新 =&gt; $C_t$ 运算</p>
<p><strong>Backpropagation:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/LSTMbp.png" class="ful-image" alt="LSTMbp.png"></p>
<h1 id="LSTM-变种-Peephole-connection"><a href="#LSTM-变种-Peephole-connection" class="headerlink" title="LSTM 变种: Peephole connection"></a>LSTM 变种: Peephole connection</h1><p>$C_t$ 受到 Gate 参数影响 =&gt; 二者相互影响<br>$f_t=\sigma(W_f[C_{t-1},h_{t-1},x_t]+b_f)$<br>$f_t=\sigma(W_i[C_{t-1},h_{t-1},x_t]+b_i)$<br>$f_t=\sigma(W_o[C_{t-1},h_{t-1},x_t]+b_o)$</p>
<h1 id="LSTM-变种-遗忘-更新互为补充"><a href="#LSTM-变种-遗忘-更新互为补充" class="headerlink" title="LSTM 变种: 遗忘/更新互为补充"></a>LSTM 变种: 遗忘/更新互为补充</h1><p>Gate 的 <strong>忘记/更新</strong> 不再独立，而是互为补充互为补充。</p>
<p>$C_t = f_t * C_{t-1} + i_t * g_t$ =&gt; $C_t = f_t * C_{t-1} + (1-f_t) * g_t$</p>
<h1 id="LSTM-变种-GRU-Gated-Recurrent-Unit"><a href="#LSTM-变种-GRU-Gated-Recurrent-Unit" class="headerlink" title="LSTM 变种: GRU(Gated Recurrent Unit)"></a>LSTM 变种: GRU(Gated Recurrent Unit)</h1><ol>
<li>遗忘，更新 Gate 结合(不是独立，也不是互补)</li>
<li>控制参数 $C_t$ 与输出 $h_t$ 结合，直接产生带有长短记忆能力的输出 link<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20RNN%20%E7%AC%94%E8%AE%B0/GRU.png" class="ful-image" alt="GRU.png">
</li>
</ol>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><ul>
<li>RNN 应用在 language model 中，学习的实质是 P(下个词|前面多个词)</li>
<li>Vanilla RNNs 非常简单，但效果不好，通常会使用 LSTM 和 GRU，这两种结构能提高 gradient flow</li>
<li>在一层 RNN 中不同时间序列中激励函数和权值参数都一致</li>
<li>RNN 也可以是多层 RNN，其网络是整个一模型一起训练的</li>
<li>RNN 存在着梯度爆炸和梯度消散的问题。梯度爆炸可以采用<strong>Gradient clipping</strong>的方式避免，梯度消散可以采用 LSTM 的网络结构抑制</li>
<li>中间层的特征带有前后时间特征，对一些任务很有用</li>
<li>额外参数：单双向/梯度上限/梯度计算范围</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍 RNN 及其变种。Stanford cs231n Lecture 10: Recurrent Neural Networks 的部分笔记。&lt;br&gt;
    
    </summary>
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/categories/Deep-learning/"/>
    
      <category term="RNN" scheme="http://www.shuang0420.com/categories/Deep-learning/RNN/"/>
    
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/tags/Deep-learning/"/>
    
      <category term="RNN" scheme="http://www.shuang0420.com/tags/RNN/"/>
    
      <category term="LSTM" scheme="http://www.shuang0420.com/tags/LSTM/"/>
    
  </entry>
  
  <entry>
    <title>CCF-GAIR 参会笔记</title>
    <link href="http://www.shuang0420.com/2017/07/15/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.shuang0420.com/2017/07/15/CCF-GAIR 参会笔记/</id>
    <published>2017-07-15T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>回国后参加的第一场大规模的人工智能峰会，感觉收获还是很多的，对部分之前学过的东西做了一遍梳理，对当前工业界的发展现状有了一定了解，对学术界的最新进展有了些体会，最后还结识了一批志同道合的朋友，值回票价。这一篇作为峰会的笔记，记录一些我认为重要的东西，有些零散，参加的场次有限，看官们见谅～<br><a id="more"></a></p>
<h1 id="AI-发展前沿"><a href="#AI-发展前沿" class="headerlink" title="AI 发展前沿"></a>AI 发展前沿</h1><p>这一部分各位演讲嘉宾从宏观角度概括了下 AI 的发展现状。</p>
<h2 id="AI-的典型任务和应用"><a href="#AI-的典型任务和应用" class="headerlink" title="AI 的典型任务和应用"></a>AI 的典型任务和应用</h2><blockquote>
<p><strong>潘云鹤</strong>——中国工程院院士，国务院学位委员会委员、中国科学技术协会顾问、中国图象图形学学会名誉理事长、中国计算机学会理事、中国人工智能学会副理事长。中国智能CAD领域的开拓者，创造性地将人工智能引入CAD技术。</p>
</blockquote>
<p>主要介绍了 AI 行业的一些基本情况，像人工智能的典型任务、应用、重点方向之类，毕竟是刚开场的演讲，听的比较仔细。<br>人工智能应用的 7 个基本领域：</p>
<ul>
<li><strong>机器定理证明(逻辑和推理)</strong> — 仿解题者<br>主要是研究计算机进行逻辑推理</li>
<li><strong>机器翻译(自然语言理解)</strong> — 仿译者<br>研究计算机自然语言理解</li>
<li><strong>专家系统(问题求解和知识表达)</strong> — 仿专家(医生，维修者)<br>研究问题求解和知识表达</li>
<li><strong>博弈(树搜索)</strong> — 仿弈者<br>最早的时候研究搜索，后来逐渐转化为神经网络</li>
<li><strong>模式识别(多媒体认知)</strong> — 仿认知者<br>主要用于视觉、听觉或者各种各样媒体的认知</li>
<li><strong>学习(神经网络)</strong> — 仿初学者<br>主要是研究神经网络</li>
<li><strong>机器人和智能控制(感知和控制)</strong> — 仿生物动作<br>主要是研究和模拟人的感知和控制</li>
</ul>
<p>形成了符号学派、连接学派、行为学派。<br>AI 从萌芽到现在的蓬勃发展期间出现了三次低谷，得到的教训大致是<strong>驱动 AI 的发展主要是靠创新、软件和知识，而非硬件</strong>，<strong>知识不能靠专家手工表达，要靠从环境中自动学习</strong></p>
<p>一些新的技术已经初露端倪，表现在近几年 AI 技术的前沿中，主要有</p>
<ul>
<li><strong>大数据智能</strong><br>DeepMind 已为谷歌挣钱，提高了谷歌 15% 的用电效率</li>
<li><strong>基于网络的群体智能</strong><br>群智计算按难易程度分为三种类型：实现任务分配的<strong>众包模式(Crowd-sourcing)</strong>，较复杂、支持<strong>工作流模式的群体智能(Complex workflows)</strong>，以及最复杂的<strong>协同求解问题的生态系统模式(Problem solving ecosystem)</strong><br>大规模个体通过互联网参与和交互，可以表现出超乎寻常的智慧能力，是解决开放复杂问题的新途径，成功的如 AppStore，Wiki 百科等</li>
<li><strong>跨媒体推理</strong><br>在语言、视觉、图形和听觉之间语义贯通，是实现联想、推理、概括等智能的重要关键</li>
<li><p><strong>无人系统</strong><br>无人系统迅猛发展的速度远快于机器人，因为类人和类动物的机器人，往往不如机械进行智能化和自主化升级来的高效<br>如 (海康)智能分拣机器人，泊车机器人</p>
<p>​<br><strong>AI 的基础和目标:</strong> 模拟人的智能 =&gt; 人机融合 =&gt; 群体智能</p>
</li>
</ul>
<p>直接上图了<br><img class="ful-image" alt="1.1.jpeg"><br><img class="ful-image" alt="1.2.jpeg"><br><img class="ful-image" alt="1.3.jpeg"><br><img class="ful-image" alt="1.4.jpeg"><br><img class="ful-image" alt="1.5.jpeg"><br><img class="ful-image" alt="1.6.jpeg"><br><img class="ful-image" alt="1.7.jpeg"><br><img class="ful-image" alt="1.8.jpeg"></p>
<h2 id="The-Rise-of-AI-And-The-Challenges-of-Human-Aware-AI-Systems"><a href="#The-Rise-of-AI-And-The-Challenges-of-Human-Aware-AI-Systems" class="headerlink" title="The Rise of AI And The Challenges of Human-Aware AI Systems"></a>The Rise of AI And The Challenges of Human-Aware AI Systems</h2><blockquote>
<p><strong>Subbarao Kambhampati</strong>——AAAI主席，亚利桑拿州立大学教授，同时也在很多的国际机构任职，主要研究自动化的决策机制，特别是在人工感知的人工智能领域。</p>
</blockquote>
<p>同样讲了 AI 进展，不过划分方式略有不同。<br><img class="ful-image" alt="2.1.jpeg"></p>
<p>提供了一个很有意思的视角， AI 系统的发展过程和人的学习过程是截然相反的。为什么呢？因为在有 conscious theories 的基础上编程更容易，毕竟 cognitive/reasoning intelligence 一直在发展嘛，还因为我们并没有特别意识到/了解 perceptual intelligence，为什么当今的 AI 能够走入千家万户的视野呢？正是因为 perceptual abilities 让 AI 不再是瞎的聋的，现在的 AI 可以更加的智能，可以存在在各种载体之上，如智能手机，智能音箱，汽车等等。</p>
<img class="ful-image" alt="2.2.jpeg">
<p>教授还指出了几个研究方向：<strong>从小数据中学习、机器的常识、不完整性和交互。</strong></p>
<h2 id="模式识别研究回顾与展望"><a href="#模式识别研究回顾与展望" class="headerlink" title="模式识别研究回顾与展望"></a>模式识别研究回顾与展望</h2><blockquote>
<p><strong>谭铁牛</strong>——中国科学院院士、英国皇家工程院外籍院士、发展中国家科学院院士、巴西科学院外籍院士，发表专著11部、文章500多篇，还有100多项发明。获得了一系列的国家级的奖，现在是中国图象图形学会理事长、中国人工智能学会副理事长。</p>
</blockquote>
<p>主要讲了模式识别的 <strong>基本概念／发展现状／研究方向</strong>。深深的觉得 ppt 做的实在很棒，讲的也很棒，感觉最棒的！直接上图！<br><img class="ful-image" alt="3.1.jpeg"><br><img class="ful-image" alt="3.2.jpeg"><br><img class="ful-image" alt="3.3.jpeg"></p>
<p><strong>模式识别的现状：</strong></p>
<ul>
<li>面向特定任务的模式识别已经取得突破性进展，有的性能已可与人类媲美；</li>
<li>统计与机遇神经网络的模式识别目前占主导地位，深度学习开创了新局面；</li>
<li>通用模式识别系统依然任重道远；</li>
<li>鲁棒性、自适应性和可泛化性是进一步发展的三大瓶颈。</li>
</ul>
<p><strong>现有模式识别的局限性:</strong></p>
<ul>
<li><strong>鲁棒性</strong><br>​    容易收到对抗样本的攻击<br>​    如 CV 中的局部形变／旋转变化／光照变化／遮挡／背景凌乱／多样性／尺度变化</li>
<li><strong>自适应性差</strong><br>​    不能自适应开放环境下数据分布的快速变化</li>
<li><strong>可解释性差</strong><br>​    人在判别过程中可以轻易使用具有逻辑关系的规则；机器特别是深度学习常作为黑箱模型，无法为高风险应用提供具有说服力的决策</li>
</ul>
<p>在人工智能非常火爆的时候，模式识别领域有如下值得<strong>关注的研究方向</strong>：</p>
<ul>
<li><strong>从神经生物学领域获得启发的模式识别</strong><br>神经元(类型、发放特性、突触可塑性)／神经回路(前向、侧向、后向连接)／功能区域(多任务协同、注意、记忆机制)／学习机制(人的学习特性和学习过程)<br>学习过程：发育学习、强化学习<br>学习方法：迁移学习、知识学习<br>学习效果：生成学习、概念学习(e.g., Bayesian Program Learning)</li>
<li><strong>面向大规模多源异构数据的鲁棒特征表达</strong><br>考虑如何在跨景跨媒、多源异质的视觉大数据中找到具有较好泛化性和不变性的表达<br>e.g., 定序测量特征(Ordinal Measure)</li>
<li><strong>结构与统计相结合的模式识别新理论</strong></li>
<li><strong>数据与知识相结合的模式识别</strong><img class="ful-image" alt="3.4.jpeg"></li>
<li><strong>以互联网为中心的模式识别</strong></li>
</ul>
<h1 id="AI-学术前沿"><a href="#AI-学术前沿" class="headerlink" title="AI 学术前沿"></a>AI 学术前沿</h1><p>这一场主要分析了学术界的各位的最新研究进展</p>
<h2 id="Smart-Robotic-Systems-that-Work-in-Real-Outdoor-Environments"><a href="#Smart-Robotic-Systems-that-Work-in-Real-Outdoor-Environments" class="headerlink" title="Smart Robotic Systems that Work in Real Outdoor Environments"></a>Smart Robotic Systems that Work in Real Outdoor Environments</h2><blockquote>
<p><strong>金出武雄</strong>——机器人领域的鼻祖级专家，卡耐基梅隆大学的创始人，同时也是非常著名的荣誉教授，主要研究机器人工、机器人学，享誉全世界的指路者。</p>
</blockquote>
<p>虽然是自家学校的，还是木有认真听。开头主要讲了一个例子，在车上加一个 smart headlight，使得雨滴在图片里面的成像变得很淡，可以毫无障碍在雨雪天的夜晚出行， 因为他一开始就在讲汽车灯光在下雨天各种反射怎么怎么样……然后我就……就没兴趣了TAT……</p>
<img class="ful-image" alt="4.1.jpeg">
<h2 id="A-society-of-AI-Agents-群体智能的社会"><a href="#A-society-of-AI-Agents-群体智能的社会" class="headerlink" title="A society of AI Agents 群体智能的社会"></a>A society of AI Agents 群体智能的社会</h2><blockquote>
<p>汪军， 伦敦大学学院（UCL）计算机系教授、互联网科学与大数据分析专业主任。主要研究智能信息系统，主要包括数据挖掘，计算广告学，推荐系统，机器学习，强化学习，生成模型等等。他发表了100多篇学术论文，多次获得最佳论文奖。是国际公认的计算广告学和智能推荐系统专家。</p>
</blockquote>
<p>讲多智能体怎样竞争怎样协作怎样通讯。从多智体群体的特征切入，介绍多智体的强化学习特性。同一环境下，不同的智体既可以单独处理各自的任务，又可以联合在一起处理优化一个主要的目标方程(一般是长期的 reward 方程)。强化学习的优点就是在没有足够训练数据时，系统会和环境进行交互，得到反馈信息，交互过程中不断学习，在应用上比较灵活</p>
<p><strong>Multi-agent reinforcement learning(MARL)</strong> 的应用有互联网广告的机器招标(Machine Bidding in Online Advertising)，通过对投放广告后的用户的反馈的不断学习，就可以帮助企业精准找到目标用户。再如 AI 玩星际游戏(AI plays StarCraft)等，主要考虑的是智体的通讯问题，多个智体之间怎么合作，达到双向联通。</p>
<img class="ful-image" alt="5.1.jpeg">
<p>其他的应用比如宜家的商场设计，需要模拟人的行为流向，同时让环境跟着用户的变化而变化，把路径安排最优，来优化用户的停留时长(stay)和购买金额(purchase) ，再比如迷宫的设计，一方面给定一个环境，让智体通过强化学习找到最优的策略走出来，另一方面是当智体的智能水平不再提高时，就可以来优化环境，使它更难出去。</p>
<p>多智能强化学习的研究仍然处于非常初步的阶段，主要有两个问题</p>
<ul>
<li><strong>Problem1:</strong> current research is limited to only less than 20 agents<br>许多现实场景中的多智体数量可以达到百万、甚至千万级，比如 uber 的场合怎么办？共享单车怎么办？</li>
<li><strong>Problem2: </strong> the environment is assumed to be given and not designable<br>不是去学环境的设计，而是让人工智能更加适应环境，而很多情况下，很多环境也需要有适应的过程，比如说宜家，强化学习的环境，根据用户的变化，变化环境。用随机 agents 模拟人在店铺走的情况，收集人力图，反馈到铺面设计，来最大用户停留时间/用户消费</li>
</ul>
<p>怎么处理百万级的 agent，一种方法是从自然界中找灵感，可以学习生态学／生物学的 self-organisation(自组织)理论，当一些小的智体遵循这个规则的时候，就会体现一个种群的特质。这些模型可以用宏观的事情解决宏观的问题，但是缺少一种微观的方法去观察这个世界。老虎和羊的模型 Lotka-Volterra model the dynamics of the artificial population 描述了相互竞争的两个种群数量之间的动态关系。汪军教授在此模型上做了一个创新，提出了老虎-羊-兔子模型(Tiger-sheep-rabbit model)，给智体强化学习能力以后，就和 LV 模型中的猞猁抓兔子的动态显现十分相似。当智体之间联合一起优化某一个目标或单独优化自己的目标，作为一个群体，他们就有了内在的规律。如果找到这些规律，对开发智体模型是非常有帮助的。</p>
<h1 id="计算机视觉专场"><a href="#计算机视觉专场" class="headerlink" title="计算机视觉专场"></a>计算机视觉专场</h1><h2 id="Video-Content-3C-Creation-Curation-Consumption"><a href="#Video-Content-3C-Creation-Curation-Consumption" class="headerlink" title="Video Content 3C: Creation, Curation, Consumption"></a>Video Content 3C: Creation, Curation, Consumption</h2><blockquote>
<p>梅涛，微软亚洲研究院资深研究员。</p>
</blockquote>
<p>CV understanding 问题分为几个层次(or 不同粒度)：<br><strong>Image/video 每个 pixel 代表什么 label/semantic =&gt; 每一个物体在什么位置，代表什么类别 =&gt; video/picture 有什么 tag =&gt; 输出 tag 以及一个 natural sentence 来描述 =&gt; 给定一个 picture collection，游记等，产生一个故事 story</strong><img src="CV understanding.png" alt="CV understanding"></p>
<p>从图像到视频的变换，实际是从二维到三维的变换，除了要理解每一帧的图片的 object，还要理解帧/物体在 cross, multiple-frame的动态运动。</p>
<p>视频内容的生命周期大致可以分为三个部分，即视频的<strong>创作(creation)、处理(curation)和消费(consumption)</strong>。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/video%20lifecycle.png" class="ful-image" alt="video%20lifecycle.png">
<h3 id="Creation"><a href="#Creation" class="headerlink" title="Creation"></a>Creation</h3><p>先来看一下视频是怎么产生的。首先把 Video 切成一个个的 shots(镜头/段落)，每个镜头 group(组合) 成一个 story(scene)，每一个镜头还可以细分成 sub-shots，每个 sub-shot 可以用 key-frame 来表示。通过这种分层的结构可以把 video 这样一个非线性的东西分成一个 structure data，这就是做 video summarization 的前提。</p>
<p>Video summarization 分两种，static summary 和 dynamic summary。</p>
<ul>
<li><strong>static summary:</strong> automatic selection of representative video keyframes(e.g., 5 keyframes)<br>主要是选择具有高度代表性的 keyframe 来表示视频，一个 5 分钟的 video 给你 5 个 keyframe 你就知道这个视频讲了什么</li>
<li><strong>dynamic summary:</strong> automatic generation of a short clip for fast preview(e.g., 30 second)<br>8 分钟的 video 生成 30 秒的 highlight，概括 video 的所有内容。spots video 知道哪些 segment 是最 hightlight 最精彩的，你最应该看哪部分</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/video%20summ1.png" class="ful-image" alt="video%20summ1.png">
<p><strong>Video Creation</strong> 的涉及的技术还有 <strong>stabilization and photography</strong>，怎么把拍的抖动的 video 变得平稳，怎么分辨 video 中的物体哪些是静止的哪些是动态的，然后产生 animation；另外和文字结合的技术/应用如 <strong>video generation</strong>，给出文字，来产生一个 video，像给一个动作，video 能展示这个动作。</p>
<h3 id="Curation"><a href="#Curation" class="headerlink" title="Curation"></a>Curation</h3><p><strong>Video Curation</strong> 主要涉及了 <strong>auto-tagging</strong>，<strong>action recognition</strong> 等，现在的技术已经可以识别 1000+ 物体和 500+ 的动作(action)。有了 tag 就可以做视频搜索。action recognition 的难点在于二维的 kernel 变成了三维的，参数剧增，训练非常复杂。微软研究员为 action recognition 做了一个 <strong>P3D(pseudo 3D present)</strong>，把 ResNet 扩展到 video，2D 卷积变成了 3D 卷积，把 3d conv 分解成一个 1x3x3 的 spatial 2d 和 conv + 3x1x1 的 temporal conv，最后的识别率在 UCF 101 数据集上比之前的 3D CNN 提高了 6-7 个百分点。<img src="P3D.png" alt="P3D"></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/P3D%20res.png" class="ful-image" alt="P3D%20res.png">
<p><strong>Curation</strong> 涉及的技术还有 <strong>pose estimation from RGB video</strong>，应用比如说智能健身教练，通过把动作分解来告诉你哪一个动作是不准确的；还有在 <strong>video captioning</strong> 方面的应用，可以把视频描述做的更生动，比如说原来只能识别一群人(a group of people)，加上 pose estimation 可以识别一群人在跳舞(a group of people are dancing)。还有<strong>auto-commenting</strong>，给视频自动评论，把原有的 caption 变成有人的情感对话的 comments，比如说棒球比赛的动图，可以产生<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">I love baseball</div><div class="line">that&apos;s how to play baseball</div><div class="line">That&apos;s an amazing play</div><div class="line">- [Li, Yao, Mei, MM&apos;16]</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/chat.png" class="ful-image" alt="chat.png">
<p><strong>Video caption</strong> 的经典方法是2D/3D CNN 学一个 video 的表达，然后做一个 embedding，把 embedding 的结果加上 text embedding 放到 rnn 去学。如果加上一个 relevant loss，结果不仅 cohurrent，还和内容相关<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/caption.png" class="ful-image" alt="caption.png"></p>
<h3 id="Consumption"><a href="#Consumption" class="headerlink" title="Consumption"></a>Consumption</h3><p>最后一个环节是 <strong>Video Consumption</strong>，应用像 video instagram，可以给 video 加上 style，或者说滤镜，变成 <strong>stylist video</strong>；也可以做 <strong>style transfer</strong>，比如说把油画的 style transfer 到自拍/风景照中；还有的应用像 <strong>segmentation</strong>，把人抠出来放到另一个场景里，把异地情侣放到一个房间里聊天；更难一点的还可以做 <strong>storytelling</strong>，把很多视频中的图像组合成一个吸引人的故事讲给观众听；另外还有 <strong>video advertising</strong>，来分析广告应该放什么位置，什么时间段选什么广告(是不是和插入点信息相关)，比如说广告和内容可以无缝衔接，也可以在故事高潮的时候/最 boring 的时候放广告。视频广告主要有两种度量方式，一个是 discontinuity，来衡量一个广告插入点的故事情节是否连续；另一个是 attractiveness，来衡量一段原始视频的内容是否精彩。这两者的权衡同事也就是广告商(advertiser)或用户(viewer)需求的权衡。</p>
<h2 id="产业落地和产业化路径"><a href="#产业落地和产业化路径" class="headerlink" title="产业落地和产业化路径"></a>产业落地和产业化路径</h2><p>下一个是演讲者是中山大学教授、商汤科技执行研发总监林倞老师，又是母校，主题是 <strong>深度驱动的人工智能：从学术创新到产业落地</strong>，主要还是介绍了下商汤现在的主要业务。再下一个演讲者是魏京京，图麟科技 CEO，主题是 <strong>计算机视觉的产业化路径</strong>，也就不多说了。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/%E5%95%86%E6%B1%A4.png" class="ful-image" alt="%E5%95%86%E6%B1%A4.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/%E5%9B%BE%E9%BA%9F.png" class="ful-image" alt="%E5%9B%BE%E9%BA%9F.png"></p>
<h3 id="X-数据驱动的-Seeta-视觉引擎与平台"><a href="#X-数据驱动的-Seeta-视觉引擎与平台" class="headerlink" title="X 数据驱动的 Seeta 视觉引擎与平台"></a>X 数据驱动的 Seeta 视觉引擎与平台</h3><blockquote>
<p><strong>山世光</strong>，中科院计算所研究员、博导，基金委优青，CCF青年科学奖获得者，现任中科院智能信息处理重点实验室常务副主任，中科视拓创始人、董事长兼CTO，任IEEE，TIP，CVIU， PRL，Neurocomputing，FCS等国际学术刊物的编委。</p>
</blockquote>
<p>主要记录几个点，原文可以看 <a href="https://mp.weixin.qq.com/s?__biz=MzI5NTIxNTg0OA==&amp;mid=2247486265&amp;idx=1&amp;sn=1fc14df04e82246a5cd9a07057d07942&amp;chksm=ec57bcbedb2035a892af812d7b5c956d2ff2724e7a49106be3ba727324317bda1f5a97c2408c&amp;mpshare=1&amp;scene=1&amp;srcid=0723MBBvTvlpZbp7a3JWqs28&amp;key=188350111ce3d613ac3953993817f8b9270b517e7b0422a23477402db218ce42c4c732a3a525331afcbc526a9eb4caf21181d9e39bc1e66aefddf83addea04865518c9653c66346e4e23146c56d33db5&amp;ascene=0&amp;uin=Nzc1Mjc0MDYw&amp;devicetype=iMac+MacBookPro13%2C3+OSX+OSX+10.12.3+build(16D30" target="_blank" rel="external">中科视拓CTO山世光：如何用X数据驱动AI成长 | CCF-GAIR 2017</a>&amp;version=12020610&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=fYv8LK1dmtHud6qxDzyk0NQoTcNdpkYbWuD9vGD4pepNxlPLVOKnmpPFU3ig4ZlD)</p>
<p><strong>增强学习适合：可以自动判断对错的领域</strong><br>例如：棋类、游戏类<br>视觉、听觉、理解、情感，通通不太行</p>
<p><strong>深度学习适合：好数据肥沃、可以归纳学习的领域</strong></p>
<ol>
<li>数据采集、获取、标注便利的领域，例如视觉，语音，互联网+行业</li>
<li>需要演绎推理的领域非常困难，理解需要演绎和引申，没有太多可作为的地方</li>
</ol>
<p>X 数据有五个含义：</p>
<ul>
<li><strong>大数据</strong><br>大数据驱动的视觉引擎的设计；</li>
<li><strong>小数据</strong><br>在很多场景下，我们获得智能的能力并不是依赖于大量的数据学习，反而是一些小数据，所以要考虑的十四，怎样在小数据的情况下使得我们的算法也能够有效果。通常的思路自然是迁移学习，最简单的是做 finetune 模型，把一个已经训练好的模型，再用小量的数据做调整和优化，使得它适应这些小数据所代表的应用场景。另一个思路是多模态的数据，实现跨模态的比对和融合利用；</li>
<li><strong>脏数据</strong><br>很好理解了，现在的数据都有大量的噪声，要雇人在大量的数据中把它们标注出来太不容易了，干脆就基于有噪声的数据实现机器学习。所以山世光等人在今年提出具有“自纠错学习”能力的深度学习方法，在深度学习的过程中，一边去学习算法，一边去估计哪些样本的标签可能是错误的，把一些可能错误的标签修正过来，从而得到更好的算法。<br>这里的脏可能还有另一层含义，比如说图像识别中有遮挡的情况，山世光等人也提出了一个算法，能够把面部的遮挡部分、脏的部分补出来，补出来之后再去实现感知。把这两个过程迭代起来，形成联合的学习，这个工作发表在去年的 CVPR 上面，取得了非常不错的效果。</li>
<li><strong>无监督数据</strong><br>比如说特定的物体没有标注数据，怎样利用没有标签的数据来训练模型。解决方法如 Bi-shifting 深度模型，实现从源域到无监督目标域到知识迁移。(M.Kan, et al, ICCV2015)</li>
<li><strong>增广数据</strong><br>通过对已有少量数据进行修改的方式，来生成大量数据。有两类方法，一种是模型方法，比如说 3D 重建，另一种是 GAN 方法。</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/x5.png" class="ful-image" alt="x5.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/x5.2.png" class="ful-image" alt="x5.2.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/xx.png" class="ful-image" alt="xx.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/xx2.png" class="ful-image" alt="xx2.png">
<p>AI 未来发展需要注意的三个问题：</p>
<ul>
<li><strong>鲁棒性</strong><br>鲁棒性可能是 AI 和视觉智能一个最致命的问题</li>
<li><strong>多模态数据协同</strong><br>对于人来说，除了眼睛之外，我们有很多其它信息来对我们的智力发育提供帮助，包括语音、姿态、动作、以及背后有大量的知识库作支撑。因此，人本身是需要一个多模态系统协同工作的鲁棒AI，这带给我们一个思路，AI的成长和发育也需要多模态</li>
<li><strong>基于小样本的自主学习</strong><br>AI 发育的非常重要的一点，就是如何基于小数据甚至是 0 数据完成智能的发育和后天的学习。比如说我跟大家描述一下某个人长成什么样子，你并没有见过这个人，你并没有见过这个人的照片，我们称为0数据，你如何能够识别这个人，是对AI的一个挑战。类似这样的应用场景，将来会有非常多的研究空间。</li>
</ul>
<h3 id="圆桌对话"><a href="#圆桌对话" class="headerlink" title="圆桌对话"></a>圆桌对话</h3><p>五位圆桌嘉宾包括：中科院计算所研究员、中科视拓董事长兼 CTO 山世光、阅面科技 CEO 赵京雷、图麟科技 CEO 魏京京、瑞为智能 CEO 詹东晖以及臻识科技 CEO 任鹏。<br>感觉最有意义的一个问题是：<strong>你觉得人工智能技术在落地过程中最大的难点是什么</strong>。几位嘉宾一致同意说是<strong>闭环</strong>。最核心的是<strong>市场需求和当前技术达到的闭环</strong>，产品结果和客户需求有差距，要怎么迭代。做产品的时候有很多取舍的东西，要去平衡你的功能、性能，满足客户的指标、期望，最后在产品设计和成本相关的这些方面，其实一个核心就是闭环。创业过程中<strong>最关键的不是你有什么技术，而是你把已有的技术跟他的痛点结合，这个问题不是技术的问题，基本上就是商业问题，需要付出的努力不是做技术的来做的，而是你要接地气，围着客户做讨论、设计和服务，让他慢慢接受你，这是很痛苦的，也是做技术创业需要转换的地方。</strong>我们所谓的技术完美，当然我们希望「快、准、稳」。快是随便找一个很烂的芯片就可以做；准是什么情况下都能工作；稳是不会出现差错，这样落地和闭环就不会出现难题了，<strong>但是我们现在真的做不到。比如刚才说的万分之一，很多时候是达不到的，在这个阶段最难的是怎么去找到客户的需求和技术的边界能够结合的应用，再配合上其他的一些条件，能够满足用户的需求。</strong>刚才几位说得都对，技术不完美还是一个很大的障碍。</p>
<p><a href="http://t.cn/R9h2w8p" target="_blank" rel="external">CV+圆桌对话：算法不是唯一考量，创业公司的商业闭环才是最大难点</a></p>
<h1 id="机器学习专场"><a href="#机器学习专场" class="headerlink" title="机器学习专场"></a>机器学习专场</h1><h2 id="AI-in-games"><a href="#AI-in-games" class="headerlink" title="AI in games"></a>AI in games</h2><blockquote>
<p>田渊栋，Facebook 人工智能研究院研究员</p>
</blockquote>
<p>游戏平台，作为虚拟环境，是非常好的一个数据来源。因为量大，无穷尽，获取速度快，有科学的平台可以提供重复科研的环境。游戏数据的特点：</p>
<ul>
<li>infinite supply of fully labeled data</li>
<li>controllable and replicable</li>
<li>low cost per sample</li>
<li>faster than real-time</li>
<li>less safety and ethical concerns</li>
<li>complicated dynamics with simple rules</li>
</ul>
<p>像围棋，非常简单的规则可以得到一个很有意思的过程，可以从过程中抽取一些概念，得到一些人类推理的知识。然而现实生活中规则太多，不一定是个很好的研究开端。</p>
<p>游戏平台作为数据做研究也存在一些问题：</p>
<ul>
<li>Algorithm is slow and data-inefficient<br>人玩游戏玩几盘就好了，计算机要大量的数据，虽然道最后计算机可以玩的很好</li>
<li>require a lot of resources<br>研究限于比较大的公司</li>
<li>abstract game to real-world<br>游戏能不能扩展到现实世界是个很大的问题<br>让游戏更真实 =&gt; 现在的游戏越来越真实，和现实生活非常接近</li>
<li>hard to benchmark the progress</li>
</ul>
<p>显而易见，解决方案是：<br>=&gt; better algorithm/system<br>=&gt; better environment</p>
<p>这两个都是目前游戏 AI 的研究方向，还有 domain transfer，也是一个研究方向。</p>
<blockquote>
<p>Even with a super-super computer, it is not possible to search the entire space.</p>
</blockquote>
<p>很多人以为机器能够搜索游戏的所有可能，所以能胜过人类，其实这是一个误解。我们能做的是有限搜索，从当前局面出发，哪一步是最好的，extensive search =&gt; evaluation</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.3.png" class="ful-image" alt="6.3.png">
<p>星际这样的游戏，可能的步数是指数级的，怎么做还是个开放性的问题</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.4.png" class="ful-image" alt="6.4.png">
<p>围棋用深度学习的方法 CNN 学出评估函数。怎么估计下一步怎么走？怎么评估？</p>
<p><strong>How to model policy/value function?</strong><br><strong>traditional approach</strong></p>
<ul>
<li>Many manual steps</li>
<li>Conflicting parameters, not scalable<br>有些时候规则是冲突的，大师没办法直观的告诉 ai 什么时候用哪条规则，有的时候是看直觉的，ai 没法学</li>
<li>require strong domain knowledge</li>
</ul>
<p><strong>deep learning</strong></p>
<ul>
<li>End-to-end training<br>lots of data, less tuning</li>
<li>minimal domain knowledge</li>
<li><p>amazing performance</p>
<p>​<br>Case study: AlphaGo   依靠 Monte Carlo Tree Search, aggregate win rates, and search towards the good nodes. 从根节点一路找最大概率走到叶节点，这样的好处是如果发现有些招数很糟糕，那么走了两步就不会继续往下走了，如果发现有些招数不错，可能会一路走下去，走个五六十层，这样可能会发现一些很有意思的招数。</p>
</li>
</ul>
<p>主要策略思想<br><strong>Policy network：</strong> 根据大量人类棋谱学出来<br><strong>Value network: </strong> 网络自己学，把状态中某个步骤拿出来，给每个状态提供一个标定，拿出来训练</p>
<p><strong>future work</strong></p>
<ul>
<li>richer game scenarios<br> multiple base(expand? Rush? Defending?)<br> ​more complicated units 精细控制每个决定，现在智能控制9个</li>
<li>more realistic action space<br>Assign one action per unit</li>
<li>model-based reinforcement learning<br>MCTS with perfect information and perfect dynamics also achieves ~70%<br>现在游戏都是慢慢摸索的，然而对复杂的游戏需要对游戏有大致估计</li>
<li>self-play(Trained AI versus Trained AI)<br>自对弈</li>
</ul>
<h2 id="互联网数据下的模型探索"><a href="#互联网数据下的模型探索" class="headerlink" title="互联网数据下的模型探索"></a>互联网数据下的模型探索</h2><blockquote>
<p>盖坤博士，阿里，P9,阿里妈妈精准展示广告投放</p>
</blockquote>
<p><a href="https://arxiv.org/pdf/1704.05194.pdf" target="_blank" rel="external">Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction</a><br><a href="https://arxiv.org/pdf/1706.06978.pdf" target="_blank" rel="external">Deep Interest Network for Click-Through Rate Prediction</a></p>
<h3 id="互联网数据和经典模型"><a href="#互联网数据和经典模型" class="headerlink" title="互联网数据和经典模型"></a>互联网数据和经典模型</h3><p>互联网数据业界经典的处理方法，典型问题：CTR 预估(点击率预估)</p>
<p><strong>数据特点</strong></p>
<ul>
<li><strong>样本量大</strong> 百亿样本</li>
<li><strong>特征维度大</strong> 无损表示<br>id 特征，原始特征，稀疏的鉴别式特征，轻松超十亿级<br>原始特征，用户特征+物料特征<br>加上交叉特征，笛卡尔积之类的，轻松上千亿</li>
<li><strong>稀疏</strong>数据</li>
</ul>
<p><strong>经典做法</strong></p>
<ul>
<li>简单线性模型 Logistic Regression<br>线性模型+sigmoid一个非线性变换，变成一个概率模式</li>
<li>稀疏正则 L1-Norm 特征筛选<br>压制不太重要的特征</li>
<li>处理非线性：人工特征工程<br>LR 是线性模型，能力有限，要挖掘非线性特征，只能做人工特征，笛卡尔积，做交叉，做种种特征</li>
</ul>
<p><strong>问题</strong></p>
<ul>
<li><strong>人工能力有限</strong>，很难对非线性模式挖掘完全重复</li>
<li>依赖人力和领域经验，方法推广到其他问题的代价大：<strong>不够智能</strong></li>
</ul>
<p><strong>已有的非线性模型</strong></p>
<ul>
<li><strong>Kernel 方法(kernel svm)</strong><br>复杂度太高，一般来说光存储 kernel 矩阵就是数据量平方级</li>
<li><strong>Tree base 方法(如 GBDT)</strong><br>在低维强特征上表现非常好，但在大规模弱特征上(如 id 特征)表现不行<br>​实际上是树的缺点，假如说是 user id, item id 两个信息，建树会带来一个灾难，每个叶子节点在一维特征上做 split，意味着来判断某个特征是不是 id，跟到叶子路径：if(user id == useri &amp;&amp; item id == itemj) 条件判断，变成了根到叶子的组合判断，就变成了一个记忆，判断为记忆历史行为，缺乏推广性</li>
<li><strong>矩阵分解(Topic Model, LDA 等)</strong><br>适用于两种 id 的情况，不适合多种 id 输入</li>
<li><strong>Factorization machines</strong><br>只拟合有限次关系(二次关系)<br>无法拟合其他非线性关系：例如三种特征的交叉，值的高阶变换等</li>
</ul>
<p><strong>我们需要的特性</strong></p>
<ul>
<li>足够强的非线性拟合能力</li>
<li>良好的泛化能力</li>
<li>规模化能力</li>
</ul>
<h3 id="分片线性模型和学习算法-MLR"><a href="#分片线性模型和学习算法-MLR" class="headerlink" title="分片线性模型和学习算法 MLR"></a>分片线性模型和学习算法 MLR</h3><p>分片线性模型。11 年在阿里提出的方法。采用分而治之的思想，把数据区域分成多个区域，每个区域用一个简单的模型去预测，然后把不同区域聚合起来。<img src="6.5.png" alt="6.5"></p>
<p>分片数为 1 就是一个线性模型，分片数过多会过拟合，实际过程中是用一个搜索的方法来确定分片数。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.6.png" class="ful-image" alt="6.6.png"></p>
<p>分片用 softmax，预测模型用 LR，实际就是一个 MOE 模型，外面再加一个 LR 级联<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.7.png" class="ful-image" alt="6.7.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.8.png" class="ful-image" alt="6.8.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.9.png" class="ful-image" alt="6.9.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.10.png" class="ful-image" alt="6.10.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.11.png" class="ful-image" alt="6.11.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.12.png" class="ful-image" alt="6.12.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.13.png" class="ful-image" alt="6.13.png"></p>
<h3 id="大规模-ID-特征-MLR-实践"><a href="#大规模-ID-特征-MLR-实践" class="headerlink" title="大规模 ID 特征 + MLR 实践"></a>大规模 ID 特征 + MLR 实践</h3><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.14.png" class="ful-image" alt="6.14.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.15.png" class="ful-image" alt="6.15.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.16.png" class="ful-image" alt="6.16.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.17.png" class="ful-image" alt="6.17.png">
<h3 id="深层用户兴趣分布网络"><a href="#深层用户兴趣分布网络" class="headerlink" title="深层用户兴趣分布网络"></a>深层用户兴趣分布网络</h3><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.18.png" class="ful-image" alt="6.18.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.19.png" class="ful-image" alt="6.19.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.20.png" class="ful-image" alt="6.20.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.21.png" class="ful-image" alt="6.21.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.22.png" class="ful-image" alt="6.22.png">
<h2 id="认知分析-透过机器重新审视商业本质"><a href="#认知分析-透过机器重新审视商业本质" class="headerlink" title="认知分析-透过机器重新审视商业本质"></a>认知分析-透过机器重新审视商业本质</h2><blockquote>
<p>杨洋，商业认知分析平台iPIN创始人兼CEO。创办iPIN前，杨洋曾在美国国家旅游与电子商务实验室（NLTeC）从事搜索引擎研究，曾师从世界著名信息科学家Rajiv Banker和Pei-yu Chen从事多年大规模众包集智数据分析和研究，并获得博士学位，曾任哈尔滨工业大学管理学院副教授。此外还有过多次互联网创业经历，并曾在NASDAQ上市公司YY Inc.担任全球化负责人。</p>
</blockquote>
<p>人对信息的处理过程，<strong>感知 -&gt; 认知 -&gt; 分析 -&gt; 决策</strong>。人类对认知的理解还不是很成熟，这也是人工智能的天花板之一，如何让机器去掌握人类常识。</p>
<p>从生物学／物理学／哲学／社会学／经济学／市场心理学／神经科学各个角度阐述了什么是认知。比如说在我们看来，信任/不信任是同一个维度的问题，然而神经科学发现不是，你可以同时信任一个人，不信任一个人，可以爱一个人，同时恨一个人。无论哪个领域，整体的逻辑差不多是：</p>
<blockquote>
<p>认知是<strong>真相</strong>在具体<strong>场景</strong>下的<strong>投影</strong></p>
</blockquote>
<p>实现机器认知的条件</p>
<ul>
<li>信息可靠</li>
<li>信息充分</li>
<li>精细建模<br>如何对小规模数据敏感，dl 很难达到</li>
<li>不懂就“问”<br>机器能主动发问</li>
</ul>
<p>还讲了一些具体应用，个人发展应用类的如完美志愿，涉及到生涯规划，用机器学习的方法来看人是怎么发展的，让机器去学习总结大量的(潜)规则，再如前程导航，SCCT 理论来规划你的人生；企业发展应用如人才分析引擎，把不可矢量的东西都矢量化，从认知层面去做计算，等等。</p>
<h2 id="用人工智能打造教学机器人提升十倍教育效率"><a href="#用人工智能打造教学机器人提升十倍教育效率" class="headerlink" title="用人工智能打造教学机器人提升十倍教育效率"></a>用人工智能打造教学机器人提升十倍教育效率</h2><blockquote>
<p>栗浩洋 「非你莫属」BOSS，社交APP「朋友印象」创始人，国内第一家人工智能自适应网络教育公司「乂学教育」创始人。黑马会上海会长，黑马连营主任导师，央视二套「实战商学院」导师，第一财经《中国经营者》特约嘉宾，《商界时尚》杂志封面人物。曾先后被福布斯、第一财经、i黑马、36Kr等100多家媒体采访报道。</p>
</blockquote>
<p>总体逻辑，实现<strong>有教无类，教无定法，因材施教</strong>。</p>
<p>MOOC &amp; 传统教学无区别对待所有的学生和所有知识点，每个人的起点和终点不一样，然而老师教的是线性的。智适应系统，能精确侦测不同学生的<strong>知识漏洞</strong>，利用知识状态空间+知识空间理论来精准定位学生知识点掌握状态，还可以从大量数据中发现强关联的知识点和弱关联知识点。同时，精准把知识点分拆定位；又由于每个学生掌握一个知识点所需的时间是不同的，逻辑方向是不同的，所以要做个性化的匹配和学习内容推荐</p>
<p>个性化匹配</p>
<ul>
<li>学生画像+内容侧写</li>
<li>机器学习+概率图模型</li>
<li>个性化学习内容和路径匹配</li>
</ul>
<p>哎，感觉把我们当投资人或者顾客了。。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/7.1.png" class="ful-image" alt="7.1.png"></p>
<h1 id="智能助手专场"><a href="#智能助手专场" class="headerlink" title="智能助手专场"></a>智能助手专场</h1><p>这一场本来应该是我最感兴趣的一场，无奈嘉宾讲的都很泛，可能是因为中间设计的技术太多，没法展开吧。</p>
<h2 id="远程语音交互的技术挑战和商业思考"><a href="#远程语音交互的技术挑战和商业思考" class="headerlink" title="远程语音交互的技术挑战和商业思考"></a>远程语音交互的技术挑战和商业思考</h2><blockquote>
<p>陈孝良，北京声智科技有限公司。</p>
</blockquote>
<p>人机交互的升级大致来说分三个时代，最开始是<strong>PC互联网时代</strong>，主要依赖键盘、鼠标，后来是<strong>移动互联网时代</strong>，以智能机为代表，大量依赖触摸屏，到现在的<strong>AI互联网时代</strong>，以远程语音交互为主要交互方式，当然这不是唯一的，还有其他的方式辅助。</p>
<p><strong>技术挑战：</strong> 远场语音交互技术瓶颈在于声学和场景<br>近场可以近似理解为只是实验室的理想环境，远场要考虑更多</p>
<ul>
<li>语音识别率 95%，但用户体验不好<br>行业目标：以语音控制模式打造极致(速度、精度)产品体验<br>核心瓶颈：远场语音识别、远场场景适配、NLP 精确反馈</li>
<li>语义理解技术有本质性突破<br>行业目标：拟人化，全功能型产品，实现听你所言，知你所想<br>核心瓶颈：声光电多种传感的融合，NLP 技术的实质性突破</li>
</ul>
<p><strong>技术挑战：</strong></p>
<ul>
<li>器件<br>需要升级，然而麦克风的性能、精度，核心技术不在国内，标量麦克风=&gt;矢量麦克风，国内相对落后</li>
<li>芯片</li>
<li>算法<br>如离线关键词识别(语音唤醒)、离线声纹识别(Voice ID)，AEC 回声消除，Adaptive Beamforming, Speech Dereverberation，声源定位技术，孤立样本学习，深度强化学习</li>
<li>商业<br>语音交互产业化的风险在于不确定的启动周期，到了启动周期爆发时间就只有三年<br>产品，内容和服务，标准和知识产权，</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.1.png" class="ful-image" alt="6.1.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/6.2.png" class="ful-image" alt="6.2.png">
<h2 id="对话即应用：过去仍在，未来已来"><a href="#对话即应用：过去仍在，未来已来" class="headerlink" title="对话即应用：过去仍在，未来已来"></a>对话即应用：过去仍在，未来已来</h2><blockquote>
<p>戴帅湘，蓦然认知 CEO前百度主任架构师，并长期担任百度 Query 理解方向负责人，荣获第一个百度语义技术的最高奖。</p>
</blockquote>
<p>感觉讲的更多是 IoT 的内容，讲了未来发展趋势，几个融合</p>
<ul>
<li>VOI 和 GUI 的融合<br>GUI 人适应机器，处理简单的、特定的任务，VOI，机器适应人，可以处理相对模糊的，复杂的任务</li>
<li>多场景融合<br>关注长尾的需求</li>
<li>设备之间的协同<br>比如说车+家的互联，把家里的空调调到24度</li>
<li>知识和服务的融合</li>
</ul>
<h2 id="设备时代结束，助手时代到来"><a href="#设备时代结束，助手时代到来" class="headerlink" title="设备时代结束，助手时代到来"></a>设备时代结束，助手时代到来</h2><blockquote>
<p>刘耀平，暴风TV CEO，被誉为“互联网电视第一人”。</p>
</blockquote>
<p><strong>听到(DSP) =&gt; 听清(ASR) =&gt; 听懂(NLP) =&gt; 做到(SKILL)</strong></p>
<p>介绍了暴风家庭助手，感觉像 echo show 的中文版，视频看上去不错，不知道真正体验如何。</p>
<p>讲了未来趋势：</p>
<ul>
<li>多设备协同计算(多助手)，未来一定是助手与助手之间的联网和协同，</li>
<li>多屏协同服务，服务在多屏呈现，屏幕无处不在</li>
<li>跨空间场景迁移</li>
</ul>
<p>未来会产生家庭社交平台，人与助手，助手与助手，人与人的交互。</p>
<h1 id="AI-专场"><a href="#AI-专场" class="headerlink" title="AI+专场"></a>AI+专场</h1><h2 id="机器写稿技术与应用"><a href="#机器写稿技术与应用" class="headerlink" title="机器写稿技术与应用"></a>机器写稿技术与应用</h2><blockquote>
<p>万小军，北京大学计算机科学技术研究所研究员。</p>
</blockquote>
<p>运用到机器写稿技术的主要单位有</p>
<ul>
<li>媒体：新华社、头条、南都等</li>
<li>互联网企业：微软、百度、腾讯、头条等</li>
<li>科研院所</li>
</ul>
<p>写稿类型一般有体育、财经、民生、娱乐新闻，以及绝句、诗歌等。</p>
<p><strong>原创 vs 二次创作</strong><br>机器写稿有两种方式，一种是原创，一种是二次创作。原创一般是之前没有稿件，只有结构化的数据，借助结构化的数据去生成新的稿件。比如说写一个天气预报的报道，或者年报、财报都直接可以从数据中生成。而关于一个已经有相关报道的事件，我们可以借助这些报道进行一些拼凑、改写成为新的稿件，这就是二次创作。</p>
<p><strong>基础技术研究</strong></p>
<ul>
<li>自动文摘</li>
<li>自然语言生成</li>
<li>文本推荐</li>
<li>文本复述</li>
</ul>
<p><strong>应用技术研究</strong></p>
<ul>
<li>新闻资讯自动生成</li>
<li>新闻综述自动生成</li>
<li>用户评论自动生成</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/8.1.png" class="ful-image" alt="8.1.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/8.2.png" class="ful-image" alt="8.2.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/8.3.png" class="ful-image" alt="8.3.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/8.4.png" class="ful-image" alt="8.4.png">
<p>一些应用：</p>
<ol>
<li>看明星的微博，判断是否有新闻价值，如果有，结合微博、评论信息、背景信息，生成新闻；</li>
<li>新闻资讯的生成，长短可控，几十字、上千字的简讯／资讯；</li>
<li>新闻综述自动生成：根据同一事件的多篇新闻报道，自动生成篇幅较长的事件综述。用 wikinews 做的实验，主要过程：新闻采集 =》(子话题选择)段落划分 =》段落排序 =》段落选择与合并</li>
<li>用户评论自动生成，根据制定的用户观点数据(产品特性+评分)，自动生成对应的产品评论，基于深度学习模型，根据产品特性和评分，生成自然语言的评论<img src="http://ox5l2b8f4.bkt.clouddn.com/images/CCF-GAIR%20%E5%8F%82%E4%BC%9A%E7%AC%94%E8%AE%B0/8.5.png" class="ful-image" alt="8.5.png">
</li>
</ol>
<p>趋势展望</p>
<ul>
<li>让稿件具有态度和立场，更加人性化</li>
<li>通过推理与归纳，撰写深度报道</li>
</ul>
<h2 id="智影：AI-让视频更简单"><a href="#智影：AI-让视频更简单" class="headerlink" title="智影：AI 让视频更简单"></a>智影：AI 让视频更简单</h2><blockquote>
<p>康洪文，慧川智能 CEO</p>
</blockquote>
<p>感觉很酷炫的样子，通过明星识别、场景识别、行为识别以及视频标签化后，可以根据文字来自动生成配套的视频。举个应用的例子，如果微信公众号的很多文章都可以配上配套的短视频，是不是很棒！</p>
<p><a href="http://api.zenvideo.cn/#/" target="_blank" rel="external">智影</a></p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>结尾引用某嘉宾的话，未来的世界<strong>无商业不智能，无智能不商业</strong>。从消费和生产两方面来看，<strong>消费互联网解决了高效的流通，产业互联网解决了正确的生产。</strong>看吧，我们赶上了最好的时代，同志们加油～ (P.S.最后和来自各大高校的童鞋以及雷锋网的小伙伴们面了个基，可惜奕欣姐姐嫌弃合照就不上图了。。)</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;回国后参加的第一场大规模的人工智能峰会，感觉收获还是很多的，对部分之前学过的东西做了一遍梳理，对当前工业界的发展现状有了一定了解，对学术界的最新进展有了些体会，最后还结识了一批志同道合的朋友，值回票价。这一篇作为峰会的笔记，记录一些我认为重要的东西，有些零散，参加的场次有限，看官们见谅～&lt;br&gt;
    
    </summary>
    
      <category term="Others" scheme="http://www.shuang0420.com/categories/Others/"/>
    
    
      <category term="IoT" scheme="http://www.shuang0420.com/tags/IoT/"/>
    
      <category term="chatbot" scheme="http://www.shuang0420.com/tags/chatbot/"/>
    
      <category term="物联网" scheme="http://www.shuang0420.com/tags/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
      <category term="AI" scheme="http://www.shuang0420.com/tags/AI/"/>
    
      <category term="CV" scheme="http://www.shuang0420.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>NLP 笔记 - Neural Machine Translation</title>
    <link href="http://www.shuang0420.com/2017/07/10/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/"/>
    <id>http://www.shuang0420.com/2017/07/10/NLP 笔记 - Machine Translation-Neuron models/</id>
    <published>2017-07-10T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>持续填坑中– <a href="http://www.shuang0420.com/2017/05/01/NLP%20笔记%20-%20Machine%20Translation/">NLP 笔记 - Machine Translation</a>主要讲了机器翻译的传统方法，这一篇介绍基于深度学习的机器翻译方法。<br><a id="more"></a></p>
<p>本文涉及的论文原文：</p>
<ul>
<li>Bengio et al. (2003), <a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="external">A Neural Probabilistic Language Model</a></li>
<li>Devlin et al. (2014), <a href="http://www.aclweb.org/anthology/P14-1129" target="_blank" rel="external">Fast and Robust Neural Network Joint Models for Statistical Machine Translation</a></li>
<li>Sutskever et al. (2014), <a href="https://arxiv.org/abs/1409.3215" target="_blank" rel="external">Sequence to Sequence Learning with Neural Networks</a></li>
<li>Bahdanau et al. (2014), <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
<li>Xu et al. (2015) <a href="https://arxiv.org/abs/1502.03044" target="_blank" rel="external">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. ICML’15</a></li>
<li>Luong et al. (2015)<a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj3qYKMiuDVAhVHXbwKHadFByAQFgg8MAI&amp;url=https%3A%2F%2Fnlp.stanford.edu%2Fpubs%2Femnlp15_attn.pdf&amp;usg=AFQjCNGsQHAEQhC6dQuVyiHWcEmajCM-6w" target="_blank" rel="external">Effective approaches to attention based neural machine translation</a></li>
</ul>
<h1 id="Neural-MT"><a href="#Neural-MT" class="headerlink" title="Neural MT"></a>Neural MT</h1><p><strong>Neural MT(NMT)</strong>的定义：</p>
<blockquote>
<p>Neural Machine Translation is the approach of modeling the <strong>entire</strong> MT process via <strong>one</strong> big artificial neural netowrk.</p>
</blockquote>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/phrase_base_nmt.png" class="ful-image" alt="phrase_base_nmt.png">
<p>用一个大的神经网络来给整个机器翻译的过程建模，目前主流的结构是 <strong>Neural encoder-decoder architectures</strong>，最<strong>基本的思想</strong>是 encoder 将输入文本转化为一个向量， decoder 根据这个向量生成目标译文，编码解码开始均用 RNN 实现，由于普通 RNN 存在梯度消失/爆炸的问题，通常会引入 LSTM。本篇会介绍 NMT 发展的一些重要节点。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/encodedecode.png" class="ful-image" alt="encodedecode.png">
<blockquote>
<p><strong>一句话解释 encoder-decoder architectures:</strong> Encoder compresses input series into one vector Decoder uses this vector to generate output</p>
</blockquote>
<h2 id="Big-wins-of-Neural-MT"><a href="#Big-wins-of-Neural-MT" class="headerlink" title="Big wins of Neural MT"></a>Big wins of Neural MT</h2><ul>
<li><strong>End-to-end training</strong><br>所有参数同时被训练优化</li>
<li><strong>Distributed representations share strength</strong><br>分布式表达更好的挖掘了单词／词组之间的相似性</li>
<li><strong>Better exploitation of context</strong><br>可以使用更广泛的上下文，无论是 source 还是 target text</li>
<li><strong>More fluent text generation</strong><br>生成的文本质量更高</li>
</ul>
<p>But…</p>
<h2 id="Concerns"><a href="#Concerns" class="headerlink" title="Concerns"></a>Concerns</h2><ul>
<li><strong>Black box component models for reordering, transliteration, etc.</strong></li>
<li><strong>Explicit use of syntactic or semantic structures</strong><br>没有显性的用到句法／语义结构特征</li>
<li><strong>Explicit use of discourse structure, anaphora, etc.</strong><br>没法显性利用指代消解之类的结果</li>
</ul>
<h1 id="NNLM-Bengio-et-al-2003"><a href="#NNLM-Bengio-et-al-2003" class="headerlink" title="NNLM: Bengio et al. (2003)"></a>NNLM: Bengio et al. (2003)</h1><p><a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="external">A Neural Probabilistic Language Model</a>，这篇论文为之后的 NMT 打下了基础。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/nnlm.png" class="ful-image" alt="nnlm.png">
<p>传统的 Language model 有一定缺陷：</p>
<ul>
<li>不能把 ngram 中 n 以外的词考虑进去<br>n 越大句子连贯性越好，但同时数据也就越稀疏，参数也越多</li>
<li>不能考虑单词之间的相似度<br>不能从 the cat is walking in the bedroom 学习到 a dog was running in a room</li>
</ul>
<p><strong>Neural network language model(NNLM)</strong> 可以解决上面的两个问题。主要理解上图，先来定义一些参数：<br><strong>h:</strong> number of hidden units<br><strong>m:</strong> number of features associated with each word<br><strong>b:</strong> output biases, with |V| elements<br><strong>d:</strong> hidden layer biases, with h elements<br><strong>V:</strong> word dictionary $w_1, …w_T \in V$<br><strong>U:</strong> hidden-to-output weights, |V|*h matrix<br><strong>W:</strong> word features to output weights, |V|*(n-1)m matrix<br><strong>H:</strong> hidden layer weights, h*(n-1)m matrix<br><strong>C:</strong> word features C, |V|*m matrix</p>
<p>再来看一下<strong>目标函数:</strong><br> $$f(w_t,…,w_{t-n+1})=\hat P(w_t|w_1^{t-1})$$</p>
<p>目标函数包含了两个部分</p>
<ul>
<li>Matrix C，用来 <strong>map</strong> word_id 和 word feature vector，维度是 |V|*m</li>
<li>g，用来 <strong>map</strong> 这个上下文输入的 feature vector 和下一个单词 $w_t$ 在 V 上的条件概率的分布，g 用来估计 $\hat P(w_t=i|w_1^{t-1})$<br>$$f(i, w_{t-1},…,w_{t-n+1})=g(i,C(w_{t-1}),…,C(w_{t-n+1}))$$</li>
</ul>
<p>也就是说 f 是两个 mapping C 和 g 的组合，词向量矩阵 C 所有单词共享。模型有两个 hidden layer，第一部分的输入是上下文单词 $w_{t-1},…w_{t-n+1}$ 的 word_id，每个 word_id 在 C 中寻找到对应的 word vector，vector 相加得到第二部分的输入， 与 H 相乘加一个 biases 用 tanh 激活，然后与 U 相乘产生一个得分向量，再进入 softmax 把得分向量转化成概率分布形式。</p>
<p>前向传播的式子就是：<br>$$y=b+Wx+Utanh(d+Hx)$$</p>
<p>其中 x 是 word features layer activation vector，由输入词向量拼接而成<br>$$x(C(w_{t-1}), C(w_{t-1}), …, C(w_{t-n+1}))$$</p>
<p>最后的 softmax 层，保证所有概率加和为 1<br>$$\bar P(w_t|w_{t-1},…,w_{t-n+1})={e^{y_{w_t}} \over \sum_ie^{y_i}}$$</p>
<p>通过在训练集上最大化 penalized log-likelihood 来进行训练，其中 $R(\theta)$ 是正则项，如下<br>$$L={1 \over T}\sum_tlogf(w_t,w_{t-1},…,w_{t-n+1;\theta})+R(\theta)$$</p>
<p>用 SGD 梯度下降来更新 U 和 W<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/sgd.png" class="ful-image" alt="sgd.png"></p>
<p>参数集合$\theta = (b,d,W,U,H,C)$，参数量： |V|(1+mn+h)+h(1+(n-1)m)，dominating factor 是|V|(nm+h)</p>
<p>最后提一下两个改进，一个是加上图中的曲线部分，直接把词向量和输出连接起来(direct connections from the word features to the output)，另一个是和 ngram 相结合的 mixture model。看一下在 Brown Corpus 上的评估结果:</p>
<ul>
<li>n-gram model(Kneser-Ney smoothing): 321</li>
<li>neural network language model: 276</li>
<li>neural network + ngram: 252</li>
</ul>
<h1 id="NNJM-Devlin-et-al-2014"><a href="#NNJM-Devlin-et-al-2014" class="headerlink" title="NNJM: Devlin et al. (2014)"></a>NNJM: Devlin et al. (2014)</h1><p><a href="http://www.aclweb.org/anthology/P14-1129" target="_blank" rel="external">Fast and Robust Neural Network Joint Models for Statistical Machine Translation</a>，把 Bengio et al. (2003) 的 model 转化为一个 translation model，简单来说就是把 n-gram target language model 和 m-word source window 相结合，来创建一个 MT decoding feature，可以简单的融入任何的 SMT decoder。</p>
<h2 id="Neural-Network-Joint-Models-NNJM"><a href="#Neural-Network-Joint-Models-NNJM" class="headerlink" title="Neural Network Joint Models(NNJM)"></a>Neural Network Joint Models(NNJM)</h2><p>条件概率模型，generate the next English word <strong>conditioned on</strong></p>
<ul>
<li>The previous n English words you generated $e_{i-1}, e_{i-2}…$</li>
<li>The aligned source word and its m neighbors $…f_{a_i-1}, f_{a_i}, f_{a_i-2}…$</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/Devlin%20et%20al.png" class="ful-image" alt="Devlin%20et%20al.png">
<p>$$P(T|S) \approx \prod^{|T|}_{i=1}P(t_i|t_{i-1},…,t_{i-n+1}, S_i)$$</p>
<p>假设 target word $t_i$ 只和一个 source word $a_i$ 对齐，我们会关注 source 句子里以 $a_i$ 为中心的一个 window $S_i$，也就是和 target $t_i$ 最相关的 source part。</p>
<p>$$S_i = s_{a_i-{m-1 \over 2}},…,s_{a_i},…,s_{a_i+{m-1 \over 2}}$$</p>
<p>1) 如果 $e_i$ 只和一个 source word 对齐，那么 $a_i$ 就是对齐的那个单词的 index<br>2) 如果 $e_i$ 和多个 source word 对齐，那么 $a_i$ 就是在中间的那个单词的 index<br>3) 如果 $e_i$ 没有对齐的 source word，那么就继承最邻近(右边)的 aligned word 的 affiliation</p>
<p>affiliation 用先验的基于规则的 word alignment 来推。</p>
<p>模型的训练过程和 NNLM 相似，不过是多了个 corpus 而已。最大化训练数据的 log-likelihood<br>$$L=\sum_ilog(P(x_i))$$</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/NNJM1.png" class="ful-image" alt="NNJM1.png">
<h2 id="Self-normalization"><a href="#Self-normalization" class="headerlink" title="Self-normalization"></a>Self-normalization</h2><p>论文还提出了一种训练神经网络的新方法 – self-normalized 技术。由于训练的 cost 主要来自输出层在整个 target vocabulary 上的一个 softmax 计算，<strong>self-normalization</strong> 用近似的概率替代实际的 softmax 操作，思路很简单，主要改造一下目标函数。先来看一下 softmax log likelihood 的计算：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/Devlin%20formula.png" class="ful-image" alt="Devlin%20formula.png"><br>想象一下，如果 $log(Z(x))=0$，也就是 $Z(x)=1$，那么我们就只用计算输出层第 r 行的值而不用计算整个 matrix 了，所以改造下目标函数，变成<br>$$<br>\begin{aligned} \<br>L =\sum_i[log(P(x_i))-\alpha(log(Z(x_i))-0)^2] \\<br>&amp; =\sum_i[log(P(x_i))-\alpha log^2(Z(x_i))] \\<br> \end{aligned}<br>$$</p>
<p>output layer bias weights 初始化为 log(1/|V|)，这样初始网络就是 self-normalized 的了，decode 时，只用把 $U_r(x)$ 而不是 $log(P(x))$ 作为 feature score，这大大加快了 decoding 时的 lookup 速度(~15x)。其中 $\alpha$ 是一个 trade-off 参数，来平衡网络的 accuracy 以及 mean self-normalization error</p>
<p>其他优化如 pre-computing the (first) hidden layer 等。</p>
<h2 id="Variations"><a href="#Variations" class="headerlink" title="Variations"></a>Variations</h2><p>MT decoder 有两类，一个是 <strong>decoder</strong>方法，用的是 string-to-dependency hierarchical decoder (Shen et al., 2010)，一个是 <strong>1000-best rescoring</strong> 方法，用的 feature 是 5-gram Kneser-Ney LM，Recurrent neural network language model (RNNLM) (Mikolov et al., 2010)</p>
<p>不同模型的影响<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/res1.png" class="ful-image" alt="res1.png"><br>​<br>网络设置的影响<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/Devlin%20improve.png" class="ful-image" alt="Devlin%20improve.png"></p>
<p>模型还有一些变种比如说<strong>翻译方向(source-to-target S2T, target-to-source T2S)</strong>，<strong>language model 的方向(left-to-right L2R, right-to-left R2L)</strong>，<strong>NNTM(Neural Network Lexical Translation Model)</strong>，对 many-to-one 问题用 NULL 解决，对 one-to-many 问题用 token concatenated 解决，训练和评估与 NNJM 相似。</p>
<h1 id="Sutskever-et-al-2014"><a href="#Sutskever-et-al-2014" class="headerlink" title="Sutskever et al. (2014)"></a>Sutskever et al. (2014)</h1><p><a href="https://arxiv.org/abs/1409.3215" target="_blank" rel="external">Sequence to Sequence Learning with Neural Networks</a></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/2014_1.png" class="ful-image" alt="2014_1.png">
<p>使用了 encoder-decoder 框架，用多层的 LSTM 来把输入序列映射到一个固定维度的向量，然后用另一个深层的 LSTM 来 decode 这个向量，得到 target sequence，第二个 LSTM 实际上就是一个 NNLM 不过 conditioned on input sequences。主要的改变：</p>
<ul>
<li>fully <strong>end-to-end</strong> RNN-based translation model</li>
<li><strong>two</strong> different RNN<br>encode the source sentence using one LSTM<br>generate the target sentence one word at a time using another LSTM</li>
<li><strong>reverse</strong> the order of the words in all source sentence(but not target sentences)</li>
</ul>
<p><strong>Encoder</strong>可以看作是一个 <strong>conditional language model</strong> (Bengio et al. ,2003) ，对原始句子，每个词用相应向量表示，每个词都有一个隐含状态 h1，代表这个词以及这个词之前的所有词包含的信息，当找到句尾标记的时候，对应的隐状态也就是 encoder 层的最后一个隐状态就就代表了整个句子的信息。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/cat_ex.png" class="ful-image" alt="cat_ex.png">
<p>然后 <strong>decoder</strong> 对其进行解码，<strong>encoder</strong> 最后一层(最后一个时刻)作为 decoder 第一层，LSTM 能保持中期的记忆，那么解码层的每个隐状态，都包含了已经翻译好的状态以及隐状态，然后输出每个词。具体过程如下图：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/Sutskever%20et%20al.%203.png" class="ful-image" alt="Sutskever%20et%20al.%203.png"></p>
<p>将输入序列倒转喂给 LSTM，能够在 source 和 target 句子间引入许多 short-term dependencies，使得优化问题更加容易。</p>
<p><strong>recurrent activation function</strong> 可以使用：</p>
<ul>
<li>Hyperbolic tangent tanh</li>
<li>Gated recurrent unit [Cho et al., 2014]</li>
<li>Long short-term memory [Sutskever et al., 2014]</li>
<li>Convolutional network [Kalchbrenner &amp; Blunsom, 2013]</li>
</ul>
<p>主要的贡献</p>
<ul>
<li>hard-alignment =&gt; soft-alignment</li>
<li>对长句的泛化能力很好</li>
<li>简单的 decoder</li>
</ul>
<p>关于 <strong>Decoder</strong>，论文 baseline 用了 rescoring 1000-best 的策略，实验用了一个 <strong>left-to-right beam search decoder</strong> 结果有一定提升。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/Sut%20res.png" class="ful-image" alt="Sut%20res.png"></p>
<p>还可以提一句的是，另一种做法是把 encoder 的最后一层喂给 decoder 的每一层，这样就不会担心记忆丢失了。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/decoder2.png" class="ful-image" alt="decoder2.png">
<h1 id="乱入：Decoders"><a href="#乱入：Decoders" class="headerlink" title="乱入：Decoders"></a>乱入：Decoders</h1><p>在模型能计算 P(T|S) 后，问题来了，怎样才能找出最可能的译文 T 呢？<br>$$\bar T = argmax_T(P(T|S))$$</p>
<h2 id="Exhaustive-Search"><a href="#Exhaustive-Search" class="headerlink" title="Exhaustive Search"></a>Exhaustive Search</h2><p>最开始的想法当然是生成所有翻译，然后用 language model 打分，挑概率最大的了。<strong>BUT!! DO NOT EVEN THINK OF TRYING IT OUT!!!</strong>译文数量是词表的指数级函数，这还用想么？！</p>
<h2 id="Ancestral-Sampling"><a href="#Ancestral-Sampling" class="headerlink" title="Ancestral Sampling"></a>Ancestral Sampling</h2><p>$$x ~ P(x_t|x_1,…,x_n)$$<br>多次取 sample。然而实践中会产生高方差的结果，同一个句子每次翻译结果都不一样，不大好吧？</p>
<h2 id="Greedy-Search"><a href="#Greedy-Search" class="headerlink" title="Greedy Search"></a>Greedy Search</h2><p>$$x_t=argmax\hat x_tP(\hat x_t|x_1,…,x_n)$$<br>每次选取当前最可能的那个单词，然而，这显然不能达到全局最优，每一步都会影响到后面的部分。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/greedySearch.png" class="ful-image" alt="greedySearch.png"></p>
<h2 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/beamForm.png" class="ful-image" alt="beamForm.png">
<p>每个时刻记录 k 个最可能的选项，相当于剪枝，然后在这些选项中进行搜索<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/beamSearch.png" class="ful-image" alt="beamSearch.png"></p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/decoderResults.png" class="ful-image" alt="decoderResults.png">
<h1 id="Attention-Bahdanau-et-al-2014"><a href="#Attention-Bahdanau-et-al-2014" class="headerlink" title="Attention: Bahdanau et al. (2014)"></a>Attention: Bahdanau et al. (2014)</h1><p><a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="external">Neural Machine Translation by Jointly Learning to Align and Translate</a>，之前的 encoder-decoder 模型是将 source sentence 编码成一个固定长度的 vector，然后 decoder 产生 target sentence，这就要求 neural network 要能够把 source sentence 所有必要信息都压缩到一个 fixed-length vector 里，这对长句并不友好。我们希望在产生一个 target word 的时候只关注部分的 source word。这一篇提出了一个自动搜寻这样一个要关注的 source word window 的方法，换句话说，每次产生一个单词时，模型会从 source sentence 中搜索到相关信息所在的位置，基于包含了这些位置特征的 context vector 和 previous generated words，来生成下一个单词。这也就是<strong>注意力模型</strong>在机器翻译中的应用。</p>
<blockquote>
<p>一句话解释： Attention Mechanism predicts the output $y_t$ with a weighted average context vector $c_t$, not just the last state</p>
</blockquote>
<p>再通俗一点理解，attention 的作用可以看作是一个对齐模型，传统 SMT 我们用 EM 算法来求解对齐，这里做一个隐式的对齐，将 alignment model 用一个 feedforward neural network 参数化，和其他部分一起训练，神经网络会同时来学习 <strong>翻译模型(translation)</strong> 和 <strong>对齐模型(alignment)</strong>。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/phrase_based%20SMT.png" class="ful-image" alt="phrase_based%20SMT.png"><br>attention 效果：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/attention_al.png" class="ful-image" alt="attention_al.png"></p>
<p><strong>具体过程：</strong><br>用一个感知机公式将 source 和 target 的每个词联系起来，$a(h_{i-1},\bar h_j)=v^T_atanh(W_ah_{i-1}+U_ah_j)$，然后通过 softmax 归一化得到一个概率分布，也就是 attention 矩阵，再进行加权平均得到 context vector(可以看作是 annotation 的期望值)。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/attention1.JPG" class="ful-image" alt="attention1.JPG"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/attention2.JPG" class="ful-image" alt="attention2.JPG"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/attention3.JPG" class="ful-image" alt="attention3.JPG"></p>
<p>模型将 input sentence 编码成一系列 vector，然后在 decode 时自适应的选择这些 vector 的一个子集。$a_{ij}$，或者说对应的 $e_{ij}$，反映了 annotation $\bar h_j$ 关于前一个隐状态 $h_{i-1}$ 在决定下一个隐状态 $h_i$ 以及产生 $y_i$ 的重要性。直观的说，这在 decoder 里执行了 attention 机制。decoder 来决定应该对 source sentence 的哪一部分给予关注。通过这个 attention 机制，encoder 不用再将 source 的所有信息压缩到一个定长的 vector 里，信息可以在 annotation 序列中传播，然后由 decoder 来选择性的检索。</p>
<p>Encoder 还可以用双向 RNN 来做，这样每个单词的 annotation 不仅概括了前面单词的信息，还包括了后面单词的信息。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/birnnattention.png" class="ful-image" alt="birnnattention.png">
<h1 id="Attention-优化"><a href="#Attention-优化" class="headerlink" title="Attention 优化"></a>Attention 优化</h1><h2 id="More-Score-Functions"><a href="#More-Score-Functions" class="headerlink" title="More Score Functions"></a>More Score Functions</h2><p>怎么算 alignment score 有下面集中不同的方式，实验表示第二种效果最好。<br><strong>compute alignment weight vector</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/score.png" class="ful-image" alt="score.png"></p>
<h2 id="Global-vs-Local"><a href="#Global-vs-Local" class="headerlink" title="Global vs. Local"></a>Global vs. Local</h2><p>论文<a href="https://arxiv.org/abs/1502.03044" target="_blank" rel="external">Xu et al.2015 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. ICML’15</a> 提到了 attention 可以分为 <strong>hard</strong> 和 <strong>soft</strong> 两种模型，简单理解，<strong>hard attention</strong> 就是从 source sentence 里找到一个能与产生单词 $t^{th}$ 对齐的特定单词，把 $s_{t,i}$ 设为 1，source 里的其他单词硬性认为对齐概率为 0；<strong>soft attention</strong> 就是之前 Bahdanau et al. (2014) 提到的，对 source sentence 每个单词都给出一个对齐概率，得到一个概率分布，context vector 每次是这些概率分布的一个加权和，整个模型其实是平滑的且处处可分的。</p>
<p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj3qYKMiuDVAhVHXbwKHadFByAQFgg8MAI&amp;url=https%3A%2F%2Fnlp.stanford.edu%2Fpubs%2Femnlp15_attn.pdf&amp;usg=AFQjCNGsQHAEQhC6dQuVyiHWcEmajCM-6w" target="_blank" rel="external">Effective approaches to attention based neural machine translation</a> 提出了一个新的 attention 机制 <strong>local attention</strong>，在得到 context vector 时，我们不想看所有的 source hidden state，而是每次只看一个 hidden state 的子集(subset)，这样的 attention 其实更集中，也会有更好的结果。</p>
<p><strong>Global attention</strong> 其实就是 <strong>soft attention</strong>， <strong>local model</strong> 实际相当于 hard 和 soft attention 的一个混合或者说折中，主要是用来降低 attention 的花费，简单来说就是每次计算先用预测函数得到 source 相关信息的窗口，先预估得到一个 aligned position $p_t$，然后往左往右扩展得到一个 focused window [$p_t-D$,$p_t+D$] 取一个类似于 soft attention 的概率分布。和 global attention 不同，这里 $a_i$ 的维度是固定的。</p>
<p>那么关于 local attention 有两个问题。第一个问题是<strong>怎么产生 aligned position</strong>，之前在 Devlin et al. (2014) 里是用规则，这里用 sigmoid function $p_t = S•sigmoid(v^T_p tanh(W_ph_t))$，其中 S 是 source sentence。第二个问题是<strong>怎么来学习这些 position parameters</strong>，像 $W_p$、$h_t$ 这些参数和网络结构中其他参数没有任何关联，怎么学习呢？方法是像 global attention 一样先计算对齐分数 $score(h_t, \bar h_s)$，然后 normalize，这里有一个 trick 是将得到的 $a_t$ 与一个 truncated Gaussian distribution 结合，也就是 $a_t(s)=align(h_t, \bar h_s)exp(-{(s-p_t)^2 \over 2 \sigma^2})$，$\sigma={D \over 2}$，这样我们会只有一个 peak，现在可以用 BP 来学习预测 position，这个模型这时候几乎是 <strong>处处可分的(differentiable almost everywhere)</strong>，这种对齐称为 <strong>predictive alignment(local-p)</strong></p>
<p><strong>local attention</strong> 的训练花费更少，且几乎处处可分(differentiable)</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/local_attention1.png" class="ful-image" alt="local_attention1.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/global_local.png" class="ful-image" alt="global_local.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/effective_res.png" class="ful-image" alt="effective_res.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/effective_res2.png" class="ful-image" alt="effective_res2.png">
<h2 id="Coverage-Doubly-attention"><a href="#Coverage-Doubly-attention" class="headerlink" title="Coverage: Doubly attention"></a>Coverage: Doubly attention</h2><p>论文<a href="https://arxiv.org/abs/1502.03044" target="_blank" rel="external">Xu et al.2015 Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. ICML’15</a>提到的思路，用到机器翻译里就是同时注意原文和译文。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/caption.png" class="ful-image" alt="caption.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/doubly%20attention.png" class="ful-image" alt="doubly%20attention.png">
<h2 id="Linguistic-ideas"><a href="#Linguistic-ideas" class="headerlink" title="Linguistic ideas"></a>Linguistic ideas</h2><ul>
<li>[Tu, Lu, Liu, Liu, Li, ACL’16]: NMT model with coverage-based attention</li>
<li>[Cohn, Hoang, Vymolova, Yao, Dyer, Haffari, NAACL’16]: More substantive models of attention<br> using: position (IBM2) + Markov (HMM) + fertility<br>  (IBM3-5) + alignment symmetry (BerkeleyAligner)</li>
</ul>
<p>一般一个单词最多翻译为两三个单词，如果生成了五六个单词，那么模型可能在重复生成。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Machine%20Translation-Neuron%20models/ling.png" class="ful-image" alt="ling.png"></p>
<h1 id="Current-Research-Direction-on-Neural-MT"><a href="#Current-Research-Direction-on-Neural-MT" class="headerlink" title="Current Research Direction on Neural MT"></a>Current Research Direction on Neural MT</h1><ul>
<li>Incorporation syntax into Neural MT</li>
<li>Handling of morphologically rich languages</li>
<li>Optimizing translation quality (instead of corpus probability)</li>
<li>Multilingual models</li>
<li>Document-level translation</li>
</ul>
<p>到目前为止，我们都是假设在两种语言 F 和 E 之间训练一个模型。但是，世界上有许多种语言，一些研究已经证明能够利用所有语言的数据去训练一个模型。也可以跨语言执行迁移，先在一个语言对上训练模型，然后将其微调用于其他语言对。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;持续填坑中– &lt;a href=&quot;http://www.shuang0420.com/2017/05/01/NLP%20笔记%20-%20Machine%20Translation/&quot;&gt;NLP 笔记 - Machine Translation&lt;/a&gt;主要讲了机器翻译的传统方法，这一篇介绍基于深度学习的机器翻译方法。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Course" scheme="http://www.shuang0420.com/categories/NLP/Course/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="machine translation" scheme="http://www.shuang0420.com/tags/machine-translation/"/>
    
      <category term="机器翻译" scheme="http://www.shuang0420.com/tags/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>AWS Lambda + API Gateway + DynamoDB 添加 slash command 待办清单</title>
    <link href="http://www.shuang0420.com/2017/07/04/AWS%20Lambda%20+%20API%20Gateway%20+%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/"/>
    <id>http://www.shuang0420.com/2017/07/04/AWS Lambda + API Gateway + DynamoDB 添加 slash command 待办清单/</id>
    <published>2017-07-04T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>接上一篇<a href="http://www.shuang0420.com/2017/06/19/AWS%20API%20Gateway%20+%20Lambda%20+%20Slack%20App%20-%20新建%20slash%20command/">AWS API Gateway + Lambda + Slack App - 新建 slash command</a>，这一篇介绍怎么用 aws lambda + api gateway + dynamodb 添加 slash command /todo，完成 to-do list 的增、删、查等任务。两个重点，一是连接 dynamodb，二是创建 slack interactive message，具体到这篇的例子，是实现 message button。<br><a id="more"></a></p>
<h1 id="DynamoDB-configuration"><a href="#DynamoDB-configuration" class="headerlink" title="DynamoDB configuration"></a>DynamoDB configuration</h1><p>Amazon DynamoDB 属于 NoSQL 数据库，支持文档和 key-value 存储模型。每一行是一个 <strong>item</strong>，item 时<strong>属性(attributes)</strong> 的集合，每个 attribute 都有各自的<strong>名称(name)</strong>和<strong>值(value)</strong>。DynamoDB 提供了 item 的 4 项基本操作，<strong>创建(PutItem)/读取(GetItem)/更新(UpdateItem)/删除(DeleteItem)</strong>。</p>
<h2 id="Create-table"><a href="#Create-table" class="headerlink" title="Create table"></a>Create table</h2><p>第一步，完成 todolist table 的创建，<a href="https://console.aws.amazon.com/console/home?region=us-east-1" target="_blank" rel="external">aws console</a> 进入<a href="https://console.aws.amazon.com/dynamodb/home?region=us-east-1#gettingStarted:" target="_blank" rel="external">dynamodb</a>，选 create table，做如下设置，primary key 设为 user，一个 user 一个 item，item 有属性 todos，类型是 list，一个 user 当然可以有多个 to-do item，都保存在 todos 的 list 中。当然，之后会有更多的属性，比如说 <strong>channel, priority</strong> 等，后面再做设置。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/dynamodb_create.png" class="ful-image" alt="dynamodb_create.png">
<p>建表完成后在 Items 标签下 Create item，做如下设置，方便后面的测试。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/dynamoDB_editItem.png" class="ful-image" alt="dynamoDB_editItem.png">
<h2 id="Attach-policy-to-IAM-role"><a href="#Attach-policy-to-IAM-role" class="headerlink" title="Attach policy to IAM role"></a>Attach policy to IAM role</h2><p>接下来是测试 lambda function 能否连接数据库，默认情况下，lambda function 是没有这个权限的，我们需要创建一个 role，或者在已有的 role 上 attach 相应的 policy，再对 lambda function 采用这个 role，才可以访问数据库。所以，先从<a href="https://console.aws.amazon.com/console/home?region=us-east-1" target="_blank" rel="external">aws console</a> 进入<a href="https://console.aws.amazon.com/iam/home?region=us-east-1" target="_blank" rel="external">IAM</a>，选择 Roles 以及 lambda configuration 中的 role，比如说 <strong>lambda_basic_execution</strong>(这里以 kmsDecrypt role 为例)，选择 inline policy 来创建并且 attach policy。</p>
<p><strong>Step 1: create inline policy</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/IAM_attach.png" class="ful-image" alt="IAM_attach.png"></p>
<p><strong>Step 2: generate policy</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/AIM_attach2.png" class="ful-image" alt="AIM_attach2.png"></p>
<p><strong>Step 3: edit permissions</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/IAM_attach3.png" class="ful-image" alt="IAM_attach3.png"></p>
<p><strong>ARN</strong> 在 DynamoDB 页面 table overview 下可以找到，这里的 permission 表示使用了这个 role 的 lambda function 只可以对 todolist 这张表进行操作，<strong>Actions</strong> 是操作类型，这里选 All Actions，表示增删改查所有操作都允许。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/ARN.png" class="ful-image" alt="ARN.png">
<p><strong>Step 4: review and apply policy</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/IAM_attach4.png" class="ful-image" alt="IAM_attach4.png"></p>
<p>Policy 的具体内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</div><div class="line">    &quot;Statement&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;Sid&quot;: &quot;Stmt1498896886000&quot;,</div><div class="line">            &quot;Effect&quot;: &quot;Allow&quot;,</div><div class="line">            &quot;Action&quot;: [</div><div class="line">                &quot;dynamodb:*&quot;</div><div class="line">            ],</div><div class="line">            &quot;Resource&quot;: [</div><div class="line">                &quot;arn:aws:dynamodb:us-west-2:XXXXXXXXXXX:table/todolist&quot;</div><div class="line">            ]</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="Lambda-configuration"><a href="#Lambda-configuration" class="headerlink" title="Lambda configuration"></a>Lambda configuration</h1><p>写一个简单的 lambda function 看看能不能读取表中内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import boto3</div><div class="line"></div><div class="line">todo_table = boto3.resource(&apos;dynamodb&apos;).Table(&apos;todolist&apos;)</div><div class="line"></div><div class="line">def lambda_handler(event, context):</div><div class="line">    print todo_table.get_item(Key=&#123;&apos;user&apos;: &apos;testuser&apos;&#125;)</div></pre></td></tr></table></figure></p>
<p>连接成功<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/succeed.png" class="ful-image" alt="succeed.png"></p>
<p>连接不成功可能是因为地区不一致，可以显性指定 region 来连接。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import boto3</div><div class="line"></div><div class="line">todo_table = boto3.resource(&apos;dynamodb&apos;, &apos;us-west-2&apos;).Table(&apos;todolist&apos;)</div><div class="line"></div><div class="line">def lambda_handler(event, context):</div><div class="line">    print todo_table.get_item(Key=&#123;&apos;user&apos;: &apos;testuser&apos;&#125;)</div></pre></td></tr></table></figure></p>
<p>下一部分附上 debug 过程，提供可能的 debug 思路。</p>
<h2 id="Possible-error-Debug-process"><a href="#Possible-error-Debug-process" class="headerlink" title="Possible error/Debug process"></a>Possible error/Debug process</h2><p>有可能出现 “module initialization error”，具体错误信息是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">module initialization error: An error occurred (AccessDeniedException) when calling the GetItem operation: User: arn:aws:sts::xxxxxxxxxxxxx:assumed-role/kmsDecrypt/todolist is not authorized to perform: dynamodb:GetItem on resource: arn:aws:dynamodb:us-east-1:xxxxxxxxxxxxxx:table/todolist: ClientError</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/not_authorized.png" class="ful-image" alt="not_authorized.png">
<p>把上一步的 policy 改的 less restrict 一些，方便调试<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;Version&quot;: &quot;2012-10-17&quot;,</div><div class="line">    &quot;Statement&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;Sid&quot;: &quot;Stmt1498896886000&quot;,</div><div class="line">            &quot;Effect&quot;: &quot;Allow&quot;,</div><div class="line">            &quot;Action&quot;: [</div><div class="line">                &quot;dynamodb:*&quot;</div><div class="line">            ],</div><div class="line">            &quot;Resource&quot;: [</div><div class="line">                &quot;*&quot;</div><div class="line">            ]</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>再重新 test 一下 lambda，发现错误变成了 Requested resource not found<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/resource_not_found.png" class="ful-image" alt="resource_not_found.png"></p>
<p>根本没这个 table，怎么办？那干脆把所有 table 列出来看看喽，修改 lambda function，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">import boto3</div><div class="line"></div><div class="line">def lambda_handler(event, context):</div><div class="line">    print boto3.client(&apos;dynamodb&apos;).list_tables()</div></pre></td></tr></table></figure></p>
<p>发现 table list 为空。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/log_output_fail.png" class="ful-image" alt="log_output_fail.png"></p>
<p>这时候熟悉 aws 的朋友就知道，<strong>Region! Region! Region! 一定要一致！</strong></p>
<p>再来回顾下 dynamodb table overview，发现 table 所在 region 是 US WEST，而我们的 lambda ARN 是在 US EAST，所以办法是在连接 table 的时候直接指定地区。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/ARN.png" class="ful-image" alt="ARN.png">
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import boto3</div><div class="line"></div><div class="line">todo_table = boto3.resource(&apos;dynamodb&apos;, &apos;us-west-2&apos;).Table(&apos;todolist&apos;)</div><div class="line"></div><div class="line">def lambda_handler(event, context):</div><div class="line">    print todo_table.get_item(Key=&#123;&apos;user&apos;: &apos;testuser&apos;&#125;)</div></pre></td></tr></table></figure>
<p>连接成功。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/log_output_success.png" class="ful-image" alt="log_output_success.png"></p>
<h1 id="Slash-command-configuration"><a href="#Slash-command-configuration" class="headerlink" title="Slash command configuration"></a>Slash command configuration</h1><p>在 <a href="https://api.slack.com/apps" target="_blank" rel="external">slack app</a> 页面新建 slash command /todo，command 以及 api gateway 的设置，具体参照<a href="http://www.shuang0420.com/2017/06/19/AWS%20API%20Gateway%20+%20Lambda%20+%20Slack%20App%20-%20新建%20slash%20command/">AWS API Gateway + Lambda + Slack App - 新建 slash command</a>，非常简单的过程。</p>
<h1 id="Slack-Message-Button"><a href="#Slack-Message-Button" class="headerlink" title="Slack Message Button"></a>Slack Message Button</h1><p>先来看一下 message button 的运作流程，slack app 的 interactive messages 下有一个 Request URL，专门用来响应 message button 事件。一个 slack app 只能配置一个 action URL，它会接收所有 channel/team 下的 message button 的所有点击操作，这相当于一个 dispatch station。当用户点击 button 时，action URL 会收到一个 URL encoded request，request 的 body 参数中会包含一个 payload，记录相应的 user action，我们可以通过 payload 来获取用户的点击行为，然后做出响应。</p>
<p>Slack 官方教程 <a href="https://api.slack.com/interactive-messages" target="_blank" rel="external">Making messages interactive</a> 提供了多种响应 message action 的方法，主要说来一是直接对 action URL 的 request 进行 response，要求是 3 秒内必须做出响应；二是通过 response_url 进行对原消息的更新等，三是用 chat.update 来更新原始信息。</p>
<p>经尝试，发现在使用 python 以及 slackclient package 的情况下，并不能用 chat.postMessage, chat.update 来实现 message button。slackclient 作为 slack api 的一个 wrapper，确实可以实现 chat.postMessage，但只能提供 basics 的一些 response，并不能处理请求中加 attachments 的情况。</p>
<p>这里采用的是直接响应的方法。首先需要在 API Gateway 中配置 request url，对应的 integration 还是选 todolist lambda function，mapping templates 还是要改成 x-www-form-urlencoded 的形式。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/api%20gateway1.png" class="ful-image" alt="api%20gateway1.png"></p>
<p>deploy 后记录下 Invoke URL，在 slack app 下修改 request URL<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/request%20url.png" class="ful-image" alt="request%20url.png"></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/request%20url2.png" class="ful-image" alt="request%20url2.png">
<p><strong>message button format:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">def _respond_button(err, res=None):</div><div class="line">    return &#123;</div><div class="line">        &quot;text&quot;: res,</div><div class="line">        &quot;attachments&quot;: [</div><div class="line">            &#123;</div><div class="line">                &quot;callback_id&quot;: &quot;todo&quot;,</div><div class="line">                &quot;color&quot;: &quot;#3AA3E3&quot;,</div><div class="line">                &quot;attachment_type&quot;: &quot;default&quot;,</div><div class="line">                &quot;actions&quot;: [</div><div class="line">                    &#123;</div><div class="line">                        &quot;name&quot;: &quot;subtask&quot;,</div><div class="line">                        &quot;text&quot;: &quot;Remind me&quot;,</div><div class="line">                        &quot;type&quot;: &quot;button&quot;,</div><div class="line">                        &quot;value&quot;: &quot;reminder&quot;</div><div class="line">                    &#125;,</div><div class="line">                    &#123;</div><div class="line">                        &quot;name&quot;: &quot;subtask&quot;,</div><div class="line">                        &quot;text&quot;: &quot;Set priority&quot;,</div><div class="line">                        &quot;type&quot;: &quot;button&quot;,</div><div class="line">                        &quot;value&quot;: &quot;priority&quot;</div><div class="line">                    &#125;,</div><div class="line">                    &#123;</div><div class="line">                        &quot;name&quot;: &quot;subtask&quot;,</div><div class="line">                        &quot;text&quot;: &quot;Set project&quot;,</div><div class="line">                        &quot;type&quot;: &quot;button&quot;,</div><div class="line">                        &quot;value&quot;: &quot;project&quot;,</div><div class="line">                    &#125;</div><div class="line">                ]</div><div class="line">            &#125;</div><div class="line">        ]</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p>上面的 message format 会产生下图的三个 button<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lambda%20%2B%20API%20Gateway%20%2B%20DynamoDB%20%E6%B7%BB%E5%8A%A0%20slash%20command%20%E5%BE%85%E5%8A%9E%E6%B8%85%E5%8D%95/mes%20button.png" class="ful-image" alt="mes%20button.png"></p>
<p>如果用户点击 Remind me，这个行为对应的信息会发送到 request url，由于 request url 还是绑定了 todolist 这个 lambda function，所以可以在 lambda 中判断 request 是否包含 payload 参数，如果包含，说明这是一个 button 响应事件，就读取 user action 信息，并响应，否则，就响应 command 命令。</p>
<p>完整的 <a href="https://github.com/Shuang0420/slack-todolist" target="_blank" rel="external">lambda function 代码</a>，role 用 kmsDecrypt，环境变量设置好 kmsEncryptedToken，参照<a href="http://www.shuang0420.com/2017/06/19/AWS%20API%20Gateway%20+%20Lambda%20+%20Slack%20App%20-%20新建%20slash%20command/">AWS API Gateway + Lambda + Slack App - 新建 slash command</a>，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div></pre></td><td class="code"><pre><div class="line"># -*- coding: UTF-8 -*-</div><div class="line">import boto3</div><div class="line">import json</div><div class="line">import logging</div><div class="line">import os</div><div class="line"></div><div class="line">from base64 import b64decode</div><div class="line">from urlparse import parse_qs</div><div class="line"></div><div class="line">todo_table = boto3.resource(&apos;dynamodb&apos;, &apos;us-west-2&apos;).Table(&apos;todolist&apos;)</div><div class="line"></div><div class="line">ENCRYPTED_EXPECTED_TOKEN = os.environ[&apos;kmsEncryptedToken&apos;]</div><div class="line"></div><div class="line">kms = boto3.client(&apos;kms&apos;)</div><div class="line">expected_token = kms.decrypt(CiphertextBlob=b64decode(ENCRYPTED_EXPECTED_TOKEN))[&apos;Plaintext&apos;]</div><div class="line"></div><div class="line">logger = logging.getLogger()</div><div class="line">logger.setLevel(logging.INFO)</div><div class="line"></div><div class="line"></div><div class="line">def _respond_text(err, res=None):</div><div class="line">    return &#123;</div><div class="line">        &quot;text&quot;: res</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">def _respond_button(err, res=None):</div><div class="line">    return &#123;</div><div class="line">        &quot;text&quot;: res,</div><div class="line">        &quot;attachments&quot;: [</div><div class="line">            &#123;</div><div class="line">                &quot;callback_id&quot;: &quot;todo&quot;,</div><div class="line">                &quot;color&quot;: &quot;#3AA3E3&quot;,</div><div class="line">                &quot;attachment_type&quot;: &quot;default&quot;,</div><div class="line">                &quot;actions&quot;: [</div><div class="line">                    &#123;</div><div class="line">                        &quot;name&quot;: &quot;subtask&quot;,</div><div class="line">                        &quot;text&quot;: &quot;Remind me&quot;,</div><div class="line">                        &quot;type&quot;: &quot;button&quot;,</div><div class="line">                        &quot;value&quot;: &quot;reminder&quot;</div><div class="line">                    &#125;,</div><div class="line">                    &#123;</div><div class="line">                        &quot;name&quot;: &quot;subtask&quot;,</div><div class="line">                        &quot;text&quot;: &quot;Set priority&quot;,</div><div class="line">                        &quot;type&quot;: &quot;button&quot;,</div><div class="line">                        &quot;value&quot;: &quot;priority&quot;</div><div class="line">                    &#125;,</div><div class="line">                    &#123;</div><div class="line">                        &quot;name&quot;: &quot;subtask&quot;,</div><div class="line">                        &quot;text&quot;: &quot;Set project&quot;,</div><div class="line">                        &quot;type&quot;: &quot;button&quot;,</div><div class="line">                        &quot;value&quot;: &quot;project&quot;,</div><div class="line">                    &#125;</div><div class="line">                ]</div><div class="line">            &#125;</div><div class="line">        ]</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">def _respond_button_action(params):</div><div class="line">    params = json.loads(params[0])</div><div class="line">    token = params[&apos;token&apos;]</div><div class="line">    user = params[&apos;user&apos;][&apos;name&apos;]</div><div class="line">    channel = params[&apos;channel&apos;][&apos;name&apos;]</div><div class="line">    action = params[&apos;actions&apos;][0][&apos;value&apos;]</div><div class="line">    if action == &apos;reminder&apos;:</div><div class="line">        return &quot;&#123;&#125; set a reminder for this to-do item in &#123;&#125;&quot;.format(user, channel)</div><div class="line">    elif action == &apos;priority&apos;:</div><div class="line">        return &quot;&#123;&#125; set a priority for this to-do item in &#123;&#125;&quot;.format(user, channel)</div><div class="line">    else:</div><div class="line">        return &quot;&#123;&#125; set a project for this to-do item in &#123;&#125;&quot;.foramt(user, channel)</div><div class="line">    return</div><div class="line"></div><div class="line"></div><div class="line">def _get_todo_list(user, todos):</div><div class="line">    if &apos;Item&apos; not in todos or &apos;todos&apos; not in todos[&apos;Item&apos;] or not todos[&apos;Item&apos;][&apos;todos&apos;]:</div><div class="line">        return _respond_text(None, &quot;&#123;&#125; has nothing in to-do list!&quot;.format(user))</div><div class="line">    msg = &apos;&apos;</div><div class="line">    for i, item in enumerate(todos[&apos;Item&apos;][&apos;todos&apos;]):</div><div class="line">        msg += &apos;&#123;&#125; &#123;&#125; \n&apos;.format(i, item)</div><div class="line">    return _respond_text(None, msg)</div><div class="line"></div><div class="line"></div><div class="line">def _remove_from_list(user, index, todos):</div><div class="line">    if not index.isdigit():</div><div class="line">        return _respond_text(None, &quot;Sorry, I didn’t quite get that. This usually works: `/todo done [to-do item index]`. Try `/todo todolist` to get to-do item index.&quot;)</div><div class="line">    todo_item = todos[&apos;Item&apos;][&apos;todos&apos;][int(index)]</div><div class="line">    response = todo_table.update_item(</div><div class="line">            Key=&#123;</div><div class="line">                &apos;user&apos;: user</div><div class="line">            &#125;,</div><div class="line">            UpdateExpression=&quot;REMOVE todos[&quot; + index + &quot;]&quot;,</div><div class="line">            ReturnValues=&quot;UPDATED_NEW&quot;</div><div class="line">        )</div><div class="line">    if response[&apos;ResponseMetadata&apos;][&apos;HTTPStatusCode&apos;] != 200:</div><div class="line">        return response</div><div class="line">    return _respond_text(None, &quot;&#123;&#125; has done &#123;&#125; &#123;&#125;&quot;.format(user, index, todo_item))</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">def _clear(user, channel):</div><div class="line">    response = todo_table.delete_item(</div><div class="line">        Key=&#123;</div><div class="line">            &apos;user&apos;: user,</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line">    if response[&apos;ResponseMetadata&apos;][&apos;HTTPStatusCode&apos;] != 200:</div><div class="line">        return response</div><div class="line">    return _respond_text(None, &quot;&#123;&#125; has cleared his/her to-do list in &#123;&#125;&quot;.format(user, channel))</div><div class="line"></div><div class="line"></div><div class="line">def _send_button(user, command, channel, command_text, todos):</div><div class="line">    # insert items into database</div><div class="line">    if &apos;Item&apos; not in todos:</div><div class="line">        response = todo_table.put_item(Item=&#123;</div><div class="line">        &apos;user&apos;: user,</div><div class="line">        &apos;channel&apos;: channel,</div><div class="line">        &apos;todos&apos;: [command_text]</div><div class="line">        &#125;)</div><div class="line">    else:</div><div class="line">        response = todo_table.update_item(</div><div class="line">                Key=&#123;</div><div class="line">                    &apos;user&apos;: user</div><div class="line">                &#125;,</div><div class="line">                UpdateExpression=&quot;SET todos = list_append(todos, :val)&quot;,</div><div class="line">                ExpressionAttributeValues=&#123;&quot;:val&quot; : [command_text]&#125;,</div><div class="line">                ReturnValues=&quot;UPDATED_NEW&quot;</div><div class="line">            )</div><div class="line"></div><div class="line">    if response[&apos;ResponseMetadata&apos;][&apos;HTTPStatusCode&apos;] != 200:</div><div class="line">        return response</div><div class="line"></div><div class="line">    return _respond_button(None, &quot;&#123;&#125; added &apos; &#123;&#125; &apos; to the to-do list in &#123;&#125;&quot;.format(user, command_text, channel))</div><div class="line"></div><div class="line"></div><div class="line">def lambda_handler(event, context):</div><div class="line">    params = parse_qs(event[&apos;body&apos;])</div><div class="line">    # with payload, which means user clicks a button</div><div class="line">    if &apos;payload&apos; in params:</div><div class="line">        return _respond_button_action(params[&apos;payload&apos;])</div><div class="line">    # without payload</div><div class="line">    token = params[&apos;token&apos;][0]</div><div class="line">    if token != expected_token:</div><div class="line">        logger.error(&quot;Request token (%s) does not match expected&quot;, token)</div><div class="line">        return respond(Exception(&apos;Invalid request token&apos;))</div><div class="line"></div><div class="line">    user = params[&apos;user_name&apos;][0]</div><div class="line">    command = params[&apos;command&apos;][0]</div><div class="line">    channel = params[&apos;channel_name&apos;][0]</div><div class="line">    command_text = params[&apos;text&apos;][0]</div><div class="line"></div><div class="line">    # get todo list from database</div><div class="line">    todos = todo_table.get_item(Key=&#123;&apos;user&apos;: user&#125;)</div><div class="line">    if command_text.startswith(&apos;todolist&apos;):</div><div class="line">        return _get_todo_list(user, todos)</div><div class="line"></div><div class="line">    elif command_text.startswith(&apos;done &apos;):</div><div class="line">        return _remove_from_list(user, command_text.split(&apos; &apos;, 1)[1], todos)</div><div class="line"></div><div class="line">    elif command_text.startswith(&apos;clear&apos;):</div><div class="line">        return _clear(user, channel)</div><div class="line"></div><div class="line">    return _send_button(user, command, channel, command_text, todos)</div><div class="line">    # return respond(None, &quot;%s added %s to the to-do list in %s to to-do list %s&quot; % (user, command_text, channel, command_text, response, todo))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接上一篇&lt;a href=&quot;http://www.shuang0420.com/2017/06/19/AWS%20API%20Gateway%20+%20Lambda%20+%20Slack%20App%20-%20新建%20slash%20command/&quot;&gt;AWS API Gateway + Lambda + Slack App - 新建 slash command&lt;/a&gt;，这一篇介绍怎么用 aws lambda + api gateway + dynamodb 添加 slash command /todo，完成 to-do list 的增、删、查等任务。两个重点，一是连接 dynamodb，二是创建 slack interactive message，具体到这篇的例子，是实现 message button。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="QA System" scheme="http://www.shuang0420.com/categories/NLP/QA-System/"/>
    
    
      <category term="IoT" scheme="http://www.shuang0420.com/tags/IoT/"/>
    
      <category term="Alexa" scheme="http://www.shuang0420.com/tags/Alexa/"/>
    
      <category term="Slack" scheme="http://www.shuang0420.com/tags/Slack/"/>
    
      <category term="chatbot" scheme="http://www.shuang0420.com/tags/chatbot/"/>
    
      <category term="物联网" scheme="http://www.shuang0420.com/tags/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络 CNN 笔记 - 目标探测</title>
    <link href="http://www.shuang0420.com/2017/06/20/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/"/>
    <id>http://www.shuang0420.com/2017/06/20/卷积神经网络-目标探测/</id>
    <published>2017-06-20T02:45:12.000Z</published>
    <updated>2017-10-12T10:04:30.000Z</updated>
    
    <content type="html"><![CDATA[<p>介绍目标探测的基本方法，传统方法 DPM，神经网络分类 R-CNN 系列方法和神经网络回归 YoLo 系列方法。<br><a id="more"></a></p>
<h1 id="目标探测"><a href="#目标探测" class="headerlink" title="目标探测"></a>目标探测</h1><p>先来看下什么是目标探测，下图<strong>矩形框(running box)</strong>表示的物体都可以作为目标探测的对象。不止矩形框，椭圆形框在某些场合更适合做目标探测，因为它能更好的捕捉对象，并对物体朝向做相应调整，机变性更好。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B.png"></p>
<p>目标探测的任务一般分为<strong>单目标探测</strong>和<strong>多目标探测</strong>。目的一是找到目标的位置坐标，二是判定目标类别。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E4%BB%BB%E5%8A%A1.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E4%BB%BB%E5%8A%A1.png"></p>
<p>目标探测的<strong>应用场景</strong>有安防、自动驾驶等。从技术方面讲，目标探测传统方法用的是<strong>DPM</strong>，虽然目前已经被神经网络超越，但是很多思想可以借鉴。神经网络大体上有两类方法，一类是分类方法主要是<strong>RCNN系列方法</strong> ，先找到若干候选区，然后一个区域一个区域排查，判断有没有要找的物体；另一类是回归方法主要是<strong>YoLo系列方法</strong>，直接找到区域，以及区域有什么物体。</p>
<p>下面来看下目标探测的两个直接思路。</p>
<h2 id="直接思路一：回归问题"><a href="#直接思路一：回归问题" class="headerlink" title="直接思路一：回归问题"></a>直接思路一：回归问题</h2><p>一类思路是把目标探测看作是一个<strong>回归问题</strong>。直接生成 class score，也就是判断是该类别(物品)的 confidence value，和 box coordinates，也就是检测框的坐标值。整个任务的损失函数其实是位置差和分类差的一个组合。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E7%9B%B4%E6%8E%A5%E6%80%9D%E8%B7%AF.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E7%9B%B4%E6%8E%A5%E6%80%9D%E8%B7%AF.png"></p>
<h2 id="直接思路二：局部识别问题"><a href="#直接思路二：局部识别问题" class="headerlink" title="直接思路二：局部识别问题"></a>直接思路二：局部识别问题</h2><p>另一类思路是在很多位置上尝试识别，能够完成识别的地方就是目标位置。如下图，我们生成潜在的<strong>候选区域(proposal)</strong>，然后采用分类器逐个判别这些区域内图像是不是目标物体，如果是，可以把候选区域做延展(用 regression)，看有没有更合适的候选框。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/cat1.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/cat1.png"></p>
<p>一个问题是<strong>怎样找到这些候选位置？</strong><br>一种方法是用不同 scale 的 sliding windows 来遍历所有的位置，这种方法代价太高，另一种更有效的方法是直接计算候选区域。现在有很多算法能够有效的产生候选区域，比较常用的是 <strong>EdgeBoxes</strong>（在 RCNN 中使用）。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F%E4%BA%A7%E7%94%9F.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F%E4%BA%A7%E7%94%9F.png"></p>
<h1 id="传统方法-DPM"><a href="#传统方法-DPM" class="headerlink" title="传统方法-DPM"></a>传统方法-DPM</h1><p>传统方法主要包括 3 个步骤：</p>
<ol>
<li>利用不同尺度的滑动窗口在图像上进行区域搜索，定位候选区域；</li>
<li>对候选区域进行特征提取，如sift，hog，haar等；</li>
<li>利用分类器进行分类识别，svm等</li>
</ol>
<p>主要思路就是提取图像特征，制作出激励模板，在原始图像滑动计算，得到激励效果图，然后根据激励分布确定目标位置。如下图人物识别把人为设计的激励模板和 HOG 特征图结合，如果有人，会得到加强的激励，然而同样的，柱子也会得到激励。</p>
<p><strong>DPM(Deformable Part Model)</strong>可以看做是<strong>HOG(Histograms of Oriented Gradients)+SVM(Surpport Vector Machine) 方法</strong>的扩展，大体思路是一致的 — 先计算梯度方向直方图，然后用 SVM 训练得到物体的梯度模型。有了这样的模板就可以直接用来分类了，简单理解就是模型和目标匹配。DPM 只是在模型上做了很多改进工作。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/dpm1.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/dpm1.png"></p>
<p>由于目标可能会形变，之前模型不能很好的适应复杂场景的探测，所以一个改进是各个部分单独考虑，对物体的不同部分单独进行学习，所以<strong>DPM</strong>把物体看成了多个组成部件(比如说人脸的鼻子，嘴巴等)，用部件间的关系来描述物体，这个特点非常符合自然界许多物体的非刚性特征。基本思路如下:</p>
<ol>
<li>产生多个模板，整体模板(root filter)以及不同局部模板(part filter)<br>root filter 包含目标的整体信息，而 part filter 采用高分辨率的细节建模，看的梯度会更加精细</li>
<li>不同模板同输入图片“卷积”产生特征图</li>
<li>特征图组合形成融合特征</li>
<li>对融合特征进行传统分类，回归，得到目标位置</li>
<li>模型在图像特定位置和尺度的得分， 等于 root filter 的得分加上各个 part filter 得分的总和。每个 part filter 的得分等于该 part 在所有空间位置的得分的最大值，而部件在某位置的得分等于 part filter 在此位置的得分减去此位置的变形代价(也就是 part 偏离其理想位置的程度)</li>
</ol>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/dpm2.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/dpm2.jpg">
<p>DPM 的优点是方法比较直观、简单，运算速度快，也可以适应运动物体变形，很好的处理遮挡、非刚性可变和视觉变换问题，到 2012 年前，是最好的方法。然而 DPM 也有一些缺点</p>
<ul>
<li>性能一般</li>
<li>激励特征人为设计，表达能力有限，工作量大，难以进行迁移学习</li>
<li>大幅度旋转无法适应，稳定性差</li>
</ul>
<h1 id="神经网络分类-R-CNN-系列方法"><a href="#神经网络分类-R-CNN-系列方法" class="headerlink" title="神经网络分类: R-CNN 系列方法"></a>神经网络分类: R-CNN 系列方法</h1><h2 id="R-CNN-CVPR2014-TPAMI2015"><a href="#R-CNN-CVPR2014-TPAMI2015" class="headerlink" title="R-CNN(CVPR2014, TPAMI2015)"></a>R-CNN(CVPR2014, TPAMI2015)</h2><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>神经网络的分类思想是<strong>对多个位置，不同尺寸，用卷积神经网络判断区域内图片是不是某物</strong>，<strong>候选位置(proposal)</strong>提出方法一般用 <strong>EdgeBox</strong>。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn1.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn1.png"></p>
<p>R-CNN 最初提出的时候选择 20 类进行探测，是在 ImageNet 模型的基础上，把 1000 类的分类模型变成能识别 21 类(20类+other)的 Fine-tune 分类模型。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn2.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn2.jpg"><br>=&gt;<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn3.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn3.jpg"></p>
<p><strong>特征的提取过程:</strong> 对图片计算候选区域；对候选区域切分图片，对切分部分进行 resize 变成输入大小；提取相应高级特征；存储特征(大容量，200-300G空间存储图片)<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn4.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn4.jpg"></p>
<p><strong>单独目标探测器训练：</strong>对每一类进行单独训练，保证每一类训练数据平衡，每一类都是 binary 分类(yes/no)。比如猫的分类器，可能大部分图片没有一个理想的猫，只有一个耳朵，这不算猫，我们要与真值进行比较，看左上右下区域，如果重合(共有区域)比较多，就认为是猫的图片。每一类都有很多的正例反例(1/0)。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn5.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn5.jpg"></p>
<p><strong>单独目标回归器训练-基于候选区域微调:</strong> 同样的，每一类单独训练，保证每一类训练数据平衡，这里是每一类做 BBOX 回归。目的是在知道是不是猫以及位置的偏移后，用回归对位置进行 offset，离真值(ground truth)更近，最终的探测精度会更高。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn6.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn6.jpg"></p>
<p><strong>总的来说，R-CNN 的测试过程就是</strong></p>
<ol>
<li>对每个图像生成 1k-2k 个候选区域</li>
<li>对每个候选区域，使用深度网络进行特征计算</li>
<li>特征喂给每一类的 svm 分类器，判别是否属于该类分类；同时用回归修正候选框位置</li>
<li>后续处理<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn7.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/rcnn7.jpg">
</li>
</ol>
<h3 id="常用数据集"><a href="#常用数据集" class="headerlink" title="常用数据集"></a>常用数据集</h3><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E6%95%B0%E6%8D%AE%E9%9B%86.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E6%95%B0%E6%8D%AE%E9%9B%86.jpg">
<h3 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h3><ul>
<li><strong>MAP(mean average precision)</strong></li>
<li><strong>IoU</strong>，真值和预测值多重叠部分与两者的并集的比值，一般大于 0.5 就认为是正确的<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/IoU.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/IoU.jpg">
</li>
</ul>
<h3 id="R-CNN-结果对比"><a href="#R-CNN-结果对比" class="headerlink" title="R-CNN 结果对比"></a>R-CNN 结果对比</h3><p>Regionlets(2013) 并没有经过 fine-tune，R-CNN(2014, AlexNet) 用事先训练好的分类器进行了 fine-tune，R-CNN+bbox reg(AlexNet)，用了 regression，加了 offset 对检测框做了范围调整，R-CNN(vgg-16)把 base model 改成了 vgg</p>
<p>总的来说，主要是从下面三个角度进行了模型的调整</p>
<ol>
<li>Finetune</li>
<li>回归微调</li>
<li>Base 模型<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/crnn9.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/crnn9.jpg">
</li>
</ol>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点:</strong></p>
<ol>
<li>CNN 用于目标探测，利 用了 CNN 高效识别能力， 大大提高性能</li>
<li>摆脱人为设计物品模版， 方法具有通用性</li>
<li>分类＋回归，有了找到精确位置的可能</li>
</ol>
<p><strong>缺陷:</strong></p>
<ol>
<li>为了检测一个目标，所有候选区域计算，大量卷积运算，非常慢<br>对于速度慢这个问题，SPP-NET 给出了解决方案。R-CNN 对图像提完 region proposal(2k 左右)之后将每个 proposal 当成一张图像进行后续处理(CNN提特征+SVM分类)，实际上对一张图像进行了2000次提特征和分类的过程！SPP-NET 对图像提一次卷积层特征，然后将 region proposal 在原图的位置映射到卷积层特征图上，这样对于一张图像只需要提一次卷积层特征，然后将每个 region proposal 的卷积层特征输入到全连接层做后续操作</li>
<li>SVM 训练与CNN 断裂， SVM Loss 没办法用于 CNN Loss，有效信息不能用于优化模型， not end-to-end</li>
<li>每一类单独训练，异常繁琐</li>
</ol>
<h2 id="Fast-R-CNN-ICCV2015"><a href="#Fast-R-CNN-ICCV2015" class="headerlink" title="Fast R-CNN(ICCV2015)"></a>Fast R-CNN(ICCV2015)</h2><p>Fast R-CNN 的三个进步</p>
<ul>
<li>共享卷积计算<br>增加 ROI pooling layer</li>
<li>完整训练(end-to-end)<br>用 softmax 代替 svm 分类，用多目标损失函数加入候选框回归，除 region proposal 提取外实现了 end-to-end</li>
<li>多目标一起学习<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/fast%20rcnn.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/fast%20rcnn.jpg">
</li>
</ul>
<h3 id="共享卷积计算"><a href="#共享卷积计算" class="headerlink" title="共享卷积计算"></a>共享卷积计算</h3><p>Fast R-CNN 在最后一个卷积层后加了一个 ROI pooling layer，实际上就是上面提到的 SPP-NET 的一个精简版，特点是:</p>
<ol>
<li>卷积计算保持空间位置</li>
<li>共同区域的卷积计算只需进行一次</li>
<li>切割候选区+提取特征图=计算完整特征图+切割对应候选区<br>把图片的 region proposal 切割出来，resize，提取特征，其实就等同于在原图特征图里找到 region proposal<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E5%85%B1%E4%BA%AB%E5%8D%B7%E7%A7%AF.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E5%85%B1%E4%BA%AB%E5%8D%B7%E7%A7%AF.jpg">
</li>
</ol>
<p>一个重要的问题是<strong>不同区域的特征如何保持一致？</strong><br>全连接层要求接的区域形状一致；所以要特征图里区域的一致性处理，也就是做一个 pooling<br><strong>特征一致化 - Max Pooling</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E7%89%B9%E5%BE%81%E4%B8%80%E8%87%B4%E5%8C%96.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E7%89%B9%E5%BE%81%E4%B8%80%E8%87%B4%E5%8C%96.jpg"></p>
<p>局部区域<br>100x50 =&gt;按 4:2 pooling<br>50x100 =&gt; 按 2:4 pooling<br>=&gt; 25x25 feature<br>=&gt; 225 FC</p>
<p>如果 pooling size 不完美，其实也没有问题，pooling 本身就是填充 pooling 后的图的每一个 pixel，只要从 pooling 前某区域选一个 pixel 值即可，不一定要规整</p>
<h3 id="位置-类别联合学习"><a href="#位置-类别联合学习" class="headerlink" title="位置 + 类别联合学习"></a>位置 + 类别联合学习</h3><p><strong>图片 =&gt; cnn feature map计算 =&gt; proposal应用 =&gt; feature map相应区域做 region pooling 得到固定大小的 feature map =&gt; classification &amp; regression</strong><br>用 softmax 代替 svm 分类，使用<strong>多任务损失函数(multi-task loss)</strong>，将候选框回归直接加入到 cnn 网络中训练，除去 region proposal 的提取阶段，这样的训练过程是端到端的(end-to-end)，整个网络的训练和测试十分方便<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/fast%20rcnn.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/fast%20rcnn.png"></p>
<h3 id="性能提升"><a href="#性能提升" class="headerlink" title="性能提升"></a>性能提升</h3><p>看一下性能提升的情况<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E6%80%A7%E8%83%BD.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E6%80%A7%E8%83%BD.jpg"><br>然而前提是 不考虑候选区域(proposal)的生成，如果加上候选区域(proposal)的时间<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E6%80%A7%E8%83%BD2.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/%E6%80%A7%E8%83%BD2.jpg"><br>region proposal 的提取使用 selective search，目标检测时间大多消耗在这上面(提region proposal 2~3s，而提特征分类只需0.32s)，无法满足实时应用，那么，怎么解决候选区域的计算呢？一个方法是也靠神经网络。</p>
<h2 id="Faster-R-CNN-NIPS2015"><a href="#Faster-R-CNN-NIPS2015" class="headerlink" title="Faster R-CNN(NIPS2015)"></a>Faster R-CNN(NIPS2015)</h2><h3 id="RPN-Region-Proposal-Network"><a href="#RPN-Region-Proposal-Network" class="headerlink" title="RPN(Region Proposal Network)"></a>RPN(Region Proposal Network)</h3><p>用神经网络来解决候选区域的生成问题，主要是神经网络特征增加一组输出 <strong>RPN(Region Proposal Network)候选区域网络</strong></p>
<ol>
<li>直接产生候选区域，无需额外生成<br>本质上是 sliding window，RPN 只需在最后的卷积层上滑动一遍，因为 anchor 机制和候选框回归可以得到多尺度多长宽比多 region proposal</li>
<li>直接用于后续特征图切割</li>
</ol>
<p>最后的特征图中有很多个 pixel，每个 pixel 和卷积核进行计算，生成 k 个可能的 prpoposal(实际中 k 往往=9，一个区域可能同时被多个物体占用，所以尽可能把可能分布的形状都生成)，每个 proposal 有个 score 的计算。如图，左边是 3x3 的卷积网络的特征图，右边是 k 个 anchor box(相当于小的候选生成单元)。我们对特征图进行 sliding window 的计算，每个 pixel 生成 256 长的向量(向量长度其实是自己设计的，vgg 建议 512-d)，这个向量用来生成 k 个 proposal 的值，以及对应的 2k score(是/不是目标物体)，4k 个 coordinates(上下左右坐标)。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/faster%20rcnn1.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/faster%20rcnn1.jpg"></p>
<p><strong>网络输出的值：</strong></p>
<ol>
<li>是不是一个目标</li>
<li>覆盖范围的相对位置</li>
</ol>
<p><strong>k=9(3种尺寸，3种长宽比)个 anchor，能产生多少个 proposal?</strong><br>特征图 size HxW -&gt; HWx9 in paper 2400x9</p>
<p><strong>如果是 VGG conv5 作为特征图，3x3 区域对应的原始图像区域？</strong><br>经过了 4 个 pooling，往前推，6x6 -&gt; 12x12 -&gt; 24x24 -&gt; 48x48，也就是 16 倍的一个缩放</p>
<p><strong>Anchor的平移不变怎么理解</strong><br>较小的平移 pooling 过程中忽略，3 个 pixel 的移动经过 4 层的 pooling，移动后的位置和原位置相差可以忽略</p>
<p><strong>Anchor 同外接 Proposal 区别</strong><br>数量：1-2个数量级减少；性能：更高效；<br>速度：10x</p>
<p><strong>Anchor 设计的借鉴意义？</strong><br>神经网络有能力找到最终量，也有能力找到很多中间量。只用 Anchor 判断是不是目标，会不会存在大材小用，能够判断更多吗？或者说，能在是不是目标的基础上，判断是什么目标吗，也就是<strong>直接拟合</strong></p>
<p>为了让RPN的网络和Fast R-CNN网络实现卷积层的权值共享，训练 RPN 和 Fast R-CNN的时候用了4阶段的训练方法:</p>
<ol>
<li>使用在 ImageNet 上预训练的模型初始化网络参数，微调 RPN 网络；</li>
<li>使用(1)中RPN网络提取 region proposal 训练 Fast R-CNN网络；</li>
<li>使用(2)的 Fast R-CNN 网络重新初始化 RPN, 固定卷积层进行微调；</li>
<li>固定(2)中 Fast R-CNN 的卷积层，使用 (3) 中 RPN 提取的 region proposal 微调网络<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/faster%20rcnn2.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/faster%20rcnn2.jpg">
</li>
</ol>
<p>Faster R-CNN 用了<strong>直接联合学习(joint learning)</strong> 的方法，如上图，一个网络有 4 个损失函数</p>
<ol>
<li>Anchor 是不是目标</li>
<li>Anchor 回归候选区域回归</li>
<li>Fast R-CNN 分类</li>
<li>Fast R-CNN 基于候选位置回归<br>联合学习的方法产生了更少的候选区，但是精度不会受到影响，速度却快了 10 倍，接近于实时处理(@K40 GPU, 12G)。</li>
</ol>
<h3 id="性能提升-1"><a href="#性能提升-1" class="headerlink" title="性能提升"></a>性能提升</h3><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/faster%20rcnn3.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/faster%20rcnn3.jpg">
<p>接近于实时处理，然而还是很难实时的目标探测，下面的 YOLO 这类方法可以达到实时性。</p>
<h1 id="神经网络回归-YoLo-系列方法"><a href="#神经网络回归-YoLo-系列方法" class="headerlink" title="神经网络回归: YoLo 系列方法"></a>神经网络回归: YoLo 系列方法</h1><h2 id="YoLo"><a href="#YoLo" class="headerlink" title="YoLo"></a>YoLo</h2><h3 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h3><p>YoLo 将目标探测任务看作目标区域预测和类别预测的回归问题，用单个神经网络直接预测物品边界和类别分数，可以<strong>直接找到物体是什么，在哪里</strong>。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/YoLo.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/YoLo.jpg"></p>
<p>把图片分成 SxS 的格子(grid cell)，一般是 7x7 的网络，每个网格生成：</p>
<ol>
<li>B 个 Bbox，4 个 coordinates + 1 个 confidence score</li>
<li>N 个类别分数 $Pr(Class_i|Object)$<br>与 Anchor 不同的是，这里有 N 个分数，表示属于每一类的分数分别是多少</li>
</ol>
<p>S=7, B=2, N=20<br><strong>总共的回归目标：</strong> SxSx(5B+N)<br>​     2x5+20=30 个参数，49x30=1470 个数值，用来回归<br><strong>候选区域个数：</strong> (B=2) 98 个 &lt;&lt; Faster R-CNN<br>每个小区域生成 2 个候选区，一个小的区域就是一个粗糙的 proposal，对小区域进行大范围的 regression，找到目标<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/yolo2.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/yolo2.jpg"></p>
<p><strong>损失函数:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/yolo3.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/yolo3.png"></p>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p><strong>性能：</strong></p>
<ul>
<li>实时运行</li>
<li>精度稍微下降</li>
<li>定位精度较差</li>
</ul>
<p>经过大量的 pooling，位置的响应会有一定弱化<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/yolo4.png" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/yolo4.png"></p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><ol>
<li>YoLo 的每一个网格只预测两个 boxes，一种类别。这导致模型对相邻目标预测准确率下降。因此，YOLO 对成队列的目标（如一群鸟）识别准确率较低。</li>
<li>YoLo 是从数据中学习预测 bounding boxes，因此，对新的或者不常见角度的目标无法识别。</li>
<li>YoLo 的损失函数对small bounding boxes 和 large bounding boxes 的 error 平等对待，影响了模型识别准确率。因为对于小的 bounding boxes，small error影响更大。</li>
</ol>
<h2 id="SSD-The-Single-Shot-Detector"><a href="#SSD-The-Single-Shot-Detector" class="headerlink" title="SSD: The Single Shot Detector"></a>SSD: The Single Shot Detector</h2><p>SSD 分类更细，网络结构有点像 resnet。中间多层特征参与位置、种类计算，在不同 layer 输出的不同尺寸的 feature map 划格子，在格子上提“anchor”，弥补了 Yolo 只在最后一层分 7x7 的框漏掉的部分。和 Yolo 相比，更快更准确。</p>
<ul>
<li>候选区 98 vs 8732</li>
<li>速度 21:46 (vgg base)</li>
<li>精度 66.4:74.3</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/ssd.jpg" class="ful-image" alt="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%9B%AE%E6%A0%87%E6%8E%A2%E6%B5%8B/ssd.jpg">
<blockquote>
<p>参考链接：<br><a href="http://bealin.github.io/2016/10/23/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E4%BB%8ERCNN%E3%80%81Fast-RCNN%E5%88%B0Faster-RCNN/" target="_blank" rel="external">目标检测方法——从RCNN、Fast-RCNN到Faster-RCNN</a><br><a href="https://zhuanlan.zhihu.com/p/25045711" target="_blank" rel="external">YOLO：实时快速目标检测</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;介绍目标探测的基本方法，传统方法 DPM，神经网络分类 R-CNN 系列方法和神经网络回归 YoLo 系列方法。&lt;br&gt;
    
    </summary>
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/categories/Deep-learning/"/>
    
      <category term="CNN" scheme="http://www.shuang0420.com/categories/Deep-learning/CNN/"/>
    
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/tags/Deep-learning/"/>
    
      <category term="CNN" scheme="http://www.shuang0420.com/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>AWS API Gateway + Lambda + Slack App - 新建 slash command</title>
    <link href="http://www.shuang0420.com/2017/06/19/AWS%20API%20Gateway%20+%20Lambda%20+%20Slack%20App%20-%20%E6%96%B0%E5%BB%BA%20slash%20command/"/>
    <id>http://www.shuang0420.com/2017/06/19/AWS API Gateway + Lambda + Slack App - 新建 slash command/</id>
    <published>2017-06-19T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>接之前<a href="http://www.shuang0420.com/2017/06/09/AWS%20Lex%20创建%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/">AWS Lex 创建 Slack Bot - Integrating Lex Bot with Slack</a>，介绍怎么在 slack app 的基础上添加 slash command。<br><a id="more"></a></p>
<p>slash command 的配置页面需要一个 <strong>Request URL</strong>，这个 URL 就由 <strong>AWS API Gateway</strong> 来提供，API Gateway 调用 <strong>AWS Lambda</strong> 来完成具体的动作，而 Lambda 需要一个 slack token 来验证 slack app 的身份，才能够调用 slack api 来接收/回复信息，这个 token 由 <strong>AWS IAM</strong> 进行加密保障安全性。下面的教程分别介绍了怎么加密 token，编写 Lambda，配置 API Gateway，来完成一个 slash command 的创建。</p>
<h1 id="Encrypt-KMS-Key"><a href="#Encrypt-KMS-Key" class="headerlink" title="Encrypt KMS Key"></a>Encrypt KMS Key</h1><p><strong>Step 1:</strong> 在 <a href="https://console.aws.amazon.com/iam/home#encryptionKeys" target="_blank" rel="external">IAM console</a> 创建一个 KMS key，记录下 key-id，后面需要用到。<br><strong>Step 2:</strong> 在 <a href="https://api.slack.com/apps" target="_blank" rel="external">slack apps</a> 选择你的 app，然后在 <code>Basic Information</code> 下的 <code>App Credentials</code> 部分找到 <code>Verification Token</code>，记录下来，这就是我们需要加密的 token。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%2B%20Slack%20App%20-%20%E6%96%B0%E5%BB%BA%20slash%20command/command-token.png" class="ful-image" alt="command-token.png">
<p><strong>Step 3:</strong> 我们的目的是用 Step 1 创建的 key 来对 Step 2 记录的 token 进行加密。如果电脑已经装了 awscli，那么直接在命令行输入下面的命令即可。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ aws kms encrypt --key-id &lt;key-id&gt; --plaintext &lt;text&gt;</div></pre></td></tr></table></figure></p>
<p>其中 key-id 就是开始记录下的 kms key id，text 就是 verification token，把产生的 <code>CiphertextBlob</code>记录下来，在下一步 Lambda Configuration 里要用。</p>
<p>如果没有安装 aws-cli，OSX 系统直接用 <code>brew</code> 命令安装一下，最好不要用 <code>pip</code>，很大概率会出问题。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ brew install awscli</div></pre></td></tr></table></figure>
<p>装好后，<code>aws --version</code> 查看是否安装成功， <code>aws configure</code> 命令来配置账户信息，会要求输入</p>
<ul>
<li><strong>AWS Access Key ID:</strong> 在 aws console 的 <code>My Security Credentials</code> 下</li>
<li><strong>AWS Secret Access Key:</strong> 现在必须创建一个 IAM user 才能得到，戳 <a href="[http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html">create IAM user</a>)</li>
<li><strong>Default region name:</strong> 根据实际情况填，如果是 US East (N. Virginia)，就填 <code>us-east-1</code>，注意不要在末尾加 abcd，<code>us-east-1a</code> 类似的格式会出错</li>
<li><strong>Default output format:</strong> 可以不填</li>
</ul>
<p>配置完正常进行加密即可。</p>
<h1 id="Lambda-Configuration"><a href="#Lambda-Configuration" class="headerlink" title="Lambda Configuration"></a>Lambda Configuration</h1><p>Lambda blueprint 选 <code>slack-echo-command</code>，创建 lambda function <code>slashTest</code>，这里要实现的是当用户 [user] 调用 /test 这个 [command] 时(之后会创建)并输入文本 [text] 时，返回 <code>[user] invoked [command,e.g., /test] in [channel,eg., directmessage] with the following text: [text]&quot;</code>。代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div></pre></td><td class="code"><pre><div class="line">&apos;use strict&apos;;</div><div class="line"></div><div class="line">/*</div><div class="line">This function handles a Slack slash command and echoes the details back to the user.</div><div class="line"></div><div class="line">Follow these steps to configure the slash command in Slack:</div><div class="line"></div><div class="line">  1. Navigate to https://&lt;your-team-domain&gt;.slack.com/services/new</div><div class="line"></div><div class="line">  2. Search for and select &quot;Slash Commands&quot;.</div><div class="line"></div><div class="line">  3. Enter a name for your command and click &quot;Add Slash Command Integration&quot;.</div><div class="line"></div><div class="line">  4. Copy the token string from the integration settings and use it in the next section.</div><div class="line"></div><div class="line">  5. After you complete this blueprint, enter the provided API endpoint URL in the URL field.</div><div class="line"></div><div class="line"></div><div class="line">  To encrypt your secrets use the following steps:</div><div class="line"></div><div class="line">  1. Create or use an existing KMS Key - http://docs.aws.amazon.com/kms/latest/developerguide/create-keys.html</div><div class="line"></div><div class="line">  2. Click the &quot;Enable Encryption Helpers&quot; checkbox</div><div class="line"></div><div class="line">  3. Paste &lt;COMMAND_TOKEN&gt; into the kmsEncryptedToken environment variable and click encrypt</div><div class="line"></div><div class="line">Follow these steps to complete the configuration of your command API endpoint</div><div class="line"></div><div class="line">  1. When completing the blueprint configuration select &quot;Open&quot; for security</div><div class="line">     on the &quot;Configure triggers&quot; page.</div><div class="line"></div><div class="line">  2. Enter a name for your execution role in the &quot;Role name&quot; field.</div><div class="line">     Your function&apos;s execution role needs kms:Decrypt permissions. We have</div><div class="line">     pre-selected the &quot;KMS decryption permissions&quot; policy template that will</div><div class="line">     automatically add these permissions.</div><div class="line"></div><div class="line">  3. Update the URL for your Slack slash command with the invocation URL for the</div><div class="line">     created API resource in the prod stage.</div><div class="line">*/</div><div class="line"></div><div class="line">const AWS = require(&apos;aws-sdk&apos;);</div><div class="line">const qs = require(&apos;querystring&apos;);</div><div class="line"></div><div class="line">const kmsEncryptedToken = process.env.kmsEncryptedToken;</div><div class="line">let token;</div><div class="line"></div><div class="line"></div><div class="line">function processEvent(event, callback) &#123;</div><div class="line">    const params = qs.parse(event.body);</div><div class="line">    const requestToken = params.token;</div><div class="line">    if (requestToken !== token) &#123;</div><div class="line">        console.error(`Request token ($&#123;requestToken&#125;) does not match expected`);</div><div class="line">        return callback(&apos;Invalid request token&apos;);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    const user = params.user_name;</div><div class="line">    const command = params.command;</div><div class="line">    const channel = params.channel_name;</div><div class="line">    const commandText = params.text;</div><div class="line"></div><div class="line">    callback(null, `$&#123;user&#125; invoked $&#123;command&#125; in $&#123;channel&#125; with the following text: $&#123;commandText&#125;`);</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">exports.handler = (event, context, callback) =&gt; &#123;</div><div class="line">    const done = (err, res) =&gt; callback(null, &#123;</div><div class="line">        statusCode: err ? &apos;400&apos; : &apos;200&apos;,</div><div class="line">        body: err ? (err.message || err) : JSON.stringify(res),</div><div class="line">        headers: &#123;</div><div class="line">            &apos;Content-Type&apos;: &apos;application/json&apos;,</div><div class="line">        &#125;,</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    if (token) &#123;</div><div class="line">        // Container reuse, simply process the event with the key in memory</div><div class="line">        processEvent(event, done);</div><div class="line">    &#125; else if (kmsEncryptedToken &amp;&amp; kmsEncryptedToken !== &apos;&lt;kmsEncryptedToken&gt;&apos;) &#123;</div><div class="line">        const cipherText = &#123; CiphertextBlob: new Buffer(kmsEncryptedToken, &apos;base64&apos;) &#125;;</div><div class="line">        const kms = new AWS.KMS();</div><div class="line">        kms.decrypt(cipherText, (err, data) =&gt; &#123;</div><div class="line">            if (err) &#123;</div><div class="line">                console.log(&apos;Decrypt error:&apos;, err);</div><div class="line">                return done(err);</div><div class="line">            &#125;</div><div class="line">            token = data.Plaintext.toString(&apos;ascii&apos;);</div><div class="line">            processEvent(event, done);</div><div class="line">        &#125;);</div><div class="line">    &#125; else &#123;</div><div class="line">        done(&quot;Token has not been set.&quot;);</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>配置需要注意的是 <strong>Role</strong> 的选择，默认从 templates 里选 <code>kmsDecrypt</code>，不用修改，加个名字就好。在 <code>Environment variables</code> 里填写上一部分记录下的加密后的 token。但是！代码里请<strong>不要修改！！</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%2B%20Slack%20App%20-%20%E6%96%B0%E5%BB%BA%20slash%20command/role.png" class="ful-image" alt="role.png">
<h1 id="API-Gateway-Configuration"><a href="#API-Gateway-Configuration" class="headerlink" title="API Gateway Configuration"></a>API Gateway Configuration</h1><p>关于基础的 API Gateway 教程，见 <a href="http://www.shuang0420.com/2017/06/18/AWS%20API%20Gateway%20+%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/">AWS API Gateway + Lambda 教程 - 生成随机数</a></p>
<p>在 <a href="https://console.aws.amazon.com/console/home?region=us-east-1" target="_blank" rel="external">aws console</a> 页面的 <strong>Services -&gt; Application Service -&gt; API Gateway</strong> 下新建 API，然后在 <strong>Action</strong> 下拉框下 <strong>Create Resource</strong>，名称可以写 /test，然后继续 <strong>Create Method</strong> ，选 <strong>POST</strong>，Lambda Function 选择之前我们已经建好的 <code>slashTest</code>，保存后在新页面选择 <strong>Integration Request</strong>，新建一个 <strong>mapping template</strong>，如下：</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%2B%20Slack%20App%20-%20%E6%96%B0%E5%BB%BA%20slash%20command/mapping.png" class="ful-image" alt="mapping.png">
<p><strong>Content-Type:</strong> <code>application/x-www-form-urlencoded</code><br><strong>Template:</strong> <code>{ &quot;body&quot;: $input.json(&quot;$&quot;) }</code></p>
<p>之后部署，<strong>Actions -&gt; Deploy API</strong>，记下完成页面显示的 <strong>Invoke URL</strong>。</p>
<h1 id="Slack-App-Configuration"><a href="#Slack-App-Configuration" class="headerlink" title="Slack App Configuration"></a>Slack App Configuration</h1><p>回到 <a href="https://api.slack.com/apps" target="_blank" rel="external">slack app</a> 页面，选择左侧的 <strong>Slash Commands</strong>，新建一个 Command，<strong>Request URL</strong> 填写上一部分记录下来的地址，注意将 sub resource name 补充完整，这里是 /test。完成后记得 <strong>reinstall app</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%2B%20Slack%20App%20-%20%E6%96%B0%E5%BB%BA%20slash%20command/command.png" class="ful-image" alt="command.png">
<p>返回结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;statusCode&quot;:&quot;200&quot;,&quot;body&quot;:&quot;\&quot;sxu1 invoked /test in directmessage with the following text: hello world\&quot;&quot;,&quot;headers&quot;:&#123;&quot;Content-Type&quot;:&quot;application/json&quot;&#125;&#125;</div></pre></td></tr></table></figure></p>
<p>如果要返回 plain text，直接修改 lambda function，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">exports.handler = (event, context, callback) =&gt; &#123;</div><div class="line">    const done = (err, res) =&gt; callback(null, res); //&#123;</div><div class="line">      //     statusCode: err ? &apos;400&apos; : &apos;200&apos;,</div><div class="line">      //     body: err ? (err.message || err) : JSON.stringify(res),</div><div class="line">      //     headers: &#123;</div><div class="line">      //         &apos;Content-Type&apos;: &apos;application/json&apos;,</div><div class="line">      //     &#125;,</div><div class="line">      // &#125;);</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%2B%20Slack%20App%20-%20%E6%96%B0%E5%BB%BA%20slash%20command/test.png" class="ful-image" alt="test.png">
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接之前&lt;a href=&quot;http://www.shuang0420.com/2017/06/09/AWS%20Lex%20创建%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/&quot;&gt;AWS Lex 创建 Slack Bot - Integrating Lex Bot with Slack&lt;/a&gt;，介绍怎么在 slack app 的基础上添加 slash command。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="QA System" scheme="http://www.shuang0420.com/categories/NLP/QA-System/"/>
    
    
      <category term="IoT" scheme="http://www.shuang0420.com/tags/IoT/"/>
    
      <category term="Alexa" scheme="http://www.shuang0420.com/tags/Alexa/"/>
    
      <category term="Slack" scheme="http://www.shuang0420.com/tags/Slack/"/>
    
      <category term="chatbot" scheme="http://www.shuang0420.com/tags/chatbot/"/>
    
      <category term="物联网" scheme="http://www.shuang0420.com/tags/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>AWS API Gateway + Lambda 教程 - 生成随机数</title>
    <link href="http://www.shuang0420.com/2017/06/18/AWS%20API%20Gateway%20+%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/"/>
    <id>http://www.shuang0420.com/2017/06/18/AWS API Gateway + Lambda 教程 - 生成随机数/</id>
    <published>2017-06-18T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>非常简单的教程，以产生一定范围内的随机数为例，介绍如何用 AWS Lambda + API Gateway 建立一个 serveless API，包括 API 如何传参。<br><a id="more"></a></p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>如果要用一句话理解 <strong><a href="https://aws.amazon.com/api-gateway/?nc1=h_ls" target="_blank" rel="external">API Gateway</a></strong>，那必须是 <strong>serverless APIs</strong>。<strong>AWS API Gateway</strong> 与 <strong>AWS Lambda</strong> 紧密集成，开发者可以通过 API Gateway 创建基于 REST 风格的 API，各种 app 应用调用这些 API，而这些 API 可以通过 AWS Lambda 中运行的代码来调用公开提供的 AWS 服务(or anything you like)。下面两幅图给出了更直观的逻辑。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/api%20gateway.png" class="ful-image" alt="api%20gateway.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/serveless%20apps.png" class="ful-image" alt="serveless%20apps.png">
<p><strong><a href="https://aws.amazon.com/api-gateway/?nc1=h_ls" target="_blank" rel="external">API Gateway</a></strong> 的优势官方说明说了很多，感觉最大优势除了能够创建完全无服务器的 API 外，值得一提的就是能提供 <strong>安全控制机制(security)</strong> 和 <strong>版本控制(versioning)</strong>，有兴趣还是看文档吧。</p>
<p>下面来一个简单的例子 randomGenerator，产生 0-10 之间的随机数。网上可以找到一些教程，不过有些并不能 work，有很多坑，感觉是版本问题。主要逻辑就是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">API Gateway =&gt;</div><div class="line">handle and validate request</div><div class="line">pass to lambda function</div><div class="line"></div><div class="line">Lambda execution rule =&gt;</div><div class="line">call other aws service OR do something else</div></pre></td></tr></table></figure></p>
<p>相应的，步骤也就是分别配置好 <strong>Lambda function</strong> 和 <strong>API</strong>，然后将两者结合起来，结合方法有两种，一是在 Lambda 界面添加 <strong>Trigger</strong>，连接 API；二是在 <strong>API Gateway</strong> 界面添加 <strong>Lambda function</strong>，绑定 <strong>Lambda</strong>，两种方法都可以。</p>
<h1 id="Example-1-Basic-random-number-generator"><a href="#Example-1-Basic-random-number-generator" class="headerlink" title="Example 1: Basic random-number-generator"></a>Example 1: Basic random-number-generator</h1><h2 id="Lambda-Configuration"><a href="#Lambda-Configuration" class="headerlink" title="Lambda Configuration"></a>Lambda Configuration</h2><p>登录<a href="https://console.aws.amazon.com" target="_blank" rel="external">AWS console</a>在 Service 下选择 Lambda<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/LAMBDA1.png" class="ful-image" alt="LAMBDA1.png"></p>
<p><strong>Step1: Create a Lambda function</strong>，选 Node.js.4.3, Blank Function<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/LAMBDA2.png" class="ful-image" alt="LAMBDA2.png"></p>
<p><strong>Step 2: Configure Triggers</strong>，如果已经配置好了 API Gate，就选择相应的 API name，如果没有，直接默认下一步。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/Add%20trigger.png" class="ful-image" alt="Add%20trigger.png"></p>
<p><strong>Step 3: Configure Function</strong>，进行如下设置，附代码部分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&apos;use strict&apos;</div><div class="line">console.log(&apos;Loading function&apos;)</div><div class="line"></div><div class="line">exports.handler = (event, context, callback) =&gt; &#123;</div><div class="line">    let min = 0;</div><div class="line">    let max = 10;</div><div class="line"></div><div class="line">    let generatedNumber = Math.floor(Math.random() * (max - min)) + min;</div><div class="line"></div><div class="line">    callback(null, generatedNumber);</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/LAMBDA4.png" class="ful-image" alt="LAMBDA4.png">
<p>这里我们不需要验证身份，environment variables 留空就好。Role 如果没有 existing role，可以新建一个。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/LAMBDA5.png" class="ful-image" alt="LAMBDA5.png">
<p><strong>Step 4: Submit</strong>，预览一下如果没问题就 submit，等待一会儿 lambda function 就建好啦。</p>
<p><strong>Step 5: Test</strong>，如果在 <strong>Step 2</strong> 里选择了已经建好的 API Gateway 作为 <strong>Trigger</strong>，那么可以直接选择 <strong>Test</strong> 进行测试，也可以通过 url 测试。有可能会遇到 <strong>Internal server error</strong>，官方说明 <strong>response must have statusCode, body, headers</strong>，于是把代码改了下，就成功啦。(后来发现好像不改也没关系。。)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">&apos;use strict&apos;;</div><div class="line">console.log(&apos;Loading function&apos;);</div><div class="line"></div><div class="line">exports.handler = (event, context, callback) =&gt; &#123;</div><div class="line">    let min = 0;</div><div class="line">    let max = 10;</div><div class="line"></div><div class="line">    let generatedNumber = Math.floor(Math.random() * (max - min)) + min;</div><div class="line"></div><div class="line">    const response = &#123;</div><div class="line">        statusCode: 200,</div><div class="line">        body: JSON.stringify(generatedNumber)</div><div class="line">    &#125;;</div><div class="line"></div><div class="line">    callback(null, response);</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>测试结果如下：<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/lambda%20test.png" class="ful-image" alt="lambda%20test.png"></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/Add%20trigger%20done.png" class="ful-image" alt="Add%20trigger%20done.png">
<p>相反，如果在 <strong>Step 2</strong> 里并没有设置 <strong>Trigger</strong>，我们需要新建 <strong>API</strong>，请看下一部分 <strong>API Gateway Configuration</strong>。</p>
<h2 id="API-Gateway-Configuration"><a href="#API-Gateway-Configuration" class="headerlink" title="API Gateway Configuration"></a>API Gateway Configuration</h2><p>在 <a href="https://console.aws.amazon.com/console/home?region=us-east-1" target="_blank" rel="external">aws console</a> 页面的 <strong>Services -&gt; Application Service -&gt; API Gateway</strong> 下新建 API，然后在 <strong>Action</strong> 下拉框下 <strong>Create Resource</strong>，名称可以写 /number，然后继续 <strong>Create Method</strong> ，选 <strong>GET</strong>，Lambda Function 选择之前我们已经建好的 <code>random-number-generator</code></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/new%20api.png" class="ful-image" alt="new%20api.png">
<p>填写完毕后可以直接测试一下，产生了随机数 1。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/new%20api%20test1.png" class="ful-image" alt="new%20api%20test1.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/new%20api%20test2.png" class="ful-image" alt="new%20api%20test2.png">
<p>测试通过就可以部署，<strong>Actions -&gt; Deploy API</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/new%20api%20deploy.png" class="ful-image" alt="new%20api%20deploy.png">
<p>部署完成后会自动跳转到 Stages 页面，把 <strong>Invoke URL</strong> 记录下来。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/new%20api%20url.png" class="ful-image" alt="new%20api%20url.png">
<p>浏览器测试一下，注意补充 sub-resource，这里是 /number。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-04%20%E4%B8%8A%E5%8D%885.51.27.png" class="ful-image" alt="%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-06-04%20%E4%B8%8A%E5%8D%885.51.27.png">
<p>然后在其他应用里就可以直接通过 url 调用 API 啦～</p>
<h1 id="Example-2-Passing-information-through-API-Gateway"><a href="#Example-2-Passing-information-through-API-Gateway" class="headerlink" title="Example 2: Passing information through API Gateway"></a>Example 2: Passing information through API Gateway</h1><p>API 经常需要传参，那么怎么通过 <strong>API Gateway</strong> 传递参数呢？比如说我们希望让用户来定义产生随机数的范围，也就是 url 应该是下面这样的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">https://[API id].execute-api.us-east-1.amazonaws.com/prod/number?min=1&amp;max=10</div></pre></td></tr></table></figure>
<p>其实做法也很简单，先修改 <strong>Lambda function</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">&apos;use strict&apos;</div><div class="line">console.log(&apos;Loading function&apos;)</div><div class="line"></div><div class="line">exports.handler = (event, context, callback) =&gt; &#123;</div><div class="line">    let min = event.min;</div><div class="line">    let max = event.max;</div><div class="line"></div><div class="line">    let generatedNumber = Math.floor(Math.random() * (max - min)) + min;</div><div class="line"></div><div class="line">    callback(null, generatedNumber);</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>然后在 method 下选择 <strong>integration request</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/integration%20request1.png" class="ful-image" alt="integration%20request1.png">
<p>修改 <strong>Body Mapping Templates</strong>，新建 mapping template，添加下面的代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;min&quot;: $input.params(&apos;min&apos;),</div><div class="line">    &quot;max&quot;: $input.params(&apos;max&apos;)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后 <strong>Deploy api</strong>，浏览器测试下</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/rangetest.png" class="ful-image" alt="rangetest.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20API%20Gateway%20%2B%20Lambda%20%E6%95%99%E7%A8%8B%20-%20%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0/rangetest2.png" class="ful-image" alt="rangetest2.png">
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;非常简单的教程，以产生一定范围内的随机数为例，介绍如何用 AWS Lambda + API Gateway 建立一个 serveless API，包括 API 如何传参。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="QA System" scheme="http://www.shuang0420.com/categories/NLP/QA-System/"/>
    
    
      <category term="IoT" scheme="http://www.shuang0420.com/tags/IoT/"/>
    
      <category term="Alexa" scheme="http://www.shuang0420.com/tags/Alexa/"/>
    
      <category term="chatbot" scheme="http://www.shuang0420.com/tags/chatbot/"/>
    
      <category term="API Gateway" scheme="http://www.shuang0420.com/tags/API-Gateway/"/>
    
      <category term="Lambda" scheme="http://www.shuang0420.com/tags/Lambda/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络 CNN 笔记- 目标分类</title>
    <link href="http://www.shuang0420.com/2017/06/16/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/"/>
    <id>http://www.shuang0420.com/2017/06/16/卷积神经网络 CNN - 目标分类/</id>
    <published>2017-06-16T02:45:12.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>目标分类的基本框架 + 迁移学习 + 如何设计神经网络 + 实例:基于 VGG 进行人脸表情识别。深度学习的学习笔记。<br><a id="more"></a></p>
<h1 id="目标分类基本框架"><a href="#目标分类基本框架" class="headerlink" title="目标分类基本框架"></a>目标分类基本框架</h1><p>目标分类的<strong>应用场景</strong>有人脸识别、物体识别、场景识别、文字识别等，先看一下目标分类的基本框架。</p>
<ol>
<li>数据准备<br>数据足够？不够怎么增加数据量</li>
<li>模型设计<br>用现有模型？直接用复杂模型？<br>数据少的时候，设计简单网络进行简单学习，还是大网络进行特殊任务学习</li>
<li>训练细节<br>神经网络配件，参数等</li>
</ol>
<h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p><strong>数据来源:</strong> 现有数据集的子集; 网络采集; 现有数据人工标注<br>现有数据: <a href="http://deeplearning.net/datasets/" target="_blank" rel="external">http://deeplearning.net/datasets/</a> ，包含各种数据集如<em>自然图片/人工合成图片/人脸/文本/对话…</em></p>
<p><strong>数据扩充:</strong> 原始数据切割; 噪声颜色等像素变化; 旋转平移等姿态变化<br>如下图，一张图片经过了 5x 的像素级变化，包括平均/锐化(unsharp)/动作模糊(motion)等，每种又经过了 6x 的旋转平移，也就是说，原始数据扩充了 30x<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E6%95%B0%E6%8D%AE%E6%89%A9%E5%85%85.png" class="ful-image" alt="%E6%95%B0%E6%8D%AE%E6%89%A9%E5%85%85.png"></p>
<p>旋转平移 R, T 的矩阵变换<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E6%97%8B%E8%BD%AC%E5%B9%B3%E7%A7%BB.png" class="ful-image" alt="%E6%97%8B%E8%BD%AC%E5%B9%B3%E7%A7%BB.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E6%97%8B%E8%BD%AC%E5%B9%B3%E7%A7%BBmatlab.png" class="ful-image" alt="%E6%97%8B%E8%BD%AC%E5%B9%B3%E7%A7%BBmatlab.png"></p>
<p><strong>数据规范:</strong> 均值处理;归一化;大小调整<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># 均值处理</div><div class="line">tr_data = tr_data - MEAN_IMAGE</div><div class="line"></div><div class="line"># 归一化</div><div class="line">trdata/=256</div><div class="line"></div><div class="line"># 大小调整</div><div class="line">for t in range(3):</div><div class="line">	im224[t,:,:] = cv2.resize(imi[:,:,t], (224,224))</div><div class="line">datablob[i,:,:,:] = im224</div></pre></td></tr></table></figure></p>
<h2 id="模型设计"><a href="#模型设计" class="headerlink" title="模型设计"></a>模型设计</h2><h3 id="任务类型"><a href="#任务类型" class="headerlink" title="任务类型"></a>任务类型</h3><p><strong>分类：</strong>表情分类，属于什么种类，人群分类<br><strong>分类+回归：</strong>表情+程度，种类+信心，什么人+人数<br><strong>多目标分类：</strong>面部行为，群体行为，车流预测</p>
<h3 id="模型选取"><a href="#模型选取" class="headerlink" title="模型选取"></a>模型选取</h3><p>看<strong>现有模型(the-state-of-the-art)</strong>能否借鉴</p>
<ul>
<li>偏图像处理，CV：ICCV, ECCV, CVPR</li>
<li>偏理论，机器学习相关：ICML NIPS</li>
<li>偏语言处理，信息挖掘：ACL, KDD</li>
</ul>
<p>如果能借鉴，是否要做局部更改，从哪里改变；<br>如果不能借鉴，就需要从头设计，那么新结构特点是什么，为什么可行</p>
<h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><p>要考虑的问题有</p>
<ul>
<li><strong>GPU-Batch size，是否并行</strong><br>注意 GPU内存-Batch Size 的关系，batch size 设置太小，速度慢，batch 更新效果没那么好，如果设置过大，程序会崩掉</li>
<li><strong>数据循环方式／平衡性考虑</strong><ol>
<li>数量较少的类别，数据是否需要补偿</li>
<li>从头到尾多次循环(不利于类别不平衡的情况)</li>
<li>每次随机选取部分数据(更容易处理平衡性)</li>
</ol>
</li>
<li><strong>网络深度宽度确定</strong><br>直接答案当然是深度优先，主要原因是层数变多，能用更少的参数更有效的学习特征<br>如 5x5 一层卷积核相当于两层 3x3 卷积核，然而两层 3x3 只要 18 个参数，而一层 5x5 要 25 个参数</li>
<li><strong>损失函数设计</strong><br>比如分类用 SOFTMAX，还是直接拟合</li>
<li><strong>学习率变化方式</strong><br>模型各层学习率是否一致</li>
<li><strong>评价方式</strong><br>准确率，F1 score<br>比如在 0/1 分类中，评价方式的设计可能会偏向正例，因为很多情况下 0 会 overweight 1，假设分类结果全是 0，precision=90%，看起来很高，然而什么都没学到，所以要用 F1 score。<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">F1 score： 2*(Recall*Precision)/(Recall+Precison)</div><div class="line">Recall: 正确的1识别／真值所有1个数</div><div class="line">Precision:正确的1的识别／所有认为是1的个数</div></pre></td></tr></table></figure>
</li>
</ul>
<p>更多见 <a href="http://www.shuang0420.com/2017/01/20/卷积神经网络%20CNN%20笔记/">卷积神经网络 CNN 笔记</a> 功能层部分。</p>
<h1 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h1><p><strong>问题：</strong>ImageNet 上亿参数，数据量百万，是不是参数多的模型都需要大量数据？<br>当然不是啦，我们可以用别人训练好的模型(<strong>基础模型</strong>)，在训练好的部分参数基础上进行训练。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A01.png" class="ful-image" alt="%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A01.png"></p>
<p>那么什么情况下可以用迁移学习呢？主要看<strong>数据的性质以及数据量</strong>。如果只有少量数据，且和基础模型使用的数据比较类似，可以选择在全连接层更新参数，而如果数据非常不同，那么迁移学习可能就没什么用了；如果数据量大且类似，可以选择在中高层进行更新，而如果量大且不类似，那么可能只有模型的最开始几层的参数是有用的，也就是要更新更多层。<img src="不同数据处理.png" alt="不同数据处理"></p>
<p>基础模型的选择往往看是否已有特定任务的模型，另外关于 <strong>学习率(learning rate)</strong> 的处理，最低卷积层的学习率基本不变，中间卷积层看情况(数据是否类似等)，最后全连接，结构和参数都需要变化。</p>
<h1 id="如何设计神经网络"><a href="#如何设计神经网络" class="headerlink" title="如何设计神经网络"></a>如何设计神经网络</h1><p><strong>研究问题：</strong>如何进行面部行为识别(AU detection)<br>以如何进行面部行为识别为例，来学习如何设计神经网络。首先要明确的是，面部行为识别是一个<strong>多目标识别</strong>的问题，为什么呢？因为面部表情是由不同的<strong>面部行为单元</strong>相互配合而形成的，每个面部行为单元相当于一个目标，每个目标是一个 0/1 分类问题，0 表示 inactive，1 表示 active。(简单理解，比如微笑，至少需要嘴角上扬+眼角下垂两个条件组成)<img src="多目标识别.png" alt="多目标识别"></p>
<p>面部行为识别有很多的应用，比如测试疲劳驾驶等，一个很有意思的应用场景是推荐系统，想象看电视的时候有一个前置摄像头观察观众的反应，通过表情识别可以知道观众喜欢哪个节目，然后可以针对性的给更多高质量的推送，再比如应用到教育上面，如果能自动通过疑惑的表情判别出哪一部分学生不理解，可以针对性的给学生多解释几遍做巩固加强，当然这些都涉及到隐私问题，在这里不讨论。</p>
<h2 id="现有模型"><a href="#现有模型" class="headerlink" title="现有模型"></a>现有模型</h2><p>看一下已有方法/模型。<br><strong>Deepface</strong>，<a href="http://www.shuang0420.com/2017/04/25/卷积神经网络%20CNN%20笔记%28高级篇%29/">卷积神经网络 CNN 笔记(高级篇)</a></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/deepface.jpg" class="ful-image" alt="deepface.jpg">
<p>传统 CNN 用同一个卷积核对整张图片进行卷积运算，卷积核参数共享，不同局部特性对参数影响相互削弱，达不到最优的效果，对应的解决方法是局部卷积，不同的区域用不同参数。Deepface 对每个 pixel 都用单独一个卷积核来学习，这种<strong>全局部卷积连接</strong>有主要有下面几个缺陷</p>
<ul>
<li>预处理：大量对准，对对准要求高，原始信息可能丢失</li>
<li>卷积参数数量很大，模型收敛难度大，需要大量数据</li>
<li>模型可扩展性差，基本限于人脸计算</li>
</ul>
<p>也有人把特征图分成 8x8=64 小份，一小份一个卷积核，但是这并不能彻底解决上面的问题，我们的改进目标是：</p>
<ul>
<li>不需要预处理，自动进行局部探测</li>
<li>不要所有区域都处理，更多关注在有意义的区域<br>比如额头的信息就比较少，眼睛眉毛嘴巴的信息相对重要的多</li>
<li>重要区域之间不会影响削弱学习效果</li>
</ul>
<h2 id="注意力网络-attention-layer"><a href="#注意力网络-attention-layer" class="headerlink" title="注意力网络-attention layer"></a>注意力网络-attention layer</h2><p>一个想法是<strong>注意力网络-attention layer</strong>，通过权重来聚焦，如下图，我们的目标是看篮子里有什么，所以篮子给大的权重，其他地方不重要，就给小的权重，极端情况就是篮子给 1，其他部分给 0。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/attention%20layer.png" class="ful-image" alt="attention%20layer.png"></p>
<p>再来看一下注意力网络在面部行为识别上的应用<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/attention%20layer%20for%20face.png" class="ful-image" alt="attention%20layer%20for%20face.png"></p>
<p>左图是人脸的肌肉分布，中间的图绿色的点是特征点分布，蓝点是行为单元中心(action unit)，蓝点通过平移变换找到绿点，生成右图的 attention layer。步骤如下：</p>
<ol>
<li>Dlib(或原始数据集)找到人脸关键点</li>
<li>人脸关键点 -&gt; 行为单元中心</li>
<li>由中心生成注意力图<br>中心为 1，往外扩散</li>
</ol>
<p>这样在 CNN 结构下的注意力网络对误差的容忍度其实是很高的，原来 10 个 pixel 的误差经过几层 pooling 可能就到了 1 个甚至零点几个 pixel。</p>
<p>得到注意力网络后，我们需要对原始模型进行修改，一个问题是<strong>添加在哪里？什么方式添加？</strong>一个初始想法自然是放到中间做一个大的滤波，但是这样会完全丢掉不重要的区域，而我们希望保留原始结果，只是多加强下注意力，一个想法是采用 <strong>Residual net</strong> 的思想，将注意力层和之前的特征图层进行融合。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E6%B7%BB%E5%8A%A0attention%20layer.png" class="ful-image" alt="%E6%B7%BB%E5%8A%A0attention%20layer.png">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0.png" class="ful-image" alt="%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C%E6%B7%BB%E5%8A%A0.png">
<p>为什么添加在 3,4 层而不是 1,2 层呢？因为在 3,4 层表达会更强一些，1,2 层相对太底层。</p>
<p><strong>注意力网络的效果图：</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C%E6%95%88%E6%9E%9C.png" class="ful-image" alt="%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BD%91%E7%BB%9C%E6%95%88%E6%9E%9C.png"></p>
<h2 id="局部学习网络"><a href="#局部学习网络" class="headerlink" title="局部学习网络"></a>局部学习网络</h2><p>另一个想法是<strong>局部学习网络：针对不同的区域进行针对性学习，不同的区域的学习不会相互干扰，对区域的分布能够自动适应</strong>。方法也就是切割局部，形成局部神经网络，中间层可以做 upscaling，也就是反向 pooling，之后也可以做下 deconvolution，如下图：</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E5%B1%80%E9%83%A8%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%BB%9C.png" class="ful-image" alt="%E5%B1%80%E9%83%A8%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%BB%9C.png">
<h2 id="网络合并"><a href="#网络合并" class="headerlink" title="网络合并"></a>网络合并</h2><p><strong>网络合并：</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E7%BD%91%E7%BB%9C%E5%90%88%E5%B9%B6.png" class="ful-image" alt="%E7%BD%91%E7%BB%9C%E5%90%88%E5%B9%B6.png"></p>
<p>这种结构的效果还是非常不错的<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/%E6%95%88%E6%9E%9C.png" class="ful-image" alt="%E6%95%88%E6%9E%9C.png"></p>
<p>再总结下上面这种网络结构的作用：</p>
<ul>
<li>无需提前进行面部对准就可以对面部行为识别</li>
<li>脸部各个行为单元局部针对学习，局部信息 可以单独用于某个行为单元识别</li>
<li>根据控制肌肉的分布以及人脸特征点检测结 果确定区域，更具有合理性以及可操作性</li>
</ul>
<p>具体可以看论文<a href="https://arxiv.org/abs/1702.02925" target="_blank" rel="external">EAC-Net: A Region-based Deep Enhancing and Cropping Approach for Facial Action Unit Detection</a></p>
<h1 id="实例：基于-VGG-进行人脸表情识别"><a href="#实例：基于-VGG-进行人脸表情识别" class="headerlink" title="实例：基于 VGG 进行人脸表情识别"></a>实例：基于 VGG 进行人脸表情识别</h1><p><strong>数据集：</strong><a href="https://drive.google.com/open?id=0B3ANX1iL124qbmxOc2cyQzhvUFE" target="_blank" rel="external">CIFE:Candid image for facial expression</a><br>在 <a href="https://www.dropbox.com/s/9li9mi4105jf45v/vgg16.tflearn?dl=0" target="_blank" rel="external">vgg16</a> 基础上调整模型。</p>
<p><strong>vgg16:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/vgg16.png" class="ful-image" alt="vgg16.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20CNN%20-%20%E7%9B%AE%E6%A0%87%E5%88%86%E7%B1%BB/6.jpg" class="ful-image" alt="6.jpg"></p>
<p>这里选择在中高层更新参数(最后一个卷积群+全连接层)，模型代码如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">def vgg16(input=None, classes=1000):</div><div class="line">    x = tflearn.conv_2d(input, 64, 3, activation=&apos;relu&apos;, scope=&apos;conv1_1&apos;, trainable=False)</div><div class="line">    x = tflearn.conv_2d(x, 64, 3, activation=&apos;relu&apos;, scope=&apos;conv1_2&apos;, trainable=False)</div><div class="line">    x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool1&apos;)</div><div class="line"></div><div class="line">    x = tflearn.conv_2d(x, 128, 3, activation=&apos;relu&apos;, scope=&apos;conv2_1&apos;, trainable=False)</div><div class="line">    x = tflearn.conv_2d(x, 128, 3, activation=&apos;relu&apos;, scope=&apos;conv2_2&apos;, trainable=False)</div><div class="line">    x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool2&apos;)</div><div class="line"></div><div class="line">    x = tflearn.conv_2d(x, 256, 3, activation=&apos;relu&apos;, scope=&apos;conv3_1&apos;, trainable=False)</div><div class="line">    x = tflearn.conv_2d(x, 256, 3, activation=&apos;relu&apos;, scope=&apos;conv3_2&apos;, trainable=False)</div><div class="line">    x = tflearn.conv_2d(x, 256, 3, activation=&apos;relu&apos;, scope=&apos;conv3_3&apos;, trainable=False)</div><div class="line">    x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool3&apos;)</div><div class="line"></div><div class="line">    x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv4_1&apos;, trainable=False)</div><div class="line">    x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv4_2&apos;, trainable=False)</div><div class="line">    x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv4_3&apos;, trainable=False)</div><div class="line">    x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool4&apos;)</div><div class="line"></div><div class="line">    x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv5_1&apos;)</div><div class="line">    x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv5_2&apos;)</div><div class="line">    x = tflearn.conv_2d(x, 512, 3, activation=&apos;relu&apos;, scope=&apos;conv5_3&apos;)</div><div class="line">    x = tflearn.max_pool_2d(x, 2, strides=2, name=&apos;maxpool5&apos;)</div><div class="line"></div><div class="line">    x = tflearn.fully_connected(x, 4096, activation=&apos;relu&apos;, scope=&apos;fc6&apos;)</div><div class="line">    x = tflearn.dropout(x, 0.5, name=&apos;dropout1&apos;)</div><div class="line"></div><div class="line">    # change the structure, now fc only has 2048, leass parameters, which is enough for this task</div><div class="line">    x = tflearn.fully_connected(x, 2048, activation=&apos;relu&apos;, scope=&apos;fc7&apos;, restore=False)</div><div class="line">    x = tflearn.dropout(x, 0.5, name=&apos;dropout2&apos;)</div><div class="line"></div><div class="line">    x = tflearn.fully_connected(x, classes, activation=&apos;softmax&apos;, scope=&apos;fc8&apos;, restore=False)</div><div class="line"></div><div class="line">    return x</div></pre></td></tr></table></figure></p>
<p>完整代码<a href="https://github.com/Shuang0420/TensorFlow_Study/tree/master/emotion_vgg_finetune" target="_blank" rel="external">emotion_vgg_finetune</a></p>
<p>环境配置，docker 获取镜像 <a href="https://hub.docker.com/r/shuang0420/tensorflow-tflearn-python3-jupyter/" target="_blank" rel="external">shuang0420/tensorflow-tflearn-python3-jupyter</a></p>
<p>运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ docker run  --name notebooks -d -v /$(pwd):/notebooks -v /$(pwd)/tensorflow/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;</div><div class="line">$</div><div class="line">$ docker run  --name board -d -v /$(pwd)/tensorflow/logs:/logs -p 6006:6006 shuang0420/tensorflow-tflearn-python3-jupyter tensorboard --logdir /logs</div></pre></td></tr></table></figure></p>
<p><code>/$(pwd):</code> 和 <code>/$(pwd)/tensorflow/logs</code> 是本机目录，它把 container 中的 Jupyter notebooks 以及 logs 匹配到了本机目录，使得 container 和本机可以共享资源。当然首先要保证你的 docker 和 local host 有共享这些目录的权限，在 Docker Preferences 里可以设置。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目标分类的基本框架 + 迁移学习 + 如何设计神经网络 + 实例:基于 VGG 进行人脸表情识别。深度学习的学习笔记。&lt;br&gt;
    
    </summary>
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/categories/Deep-learning/"/>
    
      <category term="CNN" scheme="http://www.shuang0420.com/categories/Deep-learning/CNN/"/>
    
    
      <category term="Deep learning" scheme="http://www.shuang0420.com/tags/Deep-learning/"/>
    
      <category term="CNN" scheme="http://www.shuang0420.com/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>使用 Docker 快速配置深度学习(Tensorflow)环境</title>
    <link href="http://www.shuang0420.com/2017/06/15/%E4%BD%BF%E7%94%A8%20Docker%20%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Tensorflow%E7%8E%AF%E5%A2%83/"/>
    <id>http://www.shuang0420.com/2017/06/15/使用 Docker 快速配置深度学习Tensorflow环境/</id>
    <published>2017-06-15T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>用 docker 配置 tensorflow 环境(Tensorflow + Python3 + Jupyter Notebook + tflearn)，在 <a href="https://hub.docker.com/r/dash00/tensorflow-python3-jupyter/" target="_blank" rel="external">dash00/tensorflow-python3-jupyter</a> 基础上，添加 tflearn package，创建新的 docker image <a href="https://hub.docker.com/r/shuang0420/tensorflow-tflearn-python3-jupyter/" target="_blank" rel="external">shuang0420/tensorflow-tflearn-python3-jupyter</a></p>
<a id="more"></a>
<h1 id="Use-Other’s-Image"><a href="#Use-Other’s-Image" class="headerlink" title="Use Other’s Image"></a>Use Other’s Image</h1><p>我们在 <a href="https://hub.docker.com/r/dash00/tensorflow-python3-jupyter/" target="_blank" rel="external">dash00/tensorflow-python3-jupyter</a> 基础上创建自己的新镜像。</p>
<h2 id="Download-Image"><a href="#Download-Image" class="headerlink" title="Download Image"></a>Download Image</h2><p>首先获取镜像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker pull dash00/tensorflow-python3-jupyter</div></pre></td></tr></table></figure>
<p>原镜像 <code>dash00/tensorflow-python3-jupyter</code> 包含了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">- Jupyter Notebook</div><div class="line">- TensorFlow</div><div class="line">- scikit-learn</div><div class="line">- pandas</div><div class="line">- matplotlib</div><div class="line">- numpy</div><div class="line">- scipy</div><div class="line">- Pillow</div><div class="line">- Python 2 and 3</div></pre></td></tr></table></figure>
<h2 id="Start-Container"><a href="#Start-Container" class="headerlink" title="Start Container"></a>Start Container</h2><h3 id="Use-basic-container"><a href="#Use-basic-container" class="headerlink" title="Use basic container"></a>Use basic container</h3><p>如果用下面的启动方式，当结束 container 的时候，jupyter notebook 里的内容也会随之消失。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker run -it -p 8888:8888 dash00/tensorflow-python3-jupyter</div></pre></td></tr></table></figure>
<h3 id="Use-persistent-folder"><a href="#Use-persistent-folder" class="headerlink" title="Use persistent folder"></a>Use persistent folder</h3><p>这种启动方式将 notebook 内容存到了本地，本质上是一个 mapping。<code>/$(pwd)/notebooks</code> 就是本机 notebook 目录。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker run -it -p 8888:8888 -v /$(pwd)/notebooks:/notebooks dash00/tensorflow-python3-jupyter</div></pre></td></tr></table></figure>
<h3 id="Use-Jupyter-Notebook-and-Tensorboard-in-the-same-time"><a href="#Use-Jupyter-Notebook-and-Tensorboard-in-the-same-time" class="headerlink" title="Use Jupyter Notebook and Tensorboard in the same time"></a>Use Jupyter Notebook and Tensorboard in the same time</h3><p>同时运行 jupyter notebook 和 tensorboard</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ docker run  --name notebooks -d -v /$(pwd)/notebooks:/notebooks -v /$(pwd)/logs:/logs -p 8888:8888 dash00/tensorflow-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;</div><div class="line">$</div><div class="line">$ docker run  --name board -d -v /$(pwd)/logs:/logs -p 6006:6006 dash00/tensorflow-python3-jupyter tensorboard --logdir /logs</div></pre></td></tr></table></figure>
<p>打开浏览器输入 <code>http://&lt;CONTAINER_IP&gt;:8888/</code> 打开 jupyter notebook，输入 <code>http://&lt;CONTAINER_IP&gt;:6006/</code> 打开 tensorboard</p>
<h1 id="Modify-and-Create-New-Image"><a href="#Modify-and-Create-New-Image" class="headerlink" title="Modify and Create New Image"></a>Modify and Create New Image</h1><h2 id="Modify-Old-Image"><a href="#Modify-Old-Image" class="headerlink" title="Modify Old Image"></a>Modify Old Image</h2><p>进入 docker image，注意跟在 root@ 后面的 <code>97748739b45d</code> 就是新的 docker image id。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ docker run -it dash00/tensorflow-python3-jupyter /bin/bash</div><div class="line">root@97748739b45d:/notebooks#</div></pre></td></tr></table></figure>
<p>先看一下是什么系统<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">root@97748739b45d:/notebooks# lsb_release -a</div><div class="line">No LSB modules are available.</div><div class="line">Distributor ID:	Ubuntu</div><div class="line">Description:	Ubuntu 16.04.2 LTS</div><div class="line">Release:	16.04</div><div class="line">Codename:	xenial</div></pre></td></tr></table></figure></p>
<p><a href="https://hub.docker.com/r/dash00/tensorflow-python3-jupyter/" target="_blank" rel="external">dash00/tensorflow-python3-jupyter</a> 提到装了 python2 和 python3，tf 是装在 python3 下，所以 tflearn 也要装在 python3 下。发现默认 python 进入的是 python2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># python</div><div class="line">Python 2.7.12 (default, Nov 19 2016, 06:48:10)</div><div class="line">[GCC 5.4.0 20160609] on linux2</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; exit()</div><div class="line"># python3</div><div class="line">Python 3.5.2 (default, Nov 17 2016, 17:05:23)</div><div class="line">[GCC 5.4.0 20160609] on linux</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; exit()</div></pre></td></tr></table></figure></p>
<p>pip install 要在 python3 下，为了使用稳定版本的 tflearn，需要用到 git，尝试下以下命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># python3 -m pip install git+https://github.com/tflearn/tflearn.git</div><div class="line">Collecting git+https://github.com/tflearn/tflearn.git</div><div class="line">  Cloning https://github.com/tflearn/tflearn.git to /tmp/pip-u0c73_t1-build</div><div class="line">  Error [Errno 2] No such file or directory: &apos;git&apos; while executing command git clone -q https://github.com/tflearn/tflearn.git /tmp/pip-u0c73_t1-build</div><div class="line">Cannot find command &apos;git&apos;</div><div class="line">You are using pip version 8.1.1, however version 9.0.1 is available.</div><div class="line">You should consider upgrading via the &apos;pip install --upgrade pip&apos; command.</div></pre></td></tr></table></figure></p>
<p>发现没有装 git，就先装一下喽<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># apt-get update</div><div class="line"># apt-get install git</div></pre></td></tr></table></figure></p>
<p>再次 pip 下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># python3 -m pip install git+https://github.com/tflearn/tflearn.git</div><div class="line"># python3</div><div class="line">Python 3.5.2 (default, Nov 17 2016, 17:05:23)</div><div class="line">[GCC 5.4.0 20160609] on linux</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import tflearn</div><div class="line">hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)</div><div class="line">&gt;&gt;&gt;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># python3 -m pip install --upgrade pip</div><div class="line"># python3 -m pip install h5py</div></pre></td></tr></table></figure>
<p>成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># python3</div><div class="line">Python 3.5.2 (default, Nov 17 2016, 17:05:23)</div><div class="line">[GCC 5.4.0 20160609] on linux</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import tflearn</div><div class="line">&gt;&gt;&gt;</div></pre></td></tr></table></figure></p>
<h2 id="Commit-test-and-upload"><a href="#Commit-test-and-upload" class="headerlink" title="Commit, test, and upload"></a>Commit, test, and upload</h2><p>然后退出当前容器，通过命令 <code>docker commit</code> 来提交容器副本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># exit</div><div class="line">$ docker commit -m=&quot;install git and tflearn&quot; -a=&quot;shuang0420&quot; 97748739b45d shuang0420/tensorflow-tflearn-python3-jupyter:latest</div><div class="line">sha256:97748739b45dc8ce994521fa11d7ad6349bc83762e76139086789e0416560710</div></pre></td></tr></table></figure>
<p>各个参数说明：</p>
<ul>
<li><strong>-m:</strong>提交的描述信息</li>
<li><strong>-a:</strong>指定镜像作者</li>
<li><strong>e218edb10161：</strong>容器ID</li>
<li><strong>runoob/ubuntu:v2:</strong>指定要创建的目标镜像名</li>
</ul>
<p>使用 <code>docker images</code> 命令来查看我们的新镜像 <code>shuang0420/tensorflow-tflearn-python3-jupyter</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ docker images</div><div class="line">REPOSITORY                                  TAG                 IMAGE ID            CREATED             SIZE</div><div class="line">shuang0420/tensorflow-tflearn-python3-jupyter   latest              97748739b45d        20 hours ago        1.28 GB</div><div class="line">dash00/tensorflow-python3-jupyter           latest              34eeac184315        4 weeks ago         1.17 GB</div><div class="line">hello-world                                 latest              48b5124b2768        5 months ago        1.84 kB</div></pre></td></tr></table></figure>
<p>现在的镜像包含了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">- git</div><div class="line">- Jupyter Notebook</div><div class="line">- TensorFlow</div><div class="line">- tflearn</div><div class="line">- scikit-learn</div><div class="line">- pandas</div><div class="line">- matplotlib</div><div class="line">- numpy</div><div class="line">- scipy</div><div class="line">- Pillow</div><div class="line">- Python 2 and 3</div></pre></td></tr></table></figure>
<p>然后使用新镜像 <code>shuang0420/tensorflow-tflearn-python3-jupyter</code> 来启动一个容器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker run  --name notebooks -d -v /$(pwd)/notebooks:/notebooks -v /$(pwd)/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;</div></pre></td></tr></table></figure>
<p>如果出现下面的错误，说明之前已经启动了一个名为 notebooks 的 container，我们可以直接启动该容器，或者退出并删除原容器，新建一个。通过 <code>docker ps -a</code> 命令查看 container id 并删除该 container，再重新运行命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">docker: Error response from daemon: Conflict. The container name &quot;/notebooks&quot; is already in use by container 4602dc6d7f0b8b7756fa31d63a0ecb19bd37147c2af80710294a480587f9eb08. You have to remove (or rename) that container to be able to reuse that name..</div><div class="line">See &apos;docker run --help&apos;.</div><div class="line"></div><div class="line">$ docker ps -a</div><div class="line">CONTAINER ID        IMAGE                                              COMMAND                  CREATED             STATUS                           PORTS               NAMES</div><div class="line">4602dc6d7f0b        shuang0420/tenso![kitematic](kitematic.png)rflow-tflearn-python3-jupyter          &quot;/run_jupyter.sh -...&quot;   20 hours ago        Created                                              notebooks</div><div class="line">$</div><div class="line">$ docker rm 4602dc6d7f0b</div><div class="line">4602dc6d7f0b</div><div class="line">$ docker run  --name notebooks -d -v /$(pwd)/notebooks:/notebooks -v /$(pwd)/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;</div><div class="line">$ docker run  --name board -d -v /$(pwd)/logs:/logs -p 6006:6006 shuang0420/tensorflow-tflearn-python3-jupyter tensorboard --logdir /logs</div><div class="line">$</div></pre></td></tr></table></figure>
<p><strong>浏览器输入 <code>localhost:8888</code> 打开 jupyter notebook</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E4%BD%BF%E7%94%A8%20Docker%20%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Tensorflow%E7%8E%AF%E5%A2%83/tflearn.png" class="ful-image" alt="tflearn.png">
<p><strong>浏览器输入 <code>localhost:6006</code> 打开 jupyter notebook</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E4%BD%BF%E7%94%A8%20Docker%20%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Tensorflow%E7%8E%AF%E5%A2%83/tensorboard.png" class="ful-image" alt="tensorboard.png">
<p>当然也可以通过 <code>kitematic</code> 来直接控制 container 啦～～</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E4%BD%BF%E7%94%A8%20Docker%20%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Tensorflow%E7%8E%AF%E5%A2%83/kitematic.png" class="ful-image" alt="kitematic.png">
<p>用 <code>push</code> 命令将 image 上传到 docker hub<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ docker push shuang0420/tensorflow-tflearn-python3-jupyter:latest</div></pre></td></tr></table></figure></p>
<p>已上传至 docker hub，见 <a href="https://hub.docker.com/r/shuang0420/tensorflow-tflearn-python3-jupyter/" target="_blank" rel="external">shuang0420/tensorflow-tflearn-python3-jupyter</a></p>
<h1 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h1><h2 id="Run-jupyter-and-tensorboard"><a href="#Run-jupyter-and-tensorboard" class="headerlink" title="Run jupyter and tensorboard"></a>Run jupyter and tensorboard</h2><p><a href="https://hub.docker.com/r/shuang0420/tensorflow-tflearn-python3-jupyter/" target="_blank" rel="external">shuang0420/tensorflow-tflearn-python3-jupyter</a> 的使用方法，基本用法和 <a href="https://hub.docker.com/r/dash00/tensorflow-python3-jupyter/" target="_blank" rel="external">dash00/tensorflow-python3-jupyter</a> 相同。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ docker run  --name notebooks -d -v /$(pwd):/notebooks -v /$(pwd)/tensorflow/logs:/logs -p 8888:8888 shuang0420/tensorflow-tflearn-python3-jupyter /run_jupyter.sh --allow-root --NotebookApp.token=&apos;&apos;</div><div class="line">$</div><div class="line">$ docker run  --name board -d -v /$(pwd)/tensorflow/logs:/logs -p 6006:6006 shuang0420/tensorflow-tflearn-python3-jupyter tensorboard --logdir /logs</div></pre></td></tr></table></figure>
<p><code>/$(pwd):</code> 和 <code>/$(pwd)/tensorflow/logs</code> 是本机目录，它把 container 中的 Jupyter notebooks 以及 logs 匹配到了本机目录，使得 container 和本机可以共享资源。当然首先要保证你的 docker 和 local host 有共享这些目录的权限，在 Docker Preferences 里可以设置。</p>
<h2 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h2><p>用 <code>docker stats</code> 来查看 container 的资源使用状况。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">CONTAINER           CPU %               MEM USAGE / LIMIT       MEM %               NET I/O             BLOCK I/O           PIDS</div><div class="line">cb7ef0a4afc2        0.02%               8.438 MiB / 1.952 GiB   0.42%               219 kB / 1.2 MB     207 MB / 38.3 MB    2</div><div class="line">0e6a9a715cbd        0.00%               19.51 MiB / 1.952 GiB   0.98%               189 kB / 285 kB     1.24 GB / 2.23 GB   16</div></pre></td></tr></table></figure></p>
<p>或者进入 docker 用 <code>top</code> 查看。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">Last login: Mon Jun 19 16:11:32 on ttys000</div><div class="line">top - 13:38:02 up 1 day, 19:58,  0 users,  load average: 0.09, 0.17, 0.11</div><div class="line">Tasks:   6 total,   1 running,   5 sleeping,   0 stopped,   0 zombie</div><div class="line">%Cpu(s):  0.1 us,  0.1 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</div><div class="line">KiB Mem :  2046768 total,  1923504 free,    66636 used,    56628 buff/cache</div><div class="line">KiB Swap:  1048572 total,   683580 free,   364992 used.  1861204 avail Mem</div><div class="line"></div><div class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</div><div class="line">    1 root      20   0   18036      0      0 S   0.0  0.0   0:00.04 bash</div><div class="line">    7 root      20   0  300448  12820   5268 S   0.0  0.6   0:02.41 jupyter-noteboo</div><div class="line">   31 root      20   0   18248   1828   1648 S   0.0  0.1   0:00.07 bash</div><div class="line">  130 root      20   0  591052    688    688 S   0.0  0.0   0:00.78 python3</div><div class="line">  148 root      20   0   18244     12     12 S   0.0  0.0   0:00.02 bash</div><div class="line">  170 root      20   0   36644   1252   1032 R   0.0  0.1   0:00.46 top</div></pre></td></tr></table></figure></p>
<h2 id="Memory-and-CPU"><a href="#Memory-and-CPU" class="headerlink" title="Memory and CPU"></a>Memory and CPU</h2><p>Mac OS 默认给 docker 分配 4 个 CPU 和 2 GB 的内存，因此不管怎么用 <code>docker update</code> 和 <code>docker run</code> 命令来调整 container 的 CPU 和 memory，始终不能超过 docker 的限制，想要用更多的 cpu 和 memory 资源，只用在 Docker Preferences -&gt; Advanced 中调整即可。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E4%BD%BF%E7%94%A8%20Docker%20%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0Tensorflow%E7%8E%AF%E5%A2%83/docker%20preference.png" class="ful-image" alt="docker%20preference.png"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;用 docker 配置 tensorflow 环境(Tensorflow + Python3 + Jupyter Notebook + tflearn)，在 &lt;a href=&quot;https://hub.docker.com/r/dash00/tensorflow-python3-jupyter/&quot;&gt;dash00/tensorflow-python3-jupyter&lt;/a&gt; 基础上，添加 tflearn package，创建新的 docker image &lt;a href=&quot;https://hub.docker.com/r/shuang0420/tensorflow-tflearn-python3-jupyter/&quot;&gt;shuang0420/tensorflow-tflearn-python3-jupyter&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Configuration" scheme="http://www.shuang0420.com/categories/Configuration/"/>
    
    
      <category term="Tensorflow" scheme="http://www.shuang0420.com/tags/Tensorflow/"/>
    
      <category term="docker" scheme="http://www.shuang0420.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>AWS Lex 创建 Slack Bot - Integrating Lex Bot with Slack</title>
    <link href="http://www.shuang0420.com/2017/06/09/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/"/>
    <id>http://www.shuang0420.com/2017/06/09/AWS Lex 创建 Slack Bot - Integrating Lex Bot with Slack/</id>
    <published>2017-06-09T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>非常简单的教程，新建一个 Slack Bot 支持购买房/车的功能。主要流程: <strong>编写 Lambda Function =&gt; 调用 Lambda function 创建 Lex bot =&gt; 创建 Slack Application 并与 Lex bot 关联 =&gt; 测试并发布</strong>。<br><a id="more"></a></p>
<h1 id="Create-Lambda-Function"><a href="#Create-Lambda-Function" class="headerlink" title="Create Lambda Function"></a>Create Lambda Function</h1><p>Lambda Function 部分的代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">exports.handler = (event, context, callback) =&gt; &#123;</div><div class="line">    var purchase = event.currentIntent.slots.purchase,</div><div class="line">    price = &quot;free&quot;;</div><div class="line"></div><div class="line">    if (purchase === &quot;home&quot;) &#123;</div><div class="line">        price = &quot;200000 dollars&quot;;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    callback(null, &#123;</div><div class="line">        &quot;dialogAction&quot;: &#123;</div><div class="line">            &quot;type&quot;: &quot;Close&quot;,</div><div class="line">            &quot;fulfillmentState&quot;: &quot;Fulfilled&quot;,</div><div class="line">            &quot;message&quot;: &#123;</div><div class="line">                &quot;contentType&quot;: &quot;PlainText&quot;,</div><div class="line">                &quot;content&quot;: &quot;You have purchased a &quot; + event.currentIntent.slots.purchase + &quot; for &quot; + price</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>有一个 purchase 的 slot，这段代码返回的是，如果买房，价格 200000 刀，如果买其他东西(slot value 限制下)，都免费。</p>
<p>Lambda 的配置不多说了，和 <a href="http://www.shuang0420.com/2017/06/05/Alexa%20开发新技能%20-%20Lambda/">Alexa 开发新技能 - Lambda</a>的配置相同。</p>
<p>供测试的 <strong>input event example</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;currentIntent&quot;: &#123;</div><div class="line">    &quot;name&quot;: &quot;PurchaseIntent&quot;,</div><div class="line">    &quot;slots&quot;: &#123;</div><div class="line">      &quot;purchase&quot;: &quot;home&quot;</div><div class="line">    &#125;,</div><div class="line">    &quot;confirmationStatus&quot;: &quot;Confirmed&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;bot&quot;: &#123;</div><div class="line">    &quot;name&quot;: &quot;bot-name&quot;,</div><div class="line">    &quot;alias&quot;: &quot;bot-alias&quot;,</div><div class="line">    &quot;version&quot;: &quot;bot-version&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;userId&quot;: &quot;User ID specified in the POST request to Amazon Lex.&quot;,</div><div class="line">  &quot;inputTranscript&quot;: &quot;Text used to process the request&quot;,</div><div class="line">  &quot;invocationSource&quot;: &quot;FulfillmentCodeHook or DialogCodeHook&quot;,</div><div class="line">  &quot;outputDialogMode&quot;: &quot;Text or Voice, based on ContentType request header in runtime API request&quot;,</div><div class="line">  &quot;messageVersion&quot;: &quot;1.0&quot;,</div><div class="line">  &quot;sessionAttributes&quot;: &#123;</div><div class="line">     &quot;key1&quot;: &quot;value1&quot;,</div><div class="line">     &quot;key2&quot;: &quot;value2&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>Expect Result:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/expectRes.png" class="ful-image" alt="expectRes.png"></p>
<h1 id="Create-Amazon-Lex-Bot"><a href="#Create-Amazon-Lex-Bot" class="headerlink" title="Create Amazon Lex Bot"></a>Create Amazon Lex Bot</h1><p>登录 <a href="https://console.aws.amazon.com/lex/" target="_blank" rel="external">AWS Lex</a>，新建一个 bot(get started =&gt; custom bot)，过程非常简单，设置基本信息包括 bot name, output voice, session timeout 等，然后创建 slot type，设置 intent，基本流程和 <a href="http://www.shuang0420.com/2017/06/05/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/">Alexa add new skill</a> (尤其是 Skill Builder Beta 界面)差不多，直接上截图了。</p>
<p><strong>Create Lex Bot:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/lex1.png" class="ful-image" alt="lex1.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/lex2.png" class="ful-image" alt="lex2.png"></p>
<p><strong>Add slot type:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/AddSlot.png" class="ful-image" alt="AddSlot.png"><br>保存的 slot type 在之后所有的 bot 设置中都可以重复使用。</p>
<p><strong>Add intent:</strong><br>提供一些 <strong>Sample utterances</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">I would like to purchase a &#123;purchase&#125;​</div><div class="line">Buy me a &#123;purchase&#125;​</div><div class="line">I&apos;m going to buy a &#123;purchase&#125;​</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/lex3.png" class="ful-image" alt="lex3.png">
<p><strong>Call lambda function:</strong><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/lex4.png" class="ful-image" alt="lex4.png"></p>
<p>如果用户输入了除 <strong>slot value (这里是 home, car)</strong>以外的东西，就会触发 <strong>Prompt</strong>。</p>
<p>设置好之后选择 save intent，然后选右上角的 build，创建完成后就可以开始测试 bot，这里的测试结果有点不如人意，prompt 并没有起到作用，然而没关系，最后在 Slack 界面是 work 的<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/lex5.png" class="ful-image" alt="lex5.png"></p>
<h1 id="Create-Slack-Application"><a href="#Create-Slack-Application" class="headerlink" title="Create Slack Application"></a>Create Slack Application</h1><p>如果没有 Slack 账号，需要先注册<a href="https://get.slack.help/hc/en-us/articles/212675257-Creating-a-Slack-account" target="_blank" rel="external">注册</a><br>登录<a href="http://api.slack.com/" target="_blank" rel="external">Slack API</a>，选择 start building =&gt; create an app，然后进行相关设置:</p>
<ol>
<li>In the left menu, choose <strong>Bot Users</strong>.<ul>
<li>Provide a user name.</li>
<li>For <strong>Always Show My Bot as Online</strong>, choose <strong>On</strong>.<br>Save the changes.</li>
</ul>
</li>
<li>Choose <strong>Interactive Messages</strong> from the left menu.<ul>
<li>Choose <strong>Enable Interactive Messages</strong>.</li>
<li>Specify any valid URL in the <strong>Request URL</strong> box. For example, you can use <a href="https://slack.com" target="_blank" rel="external">https://slack.com</a>.<br>Note<br>For now, enter any valid URL so that you get the verification token that you need in the next step. You will update this URL after you add the bot channel association in the Amazon Lex console.</li>
<li>Choose <strong>Enable Interactive Messages</strong>.</li>
</ul>
</li>
<li>In the <strong>Settings</strong> section in the left menu, choose <strong>Basic Information</strong>. Record the following application credentials:<ul>
<li>Client ID</li>
<li>Client Secret</li>
<li>Verification Token</li>
</ul>
</li>
</ol>
<h1 id="Integrate-the-Slack-Application-with-the-Amazon-Lex-Bot"><a href="#Integrate-the-Slack-Application-with-the-Amazon-Lex-Bot" class="headerlink" title="Integrate the Slack Application with the Amazon Lex Bot"></a>Integrate the Slack Application with the Amazon Lex Bot</h1><p>找到之前创建的 <a href="https://console.aws.amazon.com/lex/" target="_blank" rel="external">lex bot</a>，到 <strong>Channels</strong> 标签页，在左边菜单栏选择 <strong>Slack</strong>，并提供下面的信息：</p>
<ul>
<li>Type a name. For example, <code>BotSlackIntegration</code>.</li>
<li>Choose “aws/lex” from the <strong>KMS key</strong> drop-down.</li>
<li>For <strong>Alias</strong>, choose the bot alias.</li>
<li>Type the <strong>Client Id</strong>, <strong>Client secret</strong>, and <strong>Verification Token</strong>, which you recorded in the preceding step. These are the credentials of the Slack application.</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/Channels.png" class="ful-image" alt="Channels.png">
<p>关于 Aliases 的问题，可以在 <strong>Settings</strong> 的 <strong>Aliases</strong> 部分进行设置，发现不设置 Alias 的话 Activate Bot 的时候可能会出错，所以还是设置下吧~<br>设置好后  <strong>Activate</strong>，记录下 <strong>Postback URL</strong> 和 <strong>OAuth URL</strong>，然后回到 <a href="http://api.slack.com/" target="_blank" rel="external">Slack Application</a> 页面，做如下设置：</p>
<ol>
<li>Update the <strong>OAuth &amp; Permissions</strong> feature as follows:<ol>
<li>In the <strong>Redirect URLs</strong> section, add the OAuth URL that Amazon Lex provided in the preceding step. Choose <strong>Add a new Redirect URL</strong>, and then choose <strong>Save URLs</strong>.</li>
<li>In the <strong>Permission Scopes</strong> section, choose two permissions in the <strong>Select Permission Scopes</strong> drop down. Filter the list with the following text:<ul>
<li><strong>chat:write:bot</strong></li>
<li><strong>team:read</strong><br>Choose <strong>Save Changes</strong>.</li>
</ul>
</li>
</ol>
</li>
<li>Update the <strong>Interactive Messages</strong> feature by updating the <strong>Request URL</strong> value to the Postback URL that Amazon Lex provided in the preceding step. Choose <strong>Add</strong>, and then choose <strong>Save URLs</strong>.</li>
<li>Subscribe to the <strong>Event Subscriptions</strong> feature as follows:<ul>
<li>Enable events by choosing the <strong>On</strong> option.</li>
<li>Set the <strong>Request URL</strong> value to the Postback URL that Amazon Lex provided in the preceding step.</li>
<li>Subscribe to the <code>message.im</code> bot event to enable direct messaging between the end user and the Slack bot.</li>
<li>Save the changes.</li>
</ul>
</li>
</ol>
<p>这里没什么 tricky 的地方，要注意的是每一步都要记得 <strong>Save</strong></p>
<h1 id="Test-the-Integration"><a href="#Test-the-Integration" class="headerlink" title="Test the Integration"></a>Test the Integration</h1><ol>
<li>Choose <strong>Manage Distribution</strong> under <strong>Settings</strong>. Choose <strong>Add to Slack</strong> to install the application. Authorize the bot to respond to messsages.</li>
<li>You are redirected to your Slack team. Choose your bot from the <strong>Direct Messages</strong> section in the left menu. If you don’t see your bot, choose the plus icon (+) next to <strong>Direct Messages</strong> to search for your bot.</li>
<li>Engage in a chat with your Slack application, which is linked to the Amazon Lex bot. Your bot now responds to messages.<img src="http://ox5l2b8f4.bkt.clouddn.com/images/AWS%20Lex%20%E5%88%9B%E5%BB%BA%20Slack%20Bot%20-%20Integrating%20Lex%20Bot%20with%20Slack/Slack%20test.png" class="ful-image" alt="Slack%20test.png">
</li>
</ol>
<blockquote>
<p>参考链接：<br><a href="http://docs.aws.amazon.com/lex/latest/dg/slack-bot-assoc-create-bot.html" target="_blank" rel="external">Integrating with Slack</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;非常简单的教程，新建一个 Slack Bot 支持购买房/车的功能。主要流程: &lt;strong&gt;编写 Lambda Function =&amp;gt; 调用 Lambda function 创建 Lex bot =&amp;gt; 创建 Slack Application 并与 Lex bot 关联 =&amp;gt; 测试并发布&lt;/strong&gt;。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="QA System" scheme="http://www.shuang0420.com/categories/NLP/QA-System/"/>
    
    
      <category term="IoT" scheme="http://www.shuang0420.com/tags/IoT/"/>
    
      <category term="Alexa" scheme="http://www.shuang0420.com/tags/Alexa/"/>
    
      <category term="Slack" scheme="http://www.shuang0420.com/tags/Slack/"/>
    
      <category term="chatbot" scheme="http://www.shuang0420.com/tags/chatbot/"/>
    
      <category term="物联网" scheme="http://www.shuang0420.com/tags/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
      <category term="Lex" scheme="http://www.shuang0420.com/tags/Lex/"/>
    
  </entry>
  
  <entry>
    <title>Alexa 开发新技能 - Lambda</title>
    <link href="http://www.shuang0420.com/2017/06/05/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/"/>
    <id>http://www.shuang0420.com/2017/06/05/Alexa 开发新技能 - Lambda/</id>
    <published>2017-06-05T12:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>非常简单的教程，讲怎么给 Alexa 添加新的 skill，让你的 Echo 更个性化。本篇添加的 skill 是让 Alexa 从 reddit 上读前 10 条热点。<br><a id="more"></a></p>
<p>代码戳<a href="https://github.com/Shuang0420/Alexa-Starter-RedditReader/tree/master/reddit_reader_lambda" target="_blank" rel="external">Alexa-Starter-RedditReader</a>，其他版本如用 python flask 实现，见<a href="http://www.shuang0420.com/2017/05/02/Alexa%20开发新技能/">Alexa 开发新技能 - python flask</a>。这一篇截图比较细，一方面是因为 AWS 版本迭代太快，网上之前的教程可能会过时，另一方面实在是因为一步步做下来踩了很多坑，争取这篇教程可以让大家少走一些弯路。</p>
<p>这一篇会用到 AWS Lambda，Lambda 的优势官方说明描述的很清楚，简单来说最显著的优点就是，与 <a href="http://www.shuang0420.com/2017/05/02/Alexa%20开发新技能/">Alexa 开发新技能 - python flask</a> 相比，我们不再需要后端运行代码并通过 ngrok 等工具将代码部署到公开网络。</p>
<blockquote>
<p>通过 AWS Lambda，无需配置或管理服务器即可运行代码。您只需按消耗的计算时间付费 – 代码未运行时不产生费用。借助 Lambda，您几乎可以为任何类型的应用程序或后端服务运行代码，而且全部无需管理。只需上传您的代码，Lambda 会处理运行和扩展高可用性代码所需的一切工作。您可以将您的代码设置为自动从其他 AWS 服务触发，或者直接从任何 Web 或移动应用程序调用。</p>
</blockquote>
<p>总结下来 AWS Lambda 有以下几个特点:</p>
<ul>
<li>run code in response to events</li>
<li>no maintenance of server, no worry about infrastructure</li>
<li>scale automatically</li>
<li>never pay for idle</li>
</ul>
<p>下面介绍怎么来用 Nodejs 和 Lambda 实现 Reddit Reader。</p>
<h1 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h1><ul>
<li>Nodejs 4.3</li>
<li><a href="https://developer.amazon.com/edw/home.html" target="_blank" rel="external">Amazon Developer Account</a></li>
</ul>
<h1 id="Code-for-new-skill-Lambda-Function"><a href="#Code-for-new-skill-Lambda-Function" class="headerlink" title="Code for new skill (Lambda Function)"></a>Code for new skill (Lambda Function)</h1><p>这里我们使用 Lambda function，get_headlines() 是我们主要的 method，从 Reddit 里返回 10 条热点。逻辑是这样的：</p>
<ul>
<li>(用户呼唤 Reddit Reader)</li>
<li>Alexa 问用户 ‘Hello there, would you like the news?’</li>
<li>用户回答<br>肯定回复: 读 10 headlines<br>否定回复: 回答 ‘I am not sure why you asked me to run then, but okay… bye’</li>
</ul>
<p>首先建好 project 框架<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ mkdir alexaproject</div><div class="line">$ cd alexaproject/</div><div class="line">$ npm init</div><div class="line">$ mkdir src</div><div class="line">$ touch src/index.js</div></pre></td></tr></table></figure></p>
<p>设置相关依赖<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ npm install alexa-sdk --save</div><div class="line">$ npm install request --save</div></pre></td></tr></table></figure></p>
<p>版本：</p>
<ul>
<li>“alexa-sdk”: “^1.0.9”,</li>
<li>“request”: “^2.81.0”</li>
</ul>
<p>代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">&apos;use strict&apos;;</div><div class="line"></div><div class="line">var Alexa = require(&quot;alexa-sdk&quot;);</div><div class="line">var request = require(&apos;request&apos;);</div><div class="line"></div><div class="line">exports.handler = function(event, context, callback) &#123;</div><div class="line">  var alexa = Alexa.handler(event, context, callback);</div><div class="line">  alexa.appId = &quot;amzn1.ask.skill.[YOUR_APP_ID]&quot;;</div><div class="line">  alexa.registerHandlers(handlers);</div><div class="line">  alexa.execute();</div><div class="line">&#125;</div><div class="line"></div><div class="line">var handlers = &#123;</div><div class="line">  &quot;LaunchRequest&quot;: function() &#123;</div><div class="line">    var speechOutput = &quot;Hello there, would you like the news?&quot;;</div><div class="line">    var reprompt = speechOutput;</div><div class="line">    this.emit(&apos;:ask&apos;, speechOutput, reprompt);</div><div class="line">  &#125;,</div><div class="line">  &quot;YesIntent&quot;: function() &#123;</div><div class="line">    var self = this;</div><div class="line">    get_headlines(function(headlines) &#123;</div><div class="line">      var speechOutput = &apos;The current world news headlines are &apos; + headlines;</div><div class="line">      self.emit(&apos;:tell&apos;, speechOutput);</div><div class="line">    &#125;);</div><div class="line">  &#125;,</div><div class="line">  &quot;NoIntent&quot;: function() &#123;</div><div class="line">    var speechOutput = &apos;I am not sure why you asked me to run then, but okay... bye&apos;</div><div class="line">    this.emit(&apos;:tell&apos;, speechOutput);</div><div class="line">  &#125;,</div><div class="line">  &quot;AMAZON.StopIntent&quot;: function() &#123;</div><div class="line">    var speechOutput = &quot;Good bye! Thank you for using Reddit Reader&quot;;</div><div class="line">    this.emit(&apos;:tell&apos;, speechOutput);</div><div class="line">  &#125;,</div><div class="line">  &quot;AMAZON.CancelIntent&quot;: function() &#123;</div><div class="line">    var speechOutput = &quot;Good bye! Thank you for using Reddit Reader&quot;;</div><div class="line">    this.emit(&apos;:tell&apos;, speechOutput);</div><div class="line">  &#125;,</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function get_headlines(callback) &#123;</div><div class="line">  request(&apos;https://reddit.com/r/worldnews/.json?limit=10&apos;, function (error, response, body) &#123;</div><div class="line">    if (!error &amp;&amp; response.statusCode == 200) &#123;</div><div class="line">      var body=JSON.parse(body)[&apos;data&apos;][&apos;children&apos;];</div><div class="line">      var res = &quot;&quot;;</div><div class="line">      body.forEach(function(ele)&#123;</div><div class="line">        res = res + ele[&apos;data&apos;][&apos;title&apos;] + &quot; &quot;;</div><div class="line">      &#125;);</div><div class="line">    &#125;</div><div class="line">    return callback(res);</div><div class="line">  &#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如果不用 alexa-sdk，也可以自己搭一个框架出来，如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div></pre></td><td class="code"><pre><div class="line">&apos;use strict&apos;;</div><div class="line"></div><div class="line">var request = require(&apos;request&apos;);</div><div class="line">exports.handler = function(event, context) &#123;</div><div class="line">  try &#123;</div><div class="line">    console.log(&quot;event.session.application.applicationId&quot;) + event.session.application.applicationId;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * Uncomment this if statement and populate with your skill&apos;s application ID to</div><div class="line">     * prevent someone else from configuring a skill that sends requests to this function.</div><div class="line">     */</div><div class="line"></div><div class="line">    if (event.session.application.applicationId !== &quot;[YOUR_APP_ID]&quot;) &#123;</div><div class="line">         context.fail(&quot;Invalid Application ID&quot;);</div><div class="line">     &#125;</div><div class="line"></div><div class="line"></div><div class="line">    if (event.session.new) &#123;</div><div class="line">      onSessionStarted(&#123;requestId: event.request.requestId&#125;, event.session);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    if (event.request.type === &quot;LaunchRequest&quot;) &#123;</div><div class="line">      onLaunch(event.request,</div><div class="line">          event.session,</div><div class="line">          function callback(sessionAttributes, speechletResponse) &#123;</div><div class="line">            context.succeed(buildResponse(sessionAttributes, speechletResponse));</div><div class="line">          &#125;);</div><div class="line">    &#125; else if (event.request.type === &quot;IntentRequest&quot;) &#123;</div><div class="line">      onIntent(event.request,</div><div class="line">          event.session,</div><div class="line">          function callback(sessionAttributes, speechletResponse) &#123;</div><div class="line">            context.succeed(buildResponse(sessionAttributes, speechletResponse));</div><div class="line">          &#125;);</div><div class="line">    &#125; else if (event.request.type === &quot;SessionEndedRequest&quot;) &#123;</div><div class="line">      onSessionEnded(event.request, event.session);</div><div class="line">      context.succeed();</div><div class="line">    &#125;</div><div class="line">  &#125; catch (e) &#123;</div><div class="line">    context.fail(&quot;Exception: &quot; + e);</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">/**</div><div class="line"> * called when the user invokes the skill without specifying what they want.</div><div class="line"> */</div><div class="line">function onLaunch(launchRequest, session, callback) &#123;</div><div class="line">  getWelcomeResponse(callback)</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">/**</div><div class="line"> * Called when the user specifies an intent for this skill.</div><div class="line"> */</div><div class="line">function onIntent(intentRequest, session, callback) &#123;</div><div class="line">  var intent = intentRequest.intent</div><div class="line">  var intentName = intentRequest.intent.name;</div><div class="line"></div><div class="line">  // dispatch custom intents to handlers here</div><div class="line">  if (intentName == &quot;&quot;) &#123;</div><div class="line">    handleResponse(intent, session, callback)</div><div class="line">  &#125; else if (intentName == &quot;YesIntent&quot;) &#123;</div><div class="line">    handleYesResponse(intent, session, callback)</div><div class="line">  &#125; else if (intentName == &quot;NoIntent&quot;) &#123;</div><div class="line">    handleNoResponse(intent, session, callback)</div><div class="line">  &#125; else if (intentName == &quot;AMAZON.StopIntent&quot;) &#123;</div><div class="line">    // not used here</div><div class="line">    // handleGetHelpRequest(intent, session, callback)</div><div class="line">  &#125; else if (intentName == &quot;AMAZON.CancelIntent&quot;) &#123;</div><div class="line">    handleFinishSessionRequest(intent, session, callback)</div><div class="line">  &#125; else if (intentName == &quot;AMAZON.HelpIntent&quot;) &#123;</div><div class="line">    handleFinishSessionRequest(intent, session, callback)</div><div class="line">  &#125; else &#123;</div><div class="line">    throw &quot;Invalid intent&quot;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">/**</div><div class="line"> * Called when the session starts.</div><div class="line"> */</div><div class="line">function onSessionStarted(sessionStartedRequest, session) &#123;</div><div class="line">    console.log(&quot;onSessionStarted requestId=&quot; + sessionStartedRequest.requestId</div><div class="line">                + &quot;, sessionId=&quot; + session.sessionId);</div><div class="line">&#125;</div><div class="line"></div><div class="line">/**</div><div class="line"> * Called when the user ends the session.</div><div class="line"> * Is not called when the skill returns shouldEndSession=true.</div><div class="line"> */</div><div class="line">function onSessionEnded(sessionEndedRequest, session) &#123;</div><div class="line">    console.log(&quot;onSessionEnded requestId=&quot; + sessionEndedRequest.requestId</div><div class="line">                + &quot;, sessionId=&quot; + session.sessionId);</div><div class="line">    // Add cleanup logic here</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function getWelcomeResponse(callback) &#123;</div><div class="line">  var speechOutput = &quot;Hello there, would you like the news?&quot;</div><div class="line"></div><div class="line">  var reprompt = speechOutput</div><div class="line"></div><div class="line">  var header = &quot;news&quot;</div><div class="line"></div><div class="line">  var shouldEndSession = false</div><div class="line"></div><div class="line">  var sessionAttributes = &#123;</div><div class="line">    &quot;speechOutput&quot;: speechOutput,</div><div class="line">    &quot;repromptText&quot;: reprompt</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  callback(sessionAttributes, buildSpeechletResponse(header, speechOutput, reprompt, shouldEndSession))</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function handleYesResponse(intent, session, callback) &#123;</div><div class="line">  get_headlines(function(headlines) &#123;</div><div class="line">    var speechOutput = &apos;The current world news headlines are &apos; + headlines;</div><div class="line">    var shouldEndSession = true</div><div class="line">    callback(session.attributes, buildSpeechletResponseWithoutCard(speechOutput, &quot;&quot;, shouldEndSession))</div><div class="line">  &#125;);</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function handleNoResponse(intent, session, callback) &#123;</div><div class="line">  var speechOutput = &apos;I am not sure why you asked me to run then, but okay... bye&apos;</div><div class="line">  var shouldEndSession = true</div><div class="line">  callback(session.attributes, buildSpeechletResponseWithoutCard(speechOutput, &quot;&quot;, shouldEndSession))</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">function buildSpeechletResponse(title, output, repromptText, shouldEndSession) &#123;</div><div class="line">  return &#123;</div><div class="line">    outputSpeech: &#123;</div><div class="line">      type: &quot;PlainText&quot;,</div><div class="line">      text: output</div><div class="line">    &#125;,</div><div class="line">    card: &#123;</div><div class="line">      type: &quot;Simple&quot;,</div><div class="line">      title: title,</div><div class="line">      content: output</div><div class="line">    &#125;,</div><div class="line">    reprompt: &#123;</div><div class="line">      outputSpeech: &#123;</div><div class="line">        type: &quot;PlainText&quot;,</div><div class="line">        text: repromptText</div><div class="line">      &#125;</div><div class="line">    &#125;,</div><div class="line">    shouldEndSession: shouldEndSession</div><div class="line">  &#125;;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function buildSpeechletResponseWithoutCard(output, repromptText, shouldEndSession) &#123;</div><div class="line">  return &#123;</div><div class="line">    outputSpeech: &#123;</div><div class="line">      type: &quot;PlainText&quot;,</div><div class="line">      text: output</div><div class="line">    &#125;,</div><div class="line">    reprompt: &#123;</div><div class="line">      outputSpeech: &#123;</div><div class="line">        type: &quot;PlainText&quot;,</div><div class="line">        text: repromptText</div><div class="line">      &#125;</div><div class="line">    &#125;,</div><div class="line">    shouldEndSession: shouldEndSession</div><div class="line">  &#125;;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function buildResponse(sessionAttributes, speechletResponse) &#123;</div><div class="line">  return &#123;</div><div class="line">    version: &quot;1.0&quot;,</div><div class="line">    sessionAttributes: sessionAttributes,</div><div class="line">    response: speechletResponse</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function handleFinishSessionRequest(intent, session, callback) &#123;</div><div class="line">  callback(session.attributes, buildSpeechletResponseWithoutCard(&quot;Good bye! Thank you for using Reddit Reader&quot;,&quot;&quot;,true))</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">function get_headlines(callback) &#123;</div><div class="line">  request(&apos;https://reddit.com/r/worldnews/.json?limit=10&apos;, function (error, response, body) &#123;</div><div class="line">    if (!error &amp;&amp; response.statusCode == 200) &#123;</div><div class="line">      var body=JSON.parse(body)[&apos;data&apos;][&apos;children&apos;];</div><div class="line">      var res = &quot;&quot;;</div><div class="line">      body.forEach(function(ele)&#123;</div><div class="line">        res = res + ele[&apos;data&apos;][&apos;title&apos;] + &quot; &quot;;</div><div class="line">      &#125;);</div><div class="line">    &#125;</div><div class="line">    return callback(res);</div><div class="line">  &#125;);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>更多方法戳<a href="https://github.com/alexa/alexa-skills-kit-sdk-for-nodejs" target="_blank" rel="external">alexa-skills-kit-sdk-for-nodejs</a></strong></p>
<h1 id="Lambda-Configuration"><a href="#Lambda-Configuration" class="headerlink" title="Lambda Configuration"></a>Lambda Configuration</h1><p>登录<a href="https://console.aws.amazon.com" target="_blank" rel="external">AWS console</a>在 Service 下选择 Lambda<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA1.png" class="ful-image" alt="LAMBDA1.png"></p>
<p>Create a Lambda function，选 Node.js.4.3, Blank Function<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA2.png" class="ful-image" alt="LAMBDA2.png"></p>
<p>Configure Triggers，选 Alexa Skills Kit<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA3.png" class="ful-image" alt="LAMBDA3.png"></p>
<p>Configure Function，如下设置<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA4.png" class="ful-image" alt="LAMBDA4.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA5.png" class="ful-image" alt="LAMBDA5.png"></p>
<p>注意两个点，代码上传后，Handler 的路径设置必须和代码中 handler 文件的路径相一致，建议对文件内所有文件打包，而不是直接对文件夹打包。Role 如果没有 existing role，可以新建一个。</p>
<p>完成后选择新建的 function，在 Action 里选择 Configure test event<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA6.png" class="ful-image" alt="LAMBDA6.png"></p>
<p>选择 Alexa Start Session，修改 Applicatio ID，即 Alexa console 里的 Application ID，在 Deploy 下会讲到。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/DEVELOPERCONSOLE.png" class="ful-image" alt="DEVELOPERCONSOLE.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA7.png" class="ful-image" alt="LAMBDA7.png"></p>
<p>选择 Save and Test，返回结果<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/LAMBDA8.png" class="ful-image" alt="LAMBDA8.png"></p>
<h1 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h1><p>去<a href="https://developer.amazon.com" target="_blank" rel="external">Amazon developer</a> 网站上注册用户并登陆，注意这里的用户名和你的 Echo 用户名是一致的。点开 Alexa tab，选择 add skill，开始部署。</p>
<p><strong>Step1:</strong><br>填写 Name 和 Invocation Name，Invocation Name 用来 invoke app，Application ID 可以在保存页面后找到，<strong>需要添加到代码以及 Configure test event 里</strong>，如果需要对 Lambda 页面进行测试的话。<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/1.jpg" class="ful-image" alt="1.jpg"></p>
<p><strong>Step2:</strong><br>主要填写 Intent Schema 和 Sample Utterances</p>
<p><strong>Intent Schema: </strong>how alexa will traverse your application</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&#123; &quot;intents&quot;: [&#123; &quot;intent&quot;: &quot;YesIntent&quot; &#125;,</div><div class="line">			  &#123; &quot;intent&quot;: &quot;NoIntent&quot; &#125;]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><strong>Sample Utterances:</strong> the words people say to trigger intent<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">YesIntent yes</div><div class="line">YesIntent sure</div><div class="line"></div><div class="line">NoIntent no</div><div class="line">NoIntent go away</div></pre></td></tr></table></figure></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/2.jpg" class="ful-image" alt="2.jpg">
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/3.jpg" class="ful-image" alt="3.jpg">
<p><strong>Step3:</strong><br>选择并填写 Endpoint，即 AWS Lambda 下 function 的 ARN<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/6.png" class="ful-image" alt="6.png"><br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/4.png" class="ful-image" alt="4.png"></p>
<p><strong>Step4:</strong><br>就可以用 Echo 来 test 啦~ 如果没有 Echo，可以用 <strong>Service Simulator</strong> 来模拟，可以输入 text，也可以输入 json<br>先给 Alexa 一个关于 Reddit Reader 的指令，然后按照我们的代码，Alexa 会问你要不要读新闻<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/7.jpg" class="ful-image" alt="7.jpg"></p>
<p>然后我们回答 yes，Alexa 就开始读新闻啦~<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/Alexa%20%E5%BC%80%E5%8F%91%E6%96%B0%E6%8A%80%E8%83%BD%20-%20Lambda/8.jpg" class="ful-image" alt="8.jpg"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;非常简单的教程，讲怎么给 Alexa 添加新的 skill，让你的 Echo 更个性化。本篇添加的 skill 是让 Alexa 从 reddit 上读前 10 条热点。&lt;br&gt;
    
    </summary>
    
      <category term="IoT" scheme="http://www.shuang0420.com/categories/IoT/"/>
    
    
      <category term="IoT" scheme="http://www.shuang0420.com/tags/IoT/"/>
    
      <category term="Alexa" scheme="http://www.shuang0420.com/tags/Alexa/"/>
    
      <category term="物联网" scheme="http://www.shuang0420.com/tags/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
      <category term="Echo" scheme="http://www.shuang0420.com/tags/Echo/"/>
    
  </entry>
  
  <entry>
    <title>NLP 笔记 - Sentiment Analysis</title>
    <link href="http://www.shuang0420.com/2017/06/01/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/"/>
    <id>http://www.shuang0420.com/2017/06/01/NLP 笔记 - Sentiment Analysis/</id>
    <published>2017-06-01T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>Stanford Dan Jurafsky &amp; Chris Manning: Natural Language Processing 课程笔记。<br><a id="more"></a></p>
<p><strong>Sentiment Analysis</strong> 有许多别称，如 Opinion extraction/Opinion mining/Sentiment mining/Subjectivity analysis，都是同一个意思，不过隐含着不同的应用场景。大致来说，情感分析有以下的应用:</p>
<p><strong>Products:</strong> 产品评价，不仅仅是简单的好评差评，情感分析还能分析人们对具体产品的具体属性的具体评价，如下图，对 product review 抽取 aspects/attributes，判断 sentiment，最后 aggregate 得出结果<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/product%20sentiment.png" class="ful-image" alt="product%20sentiment.png"><br><strong>Public sentiment:</strong> 公众意见(public opinion)，比如说分析消费者信息指数，股票指数等。之前就有人做过用 CALM 来预测道琼斯指数(Bollen et al. 2011 Twitter mood predicts the stock market)，算法也应用到了工业场景<br><strong>Politics:</strong> 公共政策，看公众对候选人/政治议题的看法<br><strong>Prediction:</strong> 预测选举结果，预测市场趋势等等。</p>
<p>一个成熟的产品<a href="https://www.csc2.ncsu.edu/faculty/healey/tweet_viz/tweet_app/" target="_blank" rel="external">Twitter Sentiment App</a>，能够通过 Twitter 数据来分析人们对某个品牌/话题的情感<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/Twitter%20sentiment%20app.jpg" class="ful-image" alt="Twitter%20sentiment%20app.jpg"></p>
<blockquote>
<p><strong>Attitudes</strong>: “enduring, affectively colored beliefs, dispositions towards objects or persons”</p>
</blockquote>
<p>Sentiment analysis 说白了就是来分析人们对一个事物的<strong>态度(attitudes)</strong>，包含下面几个元素(以 Mary likes the movie 为例)</p>
<ul>
<li>Holder (source) of attitude<br>持有态度的人: Mary</li>
<li>Target (aspect) of attitude<br>对象: the movie</li>
<li>Type of attitude<br>态度类型: like<br><strong>From a set of types:</strong> Like, love, hate, value, desire, etc.<br><strong>Or (more commonly) simple weighted polarity:</strong> positive, negative, neutral, together with strength</li>
<li>Text containing the attitude<br>文本: Mary likes the movie<br>Sentence or entire document</li>
</ul>
<p>最简单的情感分析任务，或者说在情感分析方向的 baseline model，是分析/预测电影评论是 positive 还是 negative 的。</p>
<h1 id="Baseline-Algorithm"><a href="#Baseline-Algorithm" class="headerlink" title="Baseline Algorithm"></a>Baseline Algorithm</h1><p>常用到的语料库 <a href="hXp://www.cs.cornell.edu/people/pabo/movie-­‐review-­‐data" target="_blank" rel="external">IMDB Polarity Data 2.0</a>，<br><strong>目的：</strong> polarity detection: is this review positive or negative?<br><strong>步骤：</strong></p>
<ol>
<li>Tokenization</li>
<li>Feature Extraction</li>
<li>Classification using different classifiers<ul>
<li>Naive Bayes</li>
<li>MaxEnt</li>
<li>SVM</li>
</ul>
</li>
</ol>
<h2 id="Sentiment-Tokenization"><a href="#Sentiment-Tokenization" class="headerlink" title="Sentiment Tokenization"></a>Sentiment Tokenization</h2><p>除了正常 tokenization 要注意的问题如处理 HTML/XML markup 外，情感分析还可能需要处理</p>
<ul>
<li><strong>twitter markup</strong>(hashtag 等)</li>
<li><strong>Capitalization:</strong> 大小写通常会保留，大写字母往往反映强烈的情感</li>
<li><strong>Emotions</strong>(表情符号)</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/Emoticons.png" class="ful-image" alt="Emoticons.png">
<p>有用的 Tokenizer 代码</p>
<ul>
<li><a href="https://github.com/dlatk/happierfuntokenizing" target="_blank" rel="external">Christopher Potts sentiment tokenizer</a></li>
<li><a href="https://github.com/brendano/tweetmotif" target="_blank" rel="external">Brendan O’Connor twitter tokenizer</a></li>
</ul>
<h2 id="Extracting-Features"><a href="#Extracting-Features" class="headerlink" title="Extracting Features"></a>Extracting Features</h2><p>关于特征提取，两个重要的问题，一是怎么来<strong>处理否定词(negation)</strong>，二是<strong>选什么词作为特征</strong>。</p>
<h3 id="Negation"><a href="#Negation" class="headerlink" title="Negation"></a>Negation</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">I didn&apos;t like this movie</div><div class="line">I really like this movie</div></pre></td></tr></table></figure>
<p>如果对否定词不做处理，那么上面两条评论的结果都是 positive，这显然不对。一种有效的处理否定词的方案是<strong>对否定词后、下一个标点符号前的每个词都加上 NOT_ 的前缀来作为标识</strong>，如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">didn&apos;t like this movie, but I</div><div class="line">=&gt;</div><div class="line">didn&apos;t NOT_like NOT_this NOT_movie but I</div></pre></td></tr></table></figure></p>
<p>具体见<br>Das, Sanjiv and Mike Chen. 2001. Yahoo! for Amazon: Extracting market sentiment from stock message boards. In Proceedings of the Asia Paciﬁc Finance Association Annual Conference (APFA).<br>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. EMNLP-2002, 79—86.</p>
<h3 id="Words-to-use"><a href="#Words-to-use" class="headerlink" title="Words to use"></a>Words to use</h3><p>一般两种方案，一是仅仅<strong>使用形容词(adjectives)</strong>，而是使用<strong>所有的单词(all words)</strong>，通常而言，使用所有的词的效果会更好些，因为动词(verbs)、名词(nouns)会提供更多有用的信息。</p>
<h2 id="Classifier"><a href="#Classifier" class="headerlink" title="Classifier"></a>Classifier</h2><p>作为 Baseline model，这里会使用 Naive Bayes，没啥悬念，计算如下</p>
<p>$$c_{NB}=argmax_{c_j \in C} P(c_j) \prod_{i \in positions} P(w_i | c_j)$$</p>
<ul>
<li><strong>Prior:</strong> how likely we see a positive movie review</li>
<li><strong>Likelihood Function:</strong> for every review, how likely every word is expressed by a positive movie review</li>
</ul>
<p>采用 <strong>Laplace/Add-one Smoothing</strong></p>
<p>$$\hat P(w|c)={count(w,c)+1 \over count(c)+|V|}$$</p>
<p>一个变种或者改进版是<strong>Binarized(Boolean feature) Multinomial Naive Bayes</strong>，它基于这样一个直觉，对情感分析而言，单词是否出现(word occurrence)这个特征比单词出现了几次(word frequency)更为重要，举个例子，出现一次 fantastic 提供了 positive 的信息，而出现 5 次 fantastic 并没有给我们提供更多信息。boolean multinomial Naive Bayes 就是把所有大于 1 的 word counts 压缩为 1。</p>
<p>算法<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/boolean%20multinomial%20naive%20bayes.jpg" class="ful-image" alt="boolean%20multinomial%20naive%20bayes.jpg"></p>
<p>也有研究认为取中间值 log(freq(w)) 效果更好一些，相关论文如下：<br>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sen+ment Classiﬁcation using Machine Learning Techniques. EMNLP-­‐2002, 79—86.<br>V. Metsis, I. Androutsopoulos, G. Paliouras. 2006. Spam Filtering with Naive Bayes – Which Naive Bayes? CEAS 2006 -­‐ Third Conference on Email and Anti‐Spam.<br>K.-­‐M. Schneider. 2004. On word frequency informa+on and negative evidence in Naive Bayes text classiﬁca+on. ICANLP, 474-­‐485.<br>JD Rennie, L Shih, J Teevan. 2003. Tackling the poor assumptions of naive bayes text classiﬁers. ICML 2003</p>
<p><em>当然在实践中，MaxEnt 和 SVM 的效果要比 Naive Bayes 好的多</em></p>
<h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><p>有些句子里并<strong>不包含情感词(sentiment word)</strong>，如下面一句是 negative 的态度，然而并不能通过情感词来得出</p>
<p>“If you are reading this because it is your darling fragrance, please wear it at home exclusively, and tape the windows shut.”</p>
<p>还有一个问题是<strong>排序问题(Order effect)</strong>，尽管前面堆砌了很多情感词，但最后来个全盘否定，显然 Naive Bayes 没法处理这种问题<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/Order%20effects.png" class="ful-image" alt="Order%20effects.png"></p>
<h1 id="Sentiment-Lexicons"><a href="#Sentiment-Lexicons" class="headerlink" title="Sentiment Lexicons"></a>Sentiment Lexicons</h1><p>看一下目前已经有的 Lexicons，</p>
<ul>
<li><a href="http://www.wjh.harvard.edu/~inquirer" target="_blank" rel="external">The General Inquirer</a><ul>
<li><a href="http://www.wjh.harvard.edu/~inquirer/homecat.htm" target="_blank" rel="external">List of Categories</a></li>
<li><a href="http://www.wjh.harvard.edu/~inquirer/inquirerbasic.xls" target="_blank" rel="external">Spreadsheet</a></li>
</ul>
</li>
<li><a href="http://www.liwc.net/" target="_blank" rel="external">LIWC(Linguistic Inquiry and Word Count)</a></li>
<li><a href="http://www.cs.pitt.edu/mpqa/subj_lexicon.html" target="_blank" rel="external">MPQA Subjectivity Cues Lexicon</a></li>
<li><a href="http://www.cs.uic.edu/~liub/FBS/opinion-­‐lexicon-­‐English.rar" target="_blank" rel="external">Bing Liu Opinion Lexicon</a></li>
<li><a href="http://sentiwordnet.isti.cnr.it/" target="_blank" rel="external">SentiWordNet</a></li>
</ul>
<p>看下各个词库的 disagreements between polarity lexicons<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/disagreement%20between%20polarity.png" class="ful-image" alt="disagreement%20between%20polarity.png"></p>
<p>那么怎么来分析 IMDB 里每个单词的 polarity 呢？<br><strong>How likely is each word to appear in each sentiment class?</strong><br><strong>likelihood:</strong> $$P(w|c)={f(w,c) \over \sum_{w \in c} f(w,c)}$$<br><strong>Make them comparable between words - Scaled likelihood:</strong><br>$${P(w|c)\over P(w)}$$</p>
<p>更多见 Potts, Christopher. 2011. On the negativity of negation. SALT 20, 636-­‐659.</p>
<h1 id="Learning-Sentiment-Lexicons"><a href="#Learning-Sentiment-Lexicons" class="headerlink" title="Learning Sentiment Lexicons"></a>Learning Sentiment Lexicons</h1><p>除了目前已有的 lexicon，我们还可以根据自己的语料库来训练自己的 sentiment lexicon。</p>
<h2 id="Semi-supervised-learning-of-lexicons"><a href="#Semi-supervised-learning-of-lexicons" class="headerlink" title="Semi-supervised learning of lexicons"></a>Semi-supervised learning of lexicons</h2><p>基于<strong>少量的有标注的数据+人工建立的规则</strong>，采用 <strong>bootstrap</strong> 方法来学习 lexicon</p>
<h3 id="Hatzivassiloglou-and-McKeown-intuition-for-identifying-word-polarity"><a href="#Hatzivassiloglou-and-McKeown-intuition-for-identifying-word-polarity" class="headerlink" title="Hatzivassiloglou and McKeown intuition for identifying word polarity"></a>Hatzivassiloglou and McKeown intuition for identifying word polarity</h3><p><strong>论文:</strong> Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the Semantic Orientation of Adjectives. ACL, 174–181</p>
<p>基于这样的<strong>假设</strong>:</p>
<ul>
<li>用 AND 连起来的形容词有着相同的 polarity<br>fair <strong>and</strong> legitimate, corrupt <strong>and</strong> brutal</li>
<li>用 BUT 连起来的形容词则相反<br>fair <strong>but</strong> brutal</li>
</ul>
<p><strong>论文方法：</strong></p>
<ol>
<li>对 1336 个形容词形成的种子集合进行标注，657 个 positive，679 个 negative</li>
<li>通过 google 搜索来查询 conjoined 形容词，eg. “was nice and”<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/STEP2.png" class="ful-image" alt="STEP2.png"></li>
<li>Supervised classifier 通过 count(AND), count(BUT) 来给每个词对(word pair)计算 polarity similarity<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/STEP3.png" class="ful-image" alt="STEP3.png"></li>
<li>将 graph 分区<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/STEP4.png" class="ful-image" alt="STEP4.png">
</li>
</ol>
<p>这种方法难以处理短语</p>
<h3 id="Turnev-Algorithm"><a href="#Turnev-Algorithm" class="headerlink" title="Turnev Algorithm"></a>Turnev Algorithm</h3><p><strong>论文:</strong> Turney (2002):Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews</p>
<p><strong>步骤:</strong></p>
<ol>
<li>从评论中抽取形容词短语(two-word phrase)<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/phrase1.png" class="ful-image" alt="phrase1.png"></li>
<li>学习短语的 polarity<br>如何衡量短语的 polarity 呢？<br>基于下面的假设<ul>
<li>Positive phrases co-‐occur more with <em>“excellent”</em></li>
<li>Negative phrases co-­‐occur more with <em>“poor”</em><br>用 PMI(Pointwise Mutual Information) 来计算 co-occurrence<br><strong>Mutual information</strong> between 2 random variables X and Y<br>$$I(X,Y)=\sum_x \sum_y P(x,y)log_2{P(x,y) \over P(x)P(y)}$$<br><strong>Pointwise mutual information:</strong> how much more do events x and y co-occur than if they were independent<br>$$PMI(X,Y)=log_2{P(x,y) \over P(x)P(y)}$$<br>同样通过搜索引擎(Altavista)查询得到概率<br>P(word) = hits(word)/N<br>$P(word_1,word_2)=hits(word_1 \ NEAR \ word_2)/N^2$<br>$$P(word_1,word_2)=log_2 {hits(word_1 \ NEAR \ word_2) \over hits(word_1)hits(word_2)}$$<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/Polarity%20phrase.png" class="ful-image" alt="Polarity%20phrase.png"></li>
</ul>
</li>
<li>Rate a review by the average polarity of its phrases</li>
</ol>
<p>一般来说 baseline 的准确率是 59%, Turney algorithm 可以提高到 74%</p>
<h3 id="Using-WordNet-to-learn-polarity"><a href="#Using-WordNet-to-learn-polarity" class="headerlink" title="Using WordNet to learn polarity"></a>Using WordNet to learn polarity</h3><p><strong>论文:</strong><br>S.M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. COLING 2004<br>M. Hu and B. Liu. Mining and summarizing customer reviews. In Proceedings of KDD, 2004</p>
<p><strong>步骤:</strong></p>
<ol>
<li>有一小部分 positive/negative seed-words</li>
<li>从 WordNet 中找到 seed-words 的同义词(synonyms)和反义词(antonyms)<br><strong>Positive Set:</strong> positive words 的同义词 + negative words 的反义词<br><strong>Negative Set:</strong> negative words 的同义词 + positive words 的反义词</li>
<li>重复 2 直到达到终止条件</li>
<li>过滤不合适的词</li>
</ol>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>采用半监督方法来引入 lexicons，好处是:</p>
<ul>
<li>can be domain-specific</li>
<li>can be more robust(for more/new words)</li>
</ul>
<p><strong>Intuition:</strong></p>
<ol>
<li>starts with a seed set of words(good,poor)</li>
<li>find other words that have similar polarity:<br>•  Using “and” and “but”<br>•  Using words that occur nearby in the same document<br>•  Using WordNet synonyms and antonyms</li>
</ol>
<h1 id="Other-Sentiment-Tasks"><a href="#Other-Sentiment-Tasks" class="headerlink" title="Other Sentiment Tasks"></a>Other Sentiment Tasks</h1><h2 id="Finding-aspects-attributes-target"><a href="#Finding-aspects-attributes-target" class="headerlink" title="Finding aspects/attributes/target"></a>Finding aspects/attributes/target</h2><p><strong>论文:</strong><br>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proceedings of KDD.<br>S. Blair-­‐Goldensohn, K. Hannan, R. McDonald, T. Neylon, G. Reis, and J. Reynar. 2008. Building a Sen+ment Summarizer for Local Service Reviews. WWW Workshop.</p>
<p>很多时候，一条评论并不能简单的被归为 positive/negative，它可能讨论了多个维度，既有肯定又有否定，如下面这个句子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">The food was great but the service was awful!</div></pre></td></tr></table></figure></p>
<p>这条评论就是对食物(food)持肯定态度(positive)，对服务(service)持否定态度(negative)，在这种情况下，我们不能简单的对这条评论进行 positive/negative 的分类，而要对其在 food，service 这两个维度上的态度进行分类。<strong>food，service 这些维度，或者说 attributes/aspects/target 从哪里来？</strong> 有两种方法，一种是从文本中抽取常用短语+规则来作为 attributes/aspects，另一种是预先定义好 attributes/aspects</p>
<h3 id="Frequent-phrases-rules"><a href="#Frequent-phrases-rules" class="headerlink" title="Frequent phrases + rules"></a>Frequent phrases + rules</h3><p>首先找到产品评论里的高频短语，然后按规则进行过滤，可用的规则如找紧跟在 sentiment word 后面的短语，”…great fish tacos” 表示 fish tacos 是一个可能的 aspect</p>
<h3 id="Supervised-classification"><a href="#Supervised-classification" class="headerlink" title="Supervised classification"></a>Supervised classification</h3><p>对一些领域如 restaurants/hotels 来说，aspects 比较规范，所以事实上可以人工给一些产品评论标注 aspect(aspects 如 food, décor, service, value, NONE)，然后再给每个句子/短语分类看它属于哪个 aspect</p>
<p>具体步骤:</p>
<ol>
<li>从评论中抽取句子/短语</li>
<li>对句子/短语进行情感分类</li>
<li>得到句子/短语的 aspects</li>
<li>汇总得到 summary<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Sentiment%20Analysis/sentiment%20for%20aspects.png" class="ful-image" alt="sentiment%20for%20aspects.png">
</li>
</ol>
<p>值得注意的是，baseline method 的假设是<strong>所有类别出现的概率是相同的</strong>。如果类别不平衡(在现实中往往如此)，我们不能用 accuracy 来评估，而是需要用 F-scores。而类别不平衡的现象越严重，分类器的表现可能就越差。有两个办法来解决这个问题</p>
<ol>
<li>Resampling in training<br>就是说如果 pos 有10^6 条数据，neg 有 10^4 的数据，那么我们都从 10^4 的数据中来划分训练数据</li>
<li>Cost-sensitive learning<br>对较少出现的那个类别的 misclassification 加大惩罚(penalize SVM more for misclassification of the rare thing)</li>
</ol>
<h2 id="How-to-deal-with-7-stars"><a href="#How-to-deal-with-7-stars" class="headerlink" title="How to deal with 7 stars"></a>How to deal with 7 stars</h2><p><strong>论文:</strong> Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. ACL, 115–124</p>
<p>怎样来处理评分型的评论？</p>
<ol>
<li>Map to binary<br>压缩到 positive/negative。比如说大于 3.5 的作为 negative，其他作为 positive</li>
<li>Use linear or ordinal regression<br>or specialized models like metric labeling</li>
</ol>
<h2 id="Summary-on-Sentiment"><a href="#Summary-on-Sentiment" class="headerlink" title="Summary on Sentiment"></a>Summary on Sentiment</h2><p>通常被建立分类/回归模型来预测 binary/ordinal 类别<br><strong>关于特征提取:</strong></p>
<ul>
<li>negation 很重要</li>
<li>对某些任务，在 Naive bayes 里使用所有的词汇表现更好</li>
<li>对其他任务，可能用部分词汇更好<br>Hand-built polarity lexicons<br>Use seeds and semi-supervised learning to induce lexicons</li>
</ul>
<h1 id="Computational-work-on-other-affective-states"><a href="#Computational-work-on-other-affective-states" class="headerlink" title="Computational work on other affective states"></a>Computational work on other affective states</h1><p>对其他任务也可以用相似手段</p>
<ul>
<li>Emotion:<br>•  Detecting annoyed callers to dialogue system<br>•  Detecting confused/frustrated versus conﬁdent students</li>
<li>Mood:<br>•  Finding traumatized or depressed writers</li>
<li>Interpersonal stances:<br>•  Detection of flirtation or friendliness in conversations</li>
<li>  Personality traits:<br>•  Detection of extroverts</li>
</ul>
<p>E.g., Detection of Friendliness</p>
<p>Friendly speakers use collaborative conversational style<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">- Laughter</div><div class="line">- Less use of negative emotional words</div><div class="line">- More sympathy</div><div class="line">​  That’s too bad I’m sorry to hear that!</div><div class="line">- More agreement</div><div class="line">​	 I think so too!</div><div class="line">- Less hedges</div><div class="line">​	 kind of sort of a little …</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Stanford Dan Jurafsky &amp;amp; Chris Manning: Natural Language Processing 课程笔记。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Course" scheme="http://www.shuang0420.com/categories/NLP/Course/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="sentiment analysis" scheme="http://www.shuang0420.com/tags/sentiment-analysis/"/>
    
      <category term="情感分析" scheme="http://www.shuang0420.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记 - Learning to Extract Conditional Knowledge for Question Answering using Dialogue</title>
    <link href="http://www.shuang0420.com/2017/05/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/"/>
    <id>http://www.shuang0420.com/2017/05/24/论文笔记 - Learning to Extract Conditional Knowledge for Question Answering using Dialogue/</id>
    <published>2017-05-24T05:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>论文<a href="http://dl.acm.org/citation.cfm?id=2983777" target="_blank" rel="external">Learning to Extract Conditional Knowledge for Question Answering using Dialogue</a>提出了 conditional knowledge base(CKB)，存储的信息格式为 (subject, predicate, object|condition)。当用户问句缺少必要条件(condition)时，自动用 dialogue model 来向用户提问获取必要信息，再进行回答。<br><a id="more"></a><br>简化版过程，从训练数据的用户问句里抽取实体，频率最高的 50% 作为 subject，剩余的作为 candidate condition。对于每一个 subject，学习用户问句的 pattern 和 condition (类似于关系抽取)，然后学习 pattern 和 condition 的 embedding，并对其进行聚类得到 pattern cluster 和 condition cluster，再从聚类信息和 QA 对中抽取信息组成 (subject, predicate, object|condition) 作为 CKB。</p>
<p>当用户提问并没有清楚的指定条件时，就可以用  dialogue model 向用户提问获取 condition，具体过程如下</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/structure.jpg" class="ful-image" alt="structure.jpg">
<p>用户界面演示<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/example.jpg" class="ful-image" alt="example.jpg"></p>
<h1 id="Pattern-mining"><a href="#Pattern-mining" class="headerlink" title="Pattern mining"></a>Pattern mining</h1><p>这一步的目的是学习 pattern 和 condition，用 bootstrapping 方法。</p>
<p><strong>input:</strong> all questions with the same subject<br><strong>output:</strong> question patterns; conditions</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Eg.,</div><div class="line"></div><div class="line">input: windows_xp free upgrade windows_10</div><div class="line">subject: windows_10</div><div class="line">candidate condition: windows_xp</div><div class="line">pattern: SLOT0 free upgrade windows_10</div></pre></td></tr></table></figure>
<p>输入有两个 entities, windows_xp 和 windows_10，windows_10 被选为 subject，那么 windows_xp 就是 candidate condition，然后我们产生了 pattern “SLOT0 free upgrade windows_10”，当遇到下面新的输入时，win7 就会被抽取作为 candidate condition，因为输入和 pattern 正好匹配</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">new input: win7 free upgrade windows_10</div><div class="line">pattern: SLOT0 free upgrade windows_10</div><div class="line">new candidate condition: win7</div></pre></td></tr></table></figure>
<p>一个问题是<strong>怎么来产生初始的种子</strong>，方法是</p>
<ul>
<li>remove question words</li>
<li>use special type of words for question chucking<br>special type of words: prepositions, copulas, interrogatives, conjunctions, modal verbs, personal pronouns, verbs, some stop words</li>
<li>add remaining parts into seed dictionary</li>
</ul>
<h1 id="Pattern-Aggregation"><a href="#Pattern-Aggregation" class="headerlink" title="Pattern Aggregation"></a>Pattern Aggregation</h1><p>这一步非常简单，就是做一个 groupby，把上一步产生的相同 pattern 不同 condition 的输出按 pattern 分组，见 Step2</p>
<h1 id="Condition-and-Pattern-Representation-Learning"><a href="#Condition-and-Pattern-Representation-Learning" class="headerlink" title="Condition and Pattern Representation Learning"></a>Condition and Pattern Representation Learning</h1><p>不同的 pattern 可能反应了相同的 user intent，这一步的目的就是对 pattern 进行聚类，目的是希望每一个类别代表一个 user intent。同时，对聚类后的每一个 pattern cluster 的 condition 进行聚类，聚类标准是在当前 condition 下的问题是否拥有相似的 answer。</p>
<p>首先学习 pattern 和 condition 的 embedding。对此论文提出了一种新的算法 <strong>patterns and conditions jointly embedding algorithm(PCJE)</strong>，由 <strong>condition embedding model, pattern embedding model 和 alignment model</strong> 三个 model 组成，目标函数是三个 model 的目标函数之和。</p>
<p><strong>Condition embedding model</strong> 主要看 $p(c_k, c_m)$，通过 Skip-gram 来学习 question, answer, condition pairs 的嵌入向量，要注意的是，这里 Skip-gram 的目标函数最大化 $J_c = J(\theta) + \beta E_c$，其中 $ J(\theta) $ 是 Skip-gram 原本的目标函数, $E_c$ 是正则化后的 condition pair($c_k,c_m$) 的联合概率，如下</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/skipgram.jpg" class="ful-image" alt="skipgram.jpg">
<p>$$p(c_k,c_m) = {1 \over 1+exp(-c^T_kc_m)}$$<br>$$E_c=\sum_{(k,m) \in P_c} w^c_{km}logp(c_k,c_m)$$</p>
<p><strong>Pattern embedding model</strong> 主要看 $p(v_k, v_m)$<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/patternEmbedding.jpg" class="ful-image" alt="patternEmbedding.jpg"></p>
<p><strong>Alignment model</strong> 主要看 $p(c_k, v_m)$，通过 pattern 和 condition 的共现关系来对齐两个向量空间<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/alignmentModel.jpg" class="ful-image" alt="alignmentModel.jpg"></p>
<p>整体需要优化的目标函数<br>$$J=J_c+J_p+J_\alpha$$</p>
<h1 id="Conditions-and-Patterns-Clustering"><a href="#Conditions-and-Patterns-Clustering" class="headerlink" title="Conditions and Patterns Clustering"></a>Conditions and Patterns Clustering</h1><p><strong>input:</strong> patterns, conditions, embedding representations<br><strong>output:</strong> pattern clusters, condition clusters</p>
<blockquote>
<p><strong>patterns in the same cluster will share the same intent, which is predicate in classical KB.</strong></p>
</blockquote>
<p>用了下面的层次聚类算法<br><img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/co-clustering%20algorithm.jpg" class="ful-image" alt="co-clustering%20algorithm.jpg"></p>
<h1 id="Conditional-Knowledge-Base-Construction"><a href="#Conditional-Knowledge-Base-Construction" class="headerlink" title="Conditional Knowledge Base Construction"></a>Conditional Knowledge Base Construction</h1><p><strong>input:</strong> pattern clusters, condition clusters<br><strong>output:</strong> (Subject, Predicate, Object | Condition) triples</p>
<p>要知道并不是所有的 condition 都是重要的，这一步骤会过滤一些不重要的 condition。这里提到了一个概念 missing percentage of slots，指的是能够匹配 pattern 然而却没有 slot 的情况，比如下面的例子，对输入而言，尽管匹配了 pattern，但 SLOT0 是缺失的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">pattern: SLOT0 free upgrade windows_10</div><div class="line">input: free upgrade windows_10</div></pre></td></tr></table></figure></p>
<p>对每个 slot 计算 missing percentage (of slots)，然后把 slot 分为下面三种类型</p>
<ol>
<li>只有一个 cluster 的 slots（没有询问的必要）</li>
<li>基本上不会被忽略的 slots</li>
<li>几乎没有用户会在意的 slots</li>
</ol>
<p>第一种直接过滤，第二种也就是过滤 missing percentage 大于 0.7 的 slot，第三种也就是过滤 missing percentage 小于 0.3 的 slot，剩下的 slots 才是重要的，组成 (Subject, Predicate, Object | Condition) 格式存到 CKB 中。</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20-%20Learning%20to%20Extract%20Conditional%20Knowledge%20for%20Question%20Answering%20using%20Dialogue/map.jpg" class="ful-image" alt="map.jpg">
<p><strong>Subject:</strong> 选定的 entity<br><strong>Predicate:</strong> 同一 cluster 的若干 pattern，用频率最高的若干个单词/短语作为代表性的 predicate<br><strong>Object:</strong> 根据 answer set 与 pattern cluster 的 average embedding 的 cosine similarity 来选择 top answer 作为 object<br><strong>Condition:</strong> 同一 cluster 的若干 condition</p>
<h1 id="Dialogue-Model-Construction"><a href="#Dialogue-Model-Construction" class="headerlink" title="Dialogue Model Construction"></a>Dialogue Model Construction</h1><p>两个任务，看 input question 是否匹配 pattern，缺失的 condition 是否重要，如果重要，那么，提问并提供候选项来让用户选择，填充 slot，返回答案</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;论文&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2983777&quot;&gt;Learning to Extract Conditional Knowledge for Question Answering using Dialogue&lt;/a&gt;提出了 conditional knowledge base(CKB)，存储的信息格式为 (subject, predicate, object|condition)。当用户问句缺少必要条件(condition)时，自动用 dialogue model 来向用户提问获取必要信息，再进行回答。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="QA System" scheme="http://www.shuang0420.com/categories/NLP/QA-System/"/>
    
    
      <category term="Question Answering" scheme="http://www.shuang0420.com/tags/Question-Answering/"/>
    
  </entry>
  
  <entry>
    <title>NLP 笔记 - Text Summarization</title>
    <link href="http://www.shuang0420.com/2017/05/10/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/"/>
    <id>http://www.shuang0420.com/2017/05/10/NLP 笔记 - Text Summarization/</id>
    <published>2017-05-10T01:02:27.000Z</published>
    <updated>2017-10-11T13:10:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>Stanford Dan Jurafsky &amp; Chris Manning: Natural Language Processing 课程笔记。文档/会议/邮件摘要，QA 系统回答 what/how 等复杂问题，都需要自动摘要技术。本篇主要讲基于查询的摘要。<br><a id="more"></a></p>
<h1 id="Types-of-Summarization-Task"><a href="#Types-of-Summarization-Task" class="headerlink" title="Types of Summarization Task"></a>Types of Summarization Task</h1><p><strong>单文档 vs 多文档</strong></p>
<ul>
<li>Single-­‐document summarization<br>给定一个文档，产生 abstract/outline/headline</li>
<li>Multiple-­‐document summarization<br>给定主题相关的一组文档，通过摘要来概况同一事件/主题的信息</li>
</ul>
<p>与单文档相比，多文档任务面临的<strong>减小句子冗余度/确定句子顺序/确定压缩比率(从每个文档中抽取句子的比例)/指代消解问题</strong>都更加的突出</p>
<p><strong>查询无关 vs 查询相关</strong></p>
<ul>
<li>Generic summarization<br>对一个文档的内容做整体性的摘要</li>
<li>Query-­‐focused summarization<br>根据用户查询语句表达的信息需求(information need)来对一篇文档做出摘要总结，如 Google snippets<br>用于 QA 系统，根据提问产生文档摘要来回答一个复杂的问题</li>
</ul>
<p>查询相关的文本摘要对句子重要性的衡量需要同时考虑主题性以及查询相关性</p>
<p><strong>抽取式 vs 合成式</strong></p>
<ul>
<li>Extractive summarization<br>摘要句子完全从源文档中抽取形成</li>
<li>Abstractive summarization: our own words<br>从源文档中抽取句子并进行改写形成摘要</li>
</ul>
<p>目前来看，大多数的系统是抽取式，合成式的技术还不够成熟。</p>
<p>本章主要讨论 <strong>Extractive summarization</strong></p>
<h1 id="Baseline-Model"><a href="#Baseline-Model" class="headerlink" title="Baseline Model"></a>Baseline Model</h1><p>好的作者常常会在标题和第一句话就表达主题，因此最简单的 baseline 就是抽取文档中的首句作为摘要。</p>
<h1 id="Generating-snippets-query-focused-summaries"><a href="#Generating-snippets-query-focused-summaries" class="headerlink" title="Generating snippets: query-focused summaries"></a>Generating snippets: query-focused summaries</h1><p>看一下 Google snippets</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/google%20snippets.png" class="ful-image" alt="google%20snippets.png">
<ul>
<li>Single-­‐document summarization</li>
<li>Query-­‐focused summarization</li>
<li>Extractive summarization</li>
</ul>
<h2 id="Main-Stages"><a href="#Main-Stages" class="headerlink" title="Main Stages"></a>Main Stages</h2><p>产生 snippets 的<strong>主要步骤(Stages):</strong></p>
<ul>
<li><strong>content selection</strong><br>选择需要抽取的句子(segment/moving window)</li>
<li><strong>information ordering</strong><br>对抽取的句子进行排序</li>
<li><strong>sentence realization</strong><br>形成摘要</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/summarization%20stages.png" class="ful-image" alt="summarization%20stages.png">
<h2 id="Base-Summarization-Algorithm"><a href="#Base-Summarization-Algorithm" class="headerlink" title="Base Summarization Algorithm"></a>Base Summarization Algorithm</h2><p>对一个 base summarization algorithm 而言，其实只需要做第一步 conent selection，之后的 information ordering 即保留句子在源文档的位置，sentence realization 即保留原句。</p>
<h3 id="Unsupervised-content-selection"><a href="#Unsupervised-content-selection" class="headerlink" title="Unsupervised content selection"></a>Unsupervised content selection</h3><p>我们需要选择的是<strong>salient or informative</strong>的句子，一般来说，salient words 有两种选择方法</p>
<ul>
<li>tf-idf<br>也就是找在该文档中经常出现，并且在其他文章中很少出现的单词</li>
<li>topic signature<br>通过计算 log-likelihood ratio(LLR) 并设置 threhold 来过滤并选择重要的单词<br>$weight(w_i)=1 \ if -2log \lambda(w_i)&gt;10 \ else \ 0$</li>
</ul>
<p>这里主要介绍下<strong>Topic signature-based content selection with queries</strong></p>
<p><strong>Step1: choose words</strong><br>salient words 有下面两个来源:</p>
<ul>
<li>计算每个单词的 log-likelihood ratio(LLR) ，根据 threshold 进行选择</li>
<li>选择所有出现在 query 里的单词</li>
</ul>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/topic%20signature.png" class="ful-image" alt="topic%20signature.png">
<p><strong>Step2: weigh a sentence(or window)</strong><br>在上一步计算的单词分数基础上，计算每个句子/短语窗口的分数<br>$$weight(s)={1 \over |S|} \sum_{w \in S} weight(w)$$<br>选择 top k 个句子。</p>
<h3 id="Supervised-content-selection"><a href="#Supervised-content-selection" class="headerlink" title="Supervised content selection"></a>Supervised content selection</h3><p>其实是一个二分类问题，对文档中的每一个句子，用分类器进行二值分类，1 代表这个句子可以作为摘要输出句子，0 代表不能。</p>
<p>监督学习方法难点是获得训练集，很有可能摘要句子并不是文档中的完整句子，所以需要事先把文档句子和摘要句子对齐，才能得到分类标签。然后对文档句子抽取特征将句子映射为特征向量，再训练分类器，可以用的算法如 <strong>Naive Bayes/Decision Tree/HMM/CRF/LR/SVM/SVM-HMM等</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/supervised%20content%20selection.png" class="ful-image" alt="supervised%20content%20selection.png">
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>上面提到的只是最基础的方法，对非监督方法而言，还有下面的方法</p>
<ul>
<li>线性组合方法：利用手工构建的评分函数，采取若干重要特征并手工设定特征权重，以此来对句子重要性进行得分计算。</li>
<li>词汇链方法：通过文章中相邻句子的语义相似性来判断文章主题，引入Wordnet等语言资源中的同义词和近义词信息，分析文章中相邻句子的语义相似性。寻找若干最长的词汇链来确定文章包含主题，并依此来构建文摘句子集合；[6,7]  </li>
<li>图模型方法：将文章中每个句子作为图中的节点，利用句子之间内容相似性构建图中节点之间的边。构建好文章图后，利用PageRank或者HITS<a href="http://lib.csdn.net/base/datastructure" target="_blank" rel="external">算法</a>来迭代计算图中节点的权值，按照权值大小作为句子重要性的评分依据来对文摘句子进行抽取。[3,4]</li>
<li>子主题分析方法：通过聚类或者语义块分析等手段，发现文章包含的子主题，并从不同的子主题中抽取句子来构造摘要句子集合。LSA，PLSA等方法属于这一类[8,10,12]。</li>
</ul>
<p>一些研究工作 <a href="https://pdfs.semanticscholar.org/8ddf/5baeeab2e2fd401c0959a2d70e4c2ba68a33.pdf" target="_blank" rel="external">Document Summarization using Conditional Random Fields</a> 和 <a href="https://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0ahUKEwjC5bWohpzUAhWBsY8KHUnHDlQQFggkMAA&amp;url=http%3a%2f%2fwww2009%2eorg%2fproceedings%2fpdf%2fp71%2epdf&amp;usg=AFQjCNHZgHD2NVdqCJ9xONGboyNI0oyNog" target="_blank" rel="external">Enhancing Diversity, Coverage and Balance for  Summarization through Structure Learning</a>对主流的一些自动文摘方法做了对比，对于非监督方法来说，基于 HITS 的图模型方法明显优于其他方法，对于监督方法来说，SVM-HMM 和 CRF 方法效果最好，其中 SVM-HMM 方法在一般<a href="http://lib.csdn.net/base/softwaretest" target="_blank" rel="external">测试</a>集合上稍微优于CRF，在难度高的测试集合上效果明显好于CRF方法。这两个方法优于HITS图模型方法，不过优势并非特别明显；从测试结果来看，方法效果排序如下 SVM-HMM&gt;CRF&gt;HITS&gt;HMM&gt;SVM&gt;LR&gt;NB&gt;LSA</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">1. 简单特征线性组合方法(非监督方法)</div><div class="line">	即确定一些主要特征，然后设定特征权重后根据线性组合方式来进行句子打分和排序输出；</div><div class="line">	优点：</div><div class="line">		方法简单；</div><div class="line">		无需训练数据；</div><div class="line">		执行速度快；</div><div class="line">	缺点：</div><div class="line">		由于手工拟合评分函数，只能采取部分主要特征；</div><div class="line">		权重设定需要手工设置并不断调试；</div><div class="line">		效果一般；</div><div class="line">2. 基于HITS的图模型方法(非监督方法)</div><div class="line">	考虑到目前的研究表明，基于 HITS 的图模型方法是非监督方法中效果最好的，如果采取非监督方法，则优先考虑 HITS 的图模型方法；</div><div class="line">	优点:</div><div class="line">		无需训练集合；</div><div class="line">		基本与语言和领域无关；</div><div class="line">		效果好；</div><div class="line">	缺点：</div><div class="line">		由于存在任意句子相似性计算和迭代计算，所以运行速度相对比较慢；需要改进速度提出改进方法；</div><div class="line">		该方法没有考虑信息冗余的问题，可能需要有针对性的改进；</div><div class="line">3. 基于 CRF 或者 SVM-HMM 的监督学习方法</div><div class="line">	目前研究表明，CRF 和 SVM-HMM 在所有监督和非监督方法中是效果最好的，其中 SVM-HMM 效果略好于 CRF，CRF 略好于 HITS 图模型方法；所以如果采取监督学习思路，可以考虑CRF或者SVM-HMM的方法；</div><div class="line">	优点：</div><div class="line">		效果好；</div><div class="line">	缺点：</div><div class="line">		需要训练数据；</div><div class="line">		效果依赖于训练数据质量和领域等方面的情况；</div><div class="line">		执行速度慢；尤其是融合HITS模型等复杂特征，需要首先计算复杂特征，所以速度应该是最慢的；</div></pre></td></tr></table></figure>
<p>这部分的总结来自<a href="http://blog.csdn.net/malefactor/article/details/8312838" target="_blank" rel="external">文本摘要技术调研</a></p>
<p>[1] .Jie Tang, Limin Yao, and Dewei Chen . Multi-topic based Query-oriented Summarization.<br>W.-T.Yih, J. Goodman, L. Vanderwende, and H. Suzuki. Multi-document summarization by maximizing informative content-words.In Proceedingsof IJCAI’07, 2007.<br>[2]  Dou Shen1,Jian-Tao Sun.etc    DocumentSummarization using Conditional Random Fields.  In<em>Proceedingsof IJCAI’07</em>, 2007.<br>[3] GunesErkan.  Dragomir R. Radev.  LexRank: Graph-based LexicalCentrality as Salience in   Text Summarization.  Journal of ArtificialIntelligence Research 22 (2004) 457-479<br>[4] Rada Mihalcea.  Language Independent Extractive Summarization.<br>[5] Liangda Li, Ke Zhou†,Gui-Rong Xue etc  Enhancing Diversity, Coverage and Balance for  Summarization through Structure Learning.  WWW 2009.<br>[6] Gregory Silber and Kathleen F. McCoy  Efficient Text Summarization Using Lexical Chains.<br>[7] Barzilay,Regina and Michael Elhadad. Using Lexical Chainsfor Text Summarization. in Proceedings of the IntelligentScalable Text Summarization Workshop(ISTS’97), 1997.<br>[8] Shanmugasundaram Hariharan   Extraction Based Multi Document Summarization using Single Document  Summary Cluster   <em>Int. J.Advance. Soft Comput. Appl., Vol. 2, No. 1, March 2010</em><br>[9] ShanmugasundaramHariharan, “Merging Multi-Document Text Summaries-A Case Study”, <em>Journal of Scienceand Technology</em>, Vol.5, No.4,pp.63-74, December 2009.<br>[10] JinZhang etc  AdaSum: An Adaptive Model for Summarization.  CIKM 2008.<br>[11] Varadarajan and Hristidis. A System forQuery-Specific Document Summarization CIKM2006.<br>[12] LeonhardHennig  Topic-based Multi-Document Summarization with Probabilistic Latent Semantic Analysis</p>
<h1 id="Complex-Questions-Summarizing-Multiple-Documents"><a href="#Complex-Questions-Summarizing-Multiple-Documents" class="headerlink" title="Complex Questions: Summarizing Multiple Documents"></a>Complex Questions: Summarizing Multiple Documents</h1><p>自动摘要还可以用于回答复杂的问句(如 how/what)，有两大类方法，自底向上的 snippet 方法，以及自上而下的信息抽取方法。</p>
<p><strong>Bottom-up snippet method:</strong></p>
<ol>
<li>找到相关文档集合</li>
<li>从文档集合中抽取 informative sentences</li>
<li>对句子进行排序并形成回答</li>
</ol>
<p><strong>Top-down information extraction method:</strong></p>
<ol>
<li>根据不同的问题类型建立特定的信息抽取框架</li>
<li>抽取信息</li>
<li>形成回答</li>
</ol>
<p>属于研究热点，有很大提升空间。</p>
<h2 id="Bottom-up-snippet-method"><a href="#Bottom-up-snippet-method" class="headerlink" title="Bottom-up snippet method"></a>Bottom-up snippet method</h2><p>处理框架：</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/query-focused%20multi-document%20summarization.png" class="ful-image" alt="query-focused%20multi-document%20summarization.png">
<h3 id="Sentence-Simplification"><a href="#Sentence-Simplification" class="headerlink" title="Sentence Simplification"></a>Sentence Simplification</h3><p>首先简化句子，可以删除 <strong>同位语/定语从句/没有命名实体的介词短语/句子开头的状语</strong> 等</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/Simplifying%20sentences.png" class="ful-image" alt="Simplifying%20sentences.png">
<h3 id="Sentence-Extraction"><a href="#Sentence-Extraction" class="headerlink" title="Sentence Extraction"></a>Sentence Extraction</h3><h4 id="Maximal-Marginal-Relevance-MMR"><a href="#Maximal-Marginal-Relevance-MMR" class="headerlink" title="Maximal Marginal Relevance(MMR)"></a>Maximal Marginal Relevance(MMR)</h4><p>MMR 是一种从多个文档中进行选择的递归(iterative)方法，递归的从文档中选取最合适的句子插入到 summary/answer 中，两个指标是<strong>相关性(relevant)</strong>，以及 <strong>新颖度(novel)</strong>。这在<a href="http://www.shuang0420.com/2016/12/07/Search%20Engines笔记%20-%20Diversity/">Search Engines笔记 - Diversity</a>也提到过。</p>
<ul>
<li><strong>Relevant</strong><br>与 query 最相关的句子，high cosine similarity to the query</li>
<li><strong>Novel</strong><br>减少 summary/answer 的冗余程度，low cosine similariy to the summary<br>$\hat S_{MMR}=max s \in D \lambda sim(s,Q) - (1-\lambda)max s \in S sim(s,S)$</li>
<li>不断添加句子到 summary 中，直到 summary length 到达预期要求</li>
</ul>
<h4 id="LLR-MMR-choosing-informative-yet-non-redundant-sentences"><a href="#LLR-MMR-choosing-informative-yet-non-redundant-sentences" class="headerlink" title="LLR + MMR: choosing informative yet non-redundant sentences"></a>LLR + MMR: choosing informative yet non-redundant sentences</h4><p>1.  根据 LLR 对每个句子进行打分<br>2.  选择 top k 个句子作为候选的摘要句<br>3.  迭代的从候选集里选取高分并且还不在当前摘要里的句子，添加进摘要</p>
<h3 id="Information-Ordering"><a href="#Information-Ordering" class="headerlink" title="Information Ordering"></a>Information Ordering</h3><ul>
<li>时间顺序(Chronological ordering)<br>根据时间对句子进行排序，主要用于新闻类的摘要(Barzilay, Elhadad, and McKeown 2002)</li>
<li>一致性(Coherence)<br>根据 cosine similarity 对句子排序，使得摘要中相邻的句子更相似，或者相邻句子讨论同一个实体(Barzilay and Lapata 2007)</li>
<li>专题排序(Topical ordering)<br>从源文档中学习主题排序</li>
</ul>
<h2 id="Information-Extraction-Method"><a href="#Information-Extraction-Method" class="headerlink" title="Information Extraction Method"></a>Information Extraction Method</h2><p>用信息抽取(IE)的方法来回答，比如说一个人物传记类的问题答案通常包含人物的 <strong>生卒年月，国籍，教育程度，名望/荣誉等</strong>，一个定义类问题(definition)通常包括 <strong>属(genus)或者上位词(hypernym)</strong>，如 The Hajj is a type of ritual，一个关于用药的医学类问题通常包括 <strong>问题(medical condition)、治疗(intervention, the drug or procedure)和结果(outcome)</strong></p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/de%EF%AC%81nition%20questions.png" class="ful-image" alt="de%EF%AC%81nition%20questions.png">
<p>上图是课程提到的 IE 方法框架，暂时不是很理解 predicate identification 这一步，感觉 <a href="http://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d3/data/pdf/anthology-PDF/H/H01/H01-1054.pdf" target="_blank" rel="external">Multidocument Summarization via Information Extraction</a>这篇文档的框架更加 straight-forward 一些。<img src="IE METHOD.png" alt="IE METHOD"></p>
<h1 id="Evaluating-summaries-ROUGE"><a href="#Evaluating-summaries-ROUGE" class="headerlink" title="Evaluating summaries: ROUGE"></a>Evaluating summaries: ROUGE</h1><p>ROUGE 是内部评价指标，以 BLEU 为基础，虽然比不上人工评价，但是用起来很方便</p>
<p>给定一个文档 D，以及一个自动生成的文本摘要 X：</p>
<ol>
<li>由 N 个人产生 D 的 reference summaries</li>
<li>运行系统，产生自动文本摘要 X</li>
<li>计算 reference summaries 中的 bigram 在 X 里出现的比例</li>
</ol>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/ROUGE-2.png" class="ful-image" alt="ROUGE-2.png">
<p>举个例子，问句是 “What is water spinach?”，Human 1, Human 2, Human 3 是人工产生的 reference summaries，System answer 是自动摘要，计算如下</p>
<img src="http://ox5l2b8f4.bkt.clouddn.com/images/NLP%20%E7%AC%94%E8%AE%B0%20-%20Text%20Summarization/ROUGE%20EXAMPLE.png" class="ful-image" alt="ROUGE%20EXAMPLE.png">
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Stanford Dan Jurafsky &amp;amp; Chris Manning: Natural Language Processing 课程笔记。文档/会议/邮件摘要，QA 系统回答 what/how 等复杂问题，都需要自动摘要技术。本篇主要讲基于查询的摘要。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://www.shuang0420.com/categories/NLP/"/>
    
      <category term="Course" scheme="http://www.shuang0420.com/categories/NLP/Course/"/>
    
    
      <category term="NLP" scheme="http://www.shuang0420.com/tags/NLP/"/>
    
      <category term="text summarization" scheme="http://www.shuang0420.com/tags/text-summarization/"/>
    
      <category term="文本摘要" scheme="http://www.shuang0420.com/tags/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/"/>
    
  </entry>
  
</feed>
